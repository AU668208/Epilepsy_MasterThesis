{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d82a9f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nptdms import TdmsFile\n",
    "\n",
    "\n",
    "ePatch_path_old = r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus to Lausanne\\Patients ePatch data\"\n",
    "ePatch_path_new = r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "337ec788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK → E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 1\\Patient_1_1_trimmed.tdms\n",
      "  Input:  group='Untitled', channel='EKG', fs=512.000 Hz, n=97861504\n",
      "  Output: group='Recording', channel='ECG', n=96632704\n",
      "  New wf_start_time: 2016-02-22T11:24:14\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nptdms import TdmsFile, TdmsWriter, RootObject, GroupObject, ChannelObject\n",
    "\n",
    "\n",
    "# ---------- Hjælpefunktioner ----------\n",
    "\n",
    "def parse_start_from_name(root_name: str) -> datetime | None:\n",
    "    \"\"\"\n",
    "    Forsøger at finde starttid i 'name'-feltet.\n",
    "    Understøtter fx:\n",
    "      ..._22_2_2016_kl_110414__24_2_2016_kl_16.tdms\n",
    "      ..._22_02_2016_kl_110414__24_02_2016_kl_160000.tdms\n",
    "      ..._22022016_kl_110414__24022016_kl_16.tdms  (går også)\n",
    "    Returnerer datetime (naiv, lokal) eller None hvis ikke fundet.\n",
    "    \"\"\"\n",
    "    s = root_name\n",
    "\n",
    "    # 1) D_M_Y + kl_HHMMSS (sekunder valgfrie)\n",
    "    m = re.search(r'(\\d{1,2})_(\\d{1,2})_(\\d{4})_kl_(\\d{1,2})(\\d{2})?(\\d{2})?', s)\n",
    "    if m:\n",
    "        d, M, y = map(int, m.group(1, 2, 3))\n",
    "        H = int(m.group(4))\n",
    "        mnt = int(m.group(5)) if m.group(5) else 0\n",
    "        sec = int(m.group(6)) if m.group(6) else 0\n",
    "        return datetime(y, M, d, H, mnt, sec)\n",
    "\n",
    "    # 2) DDMMYYYY + kl_HHMMSS (sekunder valgfrie)\n",
    "    m = re.search(r'(\\d{2})(\\d{2})(\\d{4})_kl_(\\d{1,2})(\\d{2})?(\\d{2})?', s)\n",
    "    if m:\n",
    "        d, M, y = int(m.group(1)), int(m.group(2)), int(m.group(3))\n",
    "        H = int(m.group(4))\n",
    "        mnt = int(m.group(5)) if m.group(5) else 0\n",
    "        sec = int(m.group(6)) if m.group(6) else 0\n",
    "        return datetime(y, M, d, H, mnt, sec)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def pick_channel(td: TdmsFile, preferred=(\"Untitled\", \"EKG\")):\n",
    "    \"\"\"\n",
    "    Vælg kanal:\n",
    "    - Hvis ('Untitled','EKG') findes, brug den.\n",
    "    - Ellers første kanal i første gruppe.\n",
    "    Returnerer (group_name, channel_name, channel_obj)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ch = td[preferred[0]][preferred[1]]\n",
    "        return preferred[0], preferred[1], ch\n",
    "    except Exception:\n",
    "        # find første kanal der findes\n",
    "        for g in td.groups():\n",
    "            chans = g.channels()\n",
    "            if chans:\n",
    "                return g.name, chans[0].name, chans[0]\n",
    "    raise RuntimeError(\"Ingen kanaler fundet i TDMS-filen.\")\n",
    "\n",
    "\n",
    "def build_channel_properties(orig_props: dict, new_start_time: datetime, wf_increment: float) -> dict:\n",
    "    \"\"\"\n",
    "    Sæt properties til output-kanalen. Bevar nyttige felter fra originalen,\n",
    "    men tving ny starttid og increment igennem.\n",
    "    \"\"\"\n",
    "    keep_keys = [\n",
    "        \"unit_string\", \"wf_xname\", \"wf_xunit_string\",\n",
    "        \"NI_UnitDescription\", \"NI_ChannelName\", \"PreFilter\", \"TransducerType\"\n",
    "    ]\n",
    "    props = {}\n",
    "\n",
    "    # Bevar nogle felter hvis de findes\n",
    "    for k in keep_keys:\n",
    "        if k in orig_props:\n",
    "            props[k] = orig_props[k]\n",
    "\n",
    "    # Sørg for lækre defaults\n",
    "    props.setdefault(\"unit_string\", orig_props.get(\"unit_string\", \"uV\"))\n",
    "    props.setdefault(\"wf_xname\", orig_props.get(\"wf_xname\", \"Time\"))\n",
    "    props.setdefault(\"wf_xunit_string\", orig_props.get(\"wf_xunit_string\", \"s\"))\n",
    "\n",
    "    # Tving wf_* vi vil styre\n",
    "    props[\"wf_increment\"] = float(wf_increment)      # sekunder pr. sample\n",
    "    props[\"wf_start_time\"] = new_start_time          # absolut start\n",
    "    props[\"wf_start_offset\"] = 0.0                   # vi har trimmet fra starten\n",
    "\n",
    "    # Kan navngive kanalen pænt\n",
    "    props[\"NI_ChannelName\"] = \"ECG\"\n",
    "\n",
    "    return props\n",
    "\n",
    "\n",
    "# ---------- Hovedfunktion ----------\n",
    "\n",
    "def rewrite_tdms(\n",
    "    src_tdms_path: str | Path,\n",
    "    dst_dir: str | Path,\n",
    "    out_group: str = \"Recording\",\n",
    "    out_channel: str = \"ECG\",\n",
    "    trim_minutes: int = 20,\n",
    "):\n",
    "    src_tdms_path = Path(src_tdms_path)\n",
    "    dst_dir = Path(dst_dir)\n",
    "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Læs metadata (hurtigt) og åbn så til data\n",
    "    md = TdmsFile.read_metadata(src_tdms_path)\n",
    "\n",
    "    # Root props & starttid fra navn\n",
    "    root_name = md.properties.get(\"name\", src_tdms_path.name)\n",
    "    parsed_t0 = parse_start_from_name(root_name)\n",
    "\n",
    "    with TdmsFile.open(src_tdms_path) as td:\n",
    "        # Vælg kanal\n",
    "        in_group, in_channel, ch = pick_channel(td)\n",
    "\n",
    "        # Sampling\n",
    "        inc = ch.properties.get(\"wf_increment\", None)\n",
    "        if inc is None or float(inc) <= 0:\n",
    "            raise ValueError(\"Kunne ikke finde 'wf_increment' (samplingsinterval) i kanalens properties.\")\n",
    "        fs = 1.0 / float(inc)\n",
    "\n",
    "        # Original fallback-starttid (hvis navn ikke kan parses)\n",
    "        t0_meta = ch.properties.get(\"wf_start_time\", None)\n",
    "        if parsed_t0 is None:\n",
    "            new_start = t0_meta if t0_meta is not None else datetime(1970, 1, 1)\n",
    "        else:\n",
    "            new_start = parsed_t0\n",
    "\n",
    "        # Trim-parametre\n",
    "        n = len(ch)\n",
    "        trim_n = int(round(trim_minutes * 60 * fs))\n",
    "        if n <= 2 * trim_n:\n",
    "            raise ValueError(f\"Filen er for kort ({n} samples) til at fjerne {trim_minutes} min i begge ender ved fs={fs:.3f} Hz.\")\n",
    "\n",
    "        start_idx = trim_n\n",
    "        end_idx = n - trim_n  # eksklusiv\n",
    "        new_len = end_idx - start_idx\n",
    "\n",
    "        # Ny starttid = parsed_t0 + 20 min\n",
    "        new_start_adj = new_start + timedelta(minutes=trim_minutes)\n",
    "\n",
    "        # Lav outputsti\n",
    "        out_name = src_tdms_path.stem + \"_trimmed.tdms\"\n",
    "        dst_path = dst_dir / out_name\n",
    "\n",
    "        # Forbered properties\n",
    "        out_root_props = dict(md.properties)  # kopi af root\n",
    "        # Du kan evt. opdatere 'name' i root props til nyt navn:\n",
    "        out_root_props[\"name\"] = out_name\n",
    "        out_root_props[\"registertxt1\"] = \"Written by Python (npTDMS)\"\n",
    "\n",
    "        # Bevar originale kanal-properties, men sæt wf_start_time/increment mm.\n",
    "        chan_props = build_channel_properties(ch.properties, new_start_adj, float(inc))\n",
    "\n",
    "        # Læs hele signalet (simpelt). Hvis RAM er et problem, skriv i chunks (se kommentar længere nede).\n",
    "        data_trim = ch[start_idx:end_idx]\n",
    "        # Sikr en rimelig dtype (bevar original dtype hvis muligt)\n",
    "        if isinstance(data_trim, np.ndarray):\n",
    "            out_data = data_trim\n",
    "        else:\n",
    "            out_data = np.asarray(data_trim)\n",
    "\n",
    "        # Skriv ny TDMS\n",
    "        with TdmsWriter(dst_path) as writer:\n",
    "            root_obj = RootObject(properties=out_root_props)\n",
    "            group_obj = GroupObject(out_group, properties={})\n",
    "            chan_obj = ChannelObject(out_group, out_channel, out_data, properties=chan_props)\n",
    "            writer.write_segment([root_obj, group_obj, chan_obj])\n",
    "\n",
    "        print(f\"OK → {dst_path}\")\n",
    "        print(f\"  Input:  group='{in_group}', channel='{in_channel}', fs={fs:.3f} Hz, n={n}\")\n",
    "        print(f\"  Output: group='{out_group}', channel='{out_channel}', n={new_len}\")\n",
    "        print(f\"  New wf_start_time: {new_start_adj.isoformat()}\")\n",
    "\n",
    "        # Bonus: skriv et lille summary-CSV (metadata) ved siden af (valgfrit)\n",
    "        meta = {\n",
    "            \"input_file\": src_tdms_path.name,\n",
    "            \"output_file\": out_name,\n",
    "            \"fs_Hz\": fs,\n",
    "            \"n_in\": n,\n",
    "            \"n_out\": new_len,\n",
    "            \"trim_minutes_each_end\": trim_minutes,\n",
    "            \"new_start_iso\": new_start_adj.isoformat(),\n",
    "            \"root_name_parsed\": root_name,\n",
    "        }\n",
    "        pd.DataFrame([meta]).to_csv(dst_path.with_suffix(\".summary.csv\"), index=False)\n",
    "\n",
    "\n",
    "# ---------- Brug: udfyld dine stier herunder ----------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    src = r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus to Lausanne\\Patients ePatch data\\Patient 1\\recording 1\\Patient_1_1.tdms\"\n",
    "    dst = r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 1\"\n",
    "    rewrite_tdms(src, dst, out_group=\"Recording\", out_channel=\"ECG\", trim_minutes=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0eddc91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nptdms.reader WARNING] Unrecognised version number: 538972776\n",
      "[nptdms.reader WARNING] Last segment metadata is incomplete\n",
      "[nptdms.reader WARNING] Unrecognised version number: 538972776\n",
      "[nptdms.reader WARNING] Last segment metadata is incomplete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient-ID'er fra Excel: [3, 5, 6, 8, 10, 14, 15, 16, 21, 23, 27, 28, 29, 31, 34, 37, 39, 40, 41, 42]\n",
      "Fandt 72 TDMS-filer i alt under: E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus to Lausanne\\Patients ePatch data\n",
      "Udvalgt 37 filer baseret på Excel-listen (35 fravalgt).\n",
      "[1/37] FEJL i E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus to Lausanne\\Patients ePatch data\\Patient 10\\recording 1\\Patient 10_1.tdms: RuntimeError: Ingen kanaler fundet i TDMS-filen.\n",
      "[2/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 14\\recording 1\\Patient 14_1_trimmed.tdms\n",
      "[3/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 14\\recording 2\\Patient 14_2_trimmed.tdms\n",
      "[4/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 15\\recording 1\\Patient 15_1_trimmed.tdms\n",
      "[5/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 15\\recording 2\\Patient 15_2_trimmed.tdms\n",
      "[6/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 16\\recording 1\\Patient 16_1_trimmed.tdms\n",
      "[7/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 21\\recording 1\\Patient 21_1_trimmed.tdms\n",
      "[8/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 21\\recording 2\\Patient 21_2_trimmed.tdms\n",
      "[9/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 23\\enrollment a\\recording 1\\Patient 23a_1_trimmed.tdms\n",
      "[10/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 23\\enrollment b\\recording 1\\Patient 23b_1_trimmed.tdms\n",
      "[11/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 23\\enrollment b\\recording 2\\Patient 23b_2_trimmed.tdms\n",
      "[12/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 27\\enrollment a\\recording 1\\Patient 27a_1_trimmed.tdms\n",
      "[13/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 27\\enrollment b\\recording 1\\Patient 27b_1_trimmed.tdms\n",
      "[14/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 28\\recording 1\\Patient 28_1_trimmed.tdms\n",
      "[15/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 28\\recording 2\\Patient 28_2_trimmed.tdms\n",
      "[16/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 29\\recording 1\\Patient 29_1_trimmed.tdms\n",
      "[17/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 3\\recording 1\\Patient_3_1_trimmed.tdms\n",
      "[18/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 3\\recording 2\\Henrik Koch 07092016_kl_105046__09092016_kl_103000_trimmed.tdms\n",
      "[19/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 31\\enrollment a\\recording 1\\Patient 31a_1_trimmed.tdms\n",
      "[20/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 31\\enrollment b\\recording 1\\Patient 31b_1_trimmed.tdms\n",
      "[21/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 31\\enrollment b\\recording 2\\Patient 31b_2_trimmed.tdms\n",
      "[22/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 34\\enrollment a\\recording 1\\Patient 34a_1_trimmed.tdms\n",
      "[23/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 34\\enrollment b\\recording 1\\Patient 34b_trimmed.tdms\n",
      "[24/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 34\\enrollment c\\recording 1\\Patient 34c_1_trimmed.tdms\n",
      "[25/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 34\\enrollment c\\recording 2\\Patient 34c_2_trimmed.tdms\n",
      "[26/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 37\\recording 1\\Patient 37_1_trimmed.tdms\n",
      "[27/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 39\\recording 1\\Patient 39_1_trimmed.tdms\n",
      "[28/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 40\\recording 1\\Patient 40_1_trimmed.tdms\n",
      "[29/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 40\\recording 2\\Patient 40_2_trimmed.tdms\n",
      "[30/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 41\\recording 1\\Patient 41_1_trimmed.tdms\n",
      "[31/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 42\\recording 1\\Patient 42_1_trimmed.tdms\n",
      "[32/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 5\\recording 1\\Patient 5_1_trimmed.tdms\n",
      "[33/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 6\\recording 1\\Patient 6_1_trimmed.tdms\n",
      "[34/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 6\\recording 2\\Patient 6_2_trimmed.tdms\n",
      "[35/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 8\\Enrollment a\\recording 1\\Patient 8a_1_trimmed.tdms\n",
      "[36/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 8\\Enrollment a\\recording 2\\Patient 8a_2_trimmed.tdms\n",
      "[37/37] OK -> E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 8\\Enrollment b\\Patient 8b_1_trimmed.tdms\n",
      "\n",
      "Batch færdig. Summary: E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\tdms_batch_summary_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import traceback\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nptdms import TdmsFile, TdmsWriter, RootObject, GroupObject, ChannelObject\n",
    "\n",
    "\n",
    "# -------- Parse starttid fra root.name --------\n",
    "def parse_start_from_name(root_name: str) -> datetime | None:\n",
    "    s = root_name\n",
    "    m = re.search(r'(\\d{1,2})_(\\d{1,2})_(\\d{4})_kl_(\\d{1,2})(\\d{2})?(\\d{2})?', s)\n",
    "    if m:\n",
    "        d, M, y = map(int, m.group(1, 2, 3))\n",
    "        H = int(m.group(4))\n",
    "        mnt = int(m.group(5)) if m.group(5) else 0\n",
    "        sec = int(m.group(6)) if m.group(6) else 0\n",
    "        return datetime(y, M, d, H, mnt, sec)\n",
    "    m = re.search(r'(\\d{2})(\\d{2})(\\d{4})_kl_(\\d{1,2})(\\d{2})?(\\d{2})?', s)\n",
    "    if m:\n",
    "        d, M, y = int(m.group(1)), int(m.group(2)), int(m.group(3))\n",
    "        H = int(m.group(4))\n",
    "        mnt = int(m.group(5)) if m.group(5) else 0\n",
    "        sec = int(m.group(6)) if m.group(6) else 0\n",
    "        return datetime(y, M, d, H, mnt, sec)\n",
    "    return None\n",
    "\n",
    "\n",
    "# -------- Ekstraher patient-ID fra sti/filnavn --------\n",
    "def extract_patient_id_from_path(p: Path) -> int | None:\n",
    "    # kig i hver path-del og til sidst fil-stem\n",
    "    candidates = list(p.parts) + [p.stem]\n",
    "    for part in candidates:\n",
    "        m = re.search(r'Patient[ _-]?(\\d+)', part, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            try:\n",
    "                return int(m.group(1))\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "\n",
    "# -------- Vælg kanal --------\n",
    "def pick_channel(td: TdmsFile, preferred=(\"Untitled\", \"EKG\")):\n",
    "    try:\n",
    "        ch = td[preferred[0]][preferred[1]]\n",
    "        return preferred[0], preferred[1], ch\n",
    "    except Exception:\n",
    "        for g in td.groups():\n",
    "            chans = g.channels()\n",
    "            if chans:\n",
    "                return g.name, chans[0].name, chans[0]\n",
    "    raise RuntimeError(\"Ingen kanaler fundet i TDMS-filen.\")\n",
    "\n",
    "\n",
    "# -------- Opbyg kanal-properties til output --------\n",
    "def build_channel_properties(orig_props: dict, new_start_time: datetime, wf_increment: float) -> dict:\n",
    "    keep_keys = [\n",
    "        \"unit_string\", \"wf_xname\", \"wf_xunit_string\",\n",
    "        \"NI_UnitDescription\", \"NI_ChannelName\", \"PreFilter\", \"TransducerType\"\n",
    "    ]\n",
    "    props = {}\n",
    "    for k in keep_keys:\n",
    "        if k in orig_props:\n",
    "            props[k] = orig_props[k]\n",
    "    props.setdefault(\"unit_string\", orig_props.get(\"unit_string\", \"uV\"))\n",
    "    props.setdefault(\"wf_xname\", orig_props.get(\"wf_xname\", \"Time\"))\n",
    "    props.setdefault(\"wf_xunit_string\", orig_props.get(\"wf_xunit_string\", \"s\"))\n",
    "    props[\"wf_increment\"] = float(wf_increment)\n",
    "    props[\"wf_start_time\"] = new_start_time\n",
    "    props[\"wf_start_offset\"] = 0.0\n",
    "    props[\"NI_ChannelName\"] = \"ECG\"\n",
    "    return props\n",
    "\n",
    "\n",
    "# -------- Læs -> trim -> skriv én fil --------\n",
    "def rewrite_tdms(\n",
    "    src_tdms_path: Path,\n",
    "    dst_dir: Path,\n",
    "    out_group: str = \"Recording\",\n",
    "    out_channel: str = \"ECG\",\n",
    "    trim_minutes: int = 20,\n",
    "):\n",
    "    md = TdmsFile.read_metadata(src_tdms_path)\n",
    "    root_name = md.properties.get(\"name\", src_tdms_path.name)\n",
    "    parsed_t0 = parse_start_from_name(root_name)\n",
    "\n",
    "    with TdmsFile.open(src_tdms_path) as td:\n",
    "        in_group, in_channel, ch = pick_channel(td)\n",
    "\n",
    "        inc = ch.properties.get(\"wf_increment\", None)\n",
    "        if inc is None or float(inc) <= 0:\n",
    "            raise ValueError(\"Kan ikke finde gyldig 'wf_increment' i kanalens properties.\")\n",
    "        inc = float(inc)\n",
    "        fs = 1.0 / inc\n",
    "\n",
    "        t0_meta = ch.properties.get(\"wf_start_time\", None)\n",
    "        new_start = parsed_t0 if parsed_t0 is not None else (t0_meta if t0_meta is not None else datetime(1970, 1, 1))\n",
    "\n",
    "        n = len(ch)\n",
    "        trim_n = int(round(trim_minutes * 60 * fs))\n",
    "        if n <= 2 * trim_n:\n",
    "            raise ValueError(f\"For få samples ({n}) ift. trim {trim_minutes} min @ fs={fs:.3f} Hz.\")\n",
    "\n",
    "        start_idx = trim_n\n",
    "        end_idx = n - trim_n\n",
    "        new_len = end_idx - start_idx\n",
    "        new_start_adj = new_start + timedelta(minutes=trim_minutes)\n",
    "\n",
    "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out_name = src_tdms_path.stem + \"_trimmed.tdms\"\n",
    "        dst_path = dst_dir / out_name\n",
    "\n",
    "        out_root_props = dict(md.properties)\n",
    "        out_root_props[\"name\"] = out_name\n",
    "        out_root_props[\"registertxt1\"] = \"Written by Python (npTDMS)\"\n",
    "\n",
    "        chan_props = build_channel_properties(ch.properties, new_start_adj, inc)\n",
    "\n",
    "        data_trim = ch[start_idx:end_idx]\n",
    "        out_data = np.asarray(data_trim)\n",
    "\n",
    "        with TdmsWriter(dst_path) as writer:\n",
    "            root_obj = RootObject(properties=out_root_props)\n",
    "            group_obj = GroupObject(out_group, properties={})\n",
    "            chan_obj = ChannelObject(out_group, out_channel, out_data, properties=chan_props)\n",
    "            writer.write_segment([root_obj, group_obj, chan_obj])\n",
    "\n",
    "        return {\n",
    "            \"input\": str(src_tdms_path),\n",
    "            \"output\": str(dst_path),\n",
    "            \"fs_Hz\": fs,\n",
    "            \"n_in\": n,\n",
    "            \"n_out\": new_len,\n",
    "            \"group_in\": in_group,\n",
    "            \"channel_in\": in_channel,\n",
    "            \"group_out\": out_group,\n",
    "            \"channel_out\": out_channel,\n",
    "            \"new_start_iso\": new_start_adj.isoformat(),\n",
    "            \"status\": \"ok\",\n",
    "            \"error\": \"\",\n",
    "        }\n",
    "\n",
    "\n",
    "# -------- Batch med Excel-filter + spejlet struktur --------\n",
    "def batch_rewrite_tdms_filtered(\n",
    "    input_root: str | Path,\n",
    "    output_root: str | Path,\n",
    "    excel_path: str | Path,\n",
    "    excel_col: str | None = None,   # hvis None -> brug første kolonne\n",
    "    trim_minutes: int = 20,\n",
    "    out_group: str = \"Recording\",\n",
    "    out_channel: str = \"ECG\",\n",
    "    skip_existing: bool = True,\n",
    "):\n",
    "    input_root = Path(input_root)\n",
    "    output_root = Path(output_root)\n",
    "\n",
    "    # --- læs tilladte patient-ID'er fra Excel ---\n",
    "    df_ids = pd.read_excel(excel_path)\n",
    "    if excel_col is None:\n",
    "        series = df_ids.iloc[:, 0]  # første kolonne\n",
    "    else:\n",
    "        series = df_ids[excel_col]\n",
    "    allowed_patients = {int(x) for x in series.dropna().astype(int).tolist()}\n",
    "    print(f\"Patient-ID'er fra Excel: {sorted(allowed_patients)}\")\n",
    "\n",
    "    # --- find alle TDMS og filtrer på patient-ID i stien ---\n",
    "    all_tdms = [Path(root) / f\n",
    "                for root, _, files in os.walk(input_root)\n",
    "                for f in files if f.lower().endswith(\".tdms\")]\n",
    "    print(f\"Fandt {len(all_tdms)} TDMS-filer i alt under: {input_root}\")\n",
    "\n",
    "    filtered = []\n",
    "    skipped_patient = []\n",
    "    for p in all_tdms:\n",
    "        pid = extract_patient_id_from_path(p)\n",
    "        if pid is None or pid not in allowed_patients:\n",
    "            skipped_patient.append(p)\n",
    "            continue\n",
    "        filtered.append(p)\n",
    "    print(f\"Udvalgt {len(filtered)} filer baseret på Excel-listen ({len(skipped_patient)} fravalgt).\")\n",
    "\n",
    "    # --- processér udvalgte filer ---\n",
    "    results = []\n",
    "    for i, src in enumerate(filtered, 1):\n",
    "        rel = src.relative_to(input_root).parent\n",
    "        dst_dir = output_root / rel\n",
    "        out_name = src.stem + \"_trimmed.tdms\"\n",
    "        out_path = dst_dir / out_name\n",
    "\n",
    "        if skip_existing and out_path.exists():\n",
    "            results.append({\n",
    "                \"input\": str(src), \"output\": str(out_path), \"status\": \"skipped_exists\", \"error\": \"\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rec = rewrite_tdms(\n",
    "                src_tdms_path=src,\n",
    "                dst_dir=dst_dir,\n",
    "                out_group=out_group,\n",
    "                out_channel=out_channel,\n",
    "                trim_minutes=trim_minutes,\n",
    "            )\n",
    "            results.append(rec)\n",
    "            print(f\"[{i}/{len(filtered)}] OK -> {out_path}\")\n",
    "        except Exception as e:\n",
    "            msg = \"\".join(traceback.format_exception_only(type(e), e)).strip()\n",
    "            results.append({\n",
    "                \"input\": str(src), \"output\": str(out_path),\n",
    "                \"status\": \"error\", \"error\": msg\n",
    "            })\n",
    "            print(f\"[{i}/{len(filtered)}] FEJL i {src}: {msg}\")\n",
    "\n",
    "    # --- gem opsummering ---\n",
    "    output_root.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.DataFrame(results)\n",
    "    summary_csv = output_root / \"tdms_batch_summary_filtered.csv\"\n",
    "    df.to_csv(summary_csv, index=False)\n",
    "    print(f\"\\nBatch færdig. Summary: {summary_csv}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# -------- Kørselseksempel --------\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_ROOT = r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus to Lausanne\\Patients ePatch data\"\n",
    "    OUTPUT_ROOT = r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\"\n",
    "    EXCEL_IDS  = r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\Patient seizures.xlsx\"\n",
    "\n",
    "    # Sæt excel_col til præcis kolonnenavn hvis du vil (ellers bruges første kolonne)\n",
    "    batch_rewrite_tdms_filtered(\n",
    "        input_root=INPUT_ROOT,\n",
    "        output_root=OUTPUT_ROOT,\n",
    "        excel_path=EXCEL_IDS,\n",
    "        excel_col=\"Patient number (as given to Switzerland)\",\n",
    "        trim_minutes=20,\n",
    "        out_group=\"Recording\",\n",
    "        out_channel=\"ECG\",\n",
    "        skip_existing=True,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
