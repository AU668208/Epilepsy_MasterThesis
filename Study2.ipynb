{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4323000",
   "metadata": {},
   "source": [
    "# Study 2 â€“ Descriptive Dataset Analysis\n",
    "This notebook characterises the dataset used in this thesis at patient, recording \n",
    "and seizure level. It ensures transparency in the structure, quality and distribution \n",
    "of the available ECG + annotation data prior to further SQI/HRV analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f83da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ensure src is on path\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "SRC_ROOT = PROJECT_ROOT / \"src\"\n",
    "if str(SRC_ROOT) not in sys.path:\n",
    "    sys.path.append(str(SRC_ROOT))\n",
    "\n",
    "from hrv_epatch.dataset.loader import iter_recordings\n",
    "from hrv_epatch.dataset.naming import parse_recording_key\n",
    "from hrv_epatch.dataset.annotations import load_annotations   # for debugging if needed\n",
    "from hrv_epatch.dataset.seizures import SeizureEvent, build_seizure_events_from_df\n",
    "from hrv_epatch.plots.seizure_gantt import plot_recording_seizure_timeline_multiday_clocklabels\n",
    "\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1cb138",
   "metadata": {},
   "source": [
    "## 1. Load dataset (TDMS + annotations)\n",
    "This uses the fully validated TDMS loader + annotation parser from src/hrv_epatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5359fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowKeyError",
     "evalue": "No type extension with name arrow.py_extension_type found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArrowKeyError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m PROJECT_ROOT = Path.cwd()\n\u001b[32m     33\u001b[39m OUT_DIR = Path(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mE:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSpeciale - Results\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDatastruct\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m df_rec = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUT_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecordings_index.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m df_evt = pd.read_parquet(OUT_DIR / \u001b[33m\"\u001b[39m\u001b[33mseizure_events.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m df_rec.head(), df_evt.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvjkv\\anaconda3\\envs\\mast\\Lib\\site-packages\\pandas\\io\\parquet.py:653\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;129m@doc\u001b[39m(storage_options=_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_parquet\u001b[39m(\n\u001b[32m    502\u001b[39m     path: FilePath | ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    510\u001b[39m     **kwargs,\n\u001b[32m    511\u001b[39m ) -> DataFrame:\n\u001b[32m    512\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    513\u001b[39m \u001b[33;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[32m    514\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    650\u001b[39m \u001b[33;03m    1    4    9\u001b[39;00m\n\u001b[32m    651\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_nullable_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m    656\u001b[39m         msg = (\n\u001b[32m    657\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe argument \u001b[39m\u001b[33m'\u001b[39m\u001b[33muse_nullable_dtypes\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will be removed \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    658\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33min a future version.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    659\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvjkv\\anaconda3\\envs\\mast\\Lib\\site-packages\\pandas\\io\\parquet.py:64\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m engine_class \u001b[38;5;129;01min\u001b[39;00m engine_classes:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     66\u001b[39m         error_msgs += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m - \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(err)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvjkv\\anaconda3\\envs\\mast\\Lib\\site-packages\\pandas\\io\\parquet.py:170\u001b[39m, in \u001b[36mPyArrowImpl.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# import utils to register the pyarrow extension types\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension_types\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[38;5;28mself\u001b[39m.api = pyarrow\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvjkv\\anaconda3\\envs\\mast\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\extension_types.py:174\u001b[39m\n\u001b[32m    167\u001b[39m     pyarrow.register_extension_type(\n\u001b[32m    168\u001b[39m         ForbiddenExtensionType(pyarrow.null(), \u001b[33m\"\u001b[39m\u001b[33marrow.py_extension_type\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    169\u001b[39m     )\n\u001b[32m    171\u001b[39m     pyarrow._hotfix_installed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[43mpatch_pyarrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvjkv\\anaconda3\\envs\\mast\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\extension_types.py:166\u001b[39m, in \u001b[36mpatch_pyarrow\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    157\u001b[39m         pickletools.dis(serialized, out)\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    159\u001b[39m             _ERROR_MSG.format(\n\u001b[32m    160\u001b[39m                 storage_type=storage_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    163\u001b[39m             )\n\u001b[32m    164\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[43mpyarrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43munregister_extension_type\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marrow.py_extension_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m pyarrow.register_extension_type(\n\u001b[32m    168\u001b[39m     ForbiddenExtensionType(pyarrow.null(), \u001b[33m\"\u001b[39m\u001b[33marrow.py_extension_type\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    169\u001b[39m )\n\u001b[32m    171\u001b[39m pyarrow._hotfix_installed = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvjkv\\anaconda3\\envs\\mast\\Lib\\site-packages\\pyarrow\\types.pxi:2280\u001b[39m, in \u001b[36mpyarrow.lib.unregister_extension_type\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvjkv\\anaconda3\\envs\\mast\\Lib\\site-packages\\pyarrow\\error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowKeyError\u001b[39m: No type extension with name arrow.py_extension_type found"
     ]
    }
   ],
   "source": [
    "# TDMS_ROOT = Path(r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus to Lausanne\\Patients ePatch data\")\n",
    "# ANN_ROOT  = Path(r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus to Lausanne\\Seizure log ePatch patients with seizures - excluded seizures removed\")\n",
    "\n",
    "# recordings = []\n",
    "\n",
    "# for sig, meta, ann in iter_recordings(TDMS_ROOT, ANN_ROOT):\n",
    "#     rec_start = pd.to_datetime(meta.start_time)\n",
    "#     rec_duration_s = len(sig) / meta.fs\n",
    "#     rec_end = rec_start + pd.to_timedelta(rec_duration_s, unit=\"s\")\n",
    "\n",
    "#     key = parse_recording_key(Path(meta.path))\n",
    "    \n",
    "#     events = build_seizure_events_from_df(ann, rec_start, rec_end)\n",
    "\n",
    "#     recordings.append({\n",
    "#         \"patient_id\": key.patient_id,\n",
    "#         \"enrollment_id\": key.enrollment_id,\n",
    "#         \"recording_id\": key.recording_id,\n",
    "#         \"recording_start\": rec_start,\n",
    "#         \"rec_duration_s\": rec_duration_s,\n",
    "#         \"rec_end\": rec_end,\n",
    "#         \"seizure_events\": events,\n",
    "#         \"tdms_name\": Path(meta.path).name,\n",
    "#         \"ann_df\": ann,\n",
    "#     })\n",
    "\n",
    "# len(recordings)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "OUT_DIR = Path(r\"E:\\Speciale - Results\\Datastruct\")\n",
    "\n",
    "df_rec = pd.read_parquet(OUT_DIR / \"recordings_index.parquet\")\n",
    "df_evt = pd.read_parquet(OUT_DIR / \"seizure_events.parquet\")\n",
    "\n",
    "df_rec.head(), df_evt.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482f674",
   "metadata": {},
   "source": [
    "## 2. Patient-level summary\n",
    "Total hours, number of recordings, number of seizures etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_rows = []\n",
    "patients = sorted(set((r[\"patient_id\"], r[\"enrollment_id\"]) for r in recordings))\n",
    "\n",
    "for pid, enr in patients:\n",
    "    subset = [r for r in recordings if r[\"patient_id\"] == pid and r[\"enrollment_id\"] == enr]\n",
    "    total_hours = sum(r[\"rec_duration_s\"] for r in subset) / 3600\n",
    "    num_seiz = sum(len(r[\"seizure_events\"]) for r in subset)\n",
    "    \n",
    "    summary_rows.append({\n",
    "        \"Patient\": pid,\n",
    "        \"Enrollment\": enr if enr else \"-\",\n",
    "        \"Recordings\": len(subset),\n",
    "        \"Total hours\": total_hours,\n",
    "        \"Total seizures\": num_seiz,\n",
    "        \"Hours per seizure\": total_hours/num_seiz if num_seiz else np.nan,\n",
    "    })\n",
    "\n",
    "df_patient_summary = pd.DataFrame(summary_rows)\n",
    "df_patient_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41821af7",
   "metadata": {},
   "source": [
    "## 3. Recording-level tables & figures\n",
    "A. Recording duration distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1791fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = [r[\"rec_duration_s\"]/3600 for r in recordings]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(durations, bins=20)\n",
    "plt.xlabel(\"Recording duration (hours)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of recording durations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bbb925",
   "metadata": {},
   "source": [
    "B. Seizures per recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50dc6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seiz_counts = [len(r[\"seizure_events\"]) for r in recordings]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(seiz_counts, bins=range(0, max(seiz_counts)+2))\n",
    "plt.xlabel(\"Number of seizures per recording\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Seizures per recording\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd30e08",
   "metadata": {},
   "source": [
    "## 4. Seizure-level characterisation\n",
    "A. Extract seizure durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94504e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events = []\n",
    "for r in recordings:\n",
    "    for ev in r[\"seizure_events\"]:\n",
    "        all_events.append({\n",
    "            \"patient\": r[\"patient_id\"],\n",
    "            \"enrollment\": r[\"enrollment_id\"],\n",
    "            \"recording\": r[\"recording_id\"],\n",
    "            \"duration\": ev.t1 - ev.t0,\n",
    "            \"absolute_ts\": r[\"recording_start\"] + pd.to_timedelta(ev.t0, unit=\"s\")\n",
    "        })\n",
    "\n",
    "df_events = pd.DataFrame(all_events)\n",
    "df_events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3fcae8",
   "metadata": {},
   "source": [
    "B. Seizure duration histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df_events[\"duration\"], bins=20)\n",
    "plt.xlabel(\"Duration (seconds)\")\n",
    "plt.ylabel(\"Seizures\")\n",
    "plt.title(\"Seizure duration distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc5bcc8",
   "metadata": {},
   "source": [
    "C. Time-of-day distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5251f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events[\"hour\"] = df_events[\"absolute_ts\"].dt.hour + df_events[\"absolute_ts\"].dt.minute/60\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df_events[\"hour\"], bins=24)\n",
    "plt.xlabel(\"Hour of day\")\n",
    "plt.ylabel(\"Seizures\")\n",
    "plt.title(\"Seizure time-of-day distribution\")\n",
    "plt.xticks(range(0,24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eb0709",
   "metadata": {},
   "source": [
    "D. Inter-seizure intervals (ISI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "isi_list = []\n",
    "\n",
    "for pid in df_events[\"patient\"].unique():\n",
    "    d = df_events[df_events[\"patient\"] == pid].sort_values(\"absolute_ts\")\n",
    "    if len(d) >= 2:\n",
    "        dt = d[\"absolute_ts\"].diff().dt.total_seconds().dropna()\n",
    "        isi_list.extend(dt)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(isi_list, bins=30)\n",
    "plt.xlabel(\"ISI (seconds)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Inter-seizure interval distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0603c897",
   "metadata": {},
   "source": [
    "## 5. Gantt plot of the entire dataset (from earlier)\n",
    "---- MISSING FUNCTION FOR GANTT ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675880d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings_sorted = sorted(\n",
    "    recordings,\n",
    "    key=lambda r: (r[\"patient_id\"], r[\"enrollment_id\"] or \"\", r[\"recording_id\"])\n",
    ")\n",
    "\n",
    "plot_recording_seizure_timeline_multiday_clocklabels(\n",
    "    recordings_sorted,\n",
    "    max_hours=96,\n",
    "    day_grid=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734ecd7",
   "metadata": {},
   "source": [
    "## 6. Export figures & tables for LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cda321",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = Path(\"study2_outputs\")\n",
    "OUT.mkdir(exist_ok=True)\n",
    "\n",
    "df_patient_summary.to_csv(OUT/\"patient_summary.csv\", index=False)\n",
    "df_events.to_csv(OUT/\"seizure_events.csv\", index=False)\n",
    "\n",
    "print(\"Export completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
