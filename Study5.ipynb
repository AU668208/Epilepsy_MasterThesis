{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc2ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from src.hrv_epatch.study5_tools import Study5Paths, run_study5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9efa73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Study5_final.py\n",
    "# ------------------------------------------------------------\n",
    "# Clean, single-source-of-truth pipeline for Study 5 (event-based)\n",
    "# Jeppesen-compatible:\n",
    "#   - CSI100 computed on RAW RR (no 7RR median prefilter)\n",
    "#   - ModCSI100_filt computed on 7RR median-filtered RR (tachogram prefilter)\n",
    "#   - Slope computed on HR (bpm) derived from FILTERED RR, using abs(LS slope)\n",
    "#   - Products:\n",
    "#       * CSI100_x_SlopeHR\n",
    "#       * ModCSI100_filt_x_SlopeHR\n",
    "#\n",
    "# This file is intentionally self-contained (no legacy dependencies).\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0) IO + indexing helpers\n",
    "# ============================================================\n",
    "\n",
    "_RX = re.compile(\n",
    "    r\"^P(?P<pid>\\d{2})(?P<enr>[a-z]?)_R(?P<rec>\\d{2})_(?P<algo>[^_]+)_rr_aligned\\.csv$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "\n",
    "def parse_rr_filename(p: Path) -> dict:\n",
    "    m = _RX.match(p.name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse filename: {p.name}\")\n",
    "    return {\n",
    "        \"patient_number\": int(m.group(\"pid\")),           # 1..43\n",
    "        \"enrollment_id\": (m.group(\"enr\") or \"\"),         # \"\" / \"a\" / \"b\" / \"c\"\n",
    "        \"recording_id\": int(m.group(\"rec\")),             # 1..99\n",
    "        \"algo_id\": m.group(\"algo\").lower(),\n",
    "    }\n",
    "\n",
    "\n",
    "def _norm_enrollment(x) -> str:\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    if isinstance(x, float) and np.isnan(x):\n",
    "        return \"\"\n",
    "    s = str(x).strip()\n",
    "    if s.lower() == \"nan\":\n",
    "        return \"\"\n",
    "    return s\n",
    "\n",
    "\n",
    "def lookup_recording_uid(meta: dict, df_rec_index: pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "    Find recording_uid from (patient_id, enrollment_id, recording_id)\n",
    "    \"\"\"\n",
    "    pid = int(meta[\"patient_number\"])\n",
    "    enr = _norm_enrollment(meta[\"enrollment_id\"]).lower()\n",
    "    rec = int(meta[\"recording_id\"])\n",
    "\n",
    "    cand = df_rec_index.copy()\n",
    "    cand[\"enrollment_id_norm\"] = cand[\"enrollment_id\"].apply(_norm_enrollment).str.lower()\n",
    "\n",
    "    m = cand[\n",
    "        (cand[\"patient_id\"].astype(int) == pid)\n",
    "        & (cand[\"enrollment_id_norm\"] == enr)\n",
    "        & (cand[\"recording_id\"].astype(int) == rec)\n",
    "    ]\n",
    "    if len(m) != 1:\n",
    "        base = cand[(cand[\"patient_id\"].astype(int) == pid) & (cand[\"enrollment_id_norm\"] == enr)]\n",
    "        raise KeyError(\n",
    "            f\"UID lookup failed: pid={pid} enr='{enr}' rec={rec} (n={len(m)}). \"\n",
    "            f\"Available recording_id for this pid/enr: {sorted(base['recording_id'].unique().tolist())}\"\n",
    "        )\n",
    "    return int(m.iloc[0][\"recording_uid\"])\n",
    "\n",
    "\n",
    "def load_thr_maps_from_excel(\n",
    "    thr_xlsx_path: str | Path,\n",
    "    *,\n",
    "    pid_col: str = \"Patient number\",\n",
    "    modcsi_col: str = \"Threshold ModCSI100_filt x slope\",\n",
    "    csi_col: str = \"Threshold CSI100 x slope\",\n",
    ") -> tuple[dict[int, float], dict[int, float]]:\n",
    "    thr_df = pd.read_excel(thr_xlsx_path)\n",
    "\n",
    "    thr_map_modcsi = (\n",
    "        thr_df.set_index(pid_col)[modcsi_col].dropna().to_dict()\n",
    "    )\n",
    "    thr_map_csi = (\n",
    "        thr_df.set_index(pid_col)[csi_col].dropna().to_dict()\n",
    "    )\n",
    "    thr_map_modcsi = {int(k): float(v) for k, v in thr_map_modcsi.items()}\n",
    "    thr_map_csi = {int(k): float(v) for k, v in thr_map_csi.items()}\n",
    "    return thr_map_modcsi, thr_map_csi\n",
    "\n",
    "\n",
    "def load_df_seiz(seiz_csv_or_df: str | Path | pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Expected minimum:\n",
    "      recording_uid, t0_clinical, t1_clinical\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(seiz_csv_or_df) if isinstance(seiz_csv_or_df, (str, Path)) else seiz_csv_or_df.copy()\n",
    "\n",
    "    req = {\"recording_uid\", \"t0_clinical\", \"t1_clinical\"}\n",
    "    miss = req - set(df.columns)\n",
    "    if miss:\n",
    "        raise KeyError(f\"seizure_events missing columns: {miss}\")\n",
    "\n",
    "    df[\"recording_uid\"] = pd.to_numeric(df[\"recording_uid\"], errors=\"coerce\")\n",
    "    df[\"t0_clinical\"] = pd.to_numeric(df[\"t0_clinical\"], errors=\"coerce\")\n",
    "    df[\"t1_clinical\"] = pd.to_numeric(df[\"t1_clinical\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"recording_uid\"]).copy()\n",
    "    df[\"recording_uid\"] = df[\"recording_uid\"].astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_windows_df_from_sqi_and_seiz(\n",
    "    winq_csv_or_df: str | Path | pd.DataFrame,\n",
    "    df_seiz: pd.DataFrame,\n",
    "    *,\n",
    "    t0_col: str = \"t0_clinical\",\n",
    "    t1_col: str = \"t1_clinical\",\n",
    "    # accept-regel: accepter kun hvis ingen af disse flags er True\n",
    "    flatline_col: str = \"is_flatline\",\n",
    "    noiseburst_col: str = \"is_noiseburst\",\n",
    "    clipping_col: str = \"is_clipping\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build windows_df with required columns:\n",
    "      recording_uid, win_start_s, win_end_s, is_acceptable, window_overlaps_seizure\n",
    "\n",
    "    Source:\n",
    "      - winq file provides per-window SQI flags\n",
    "      - df_seiz provides seizure intervals (t0/t1 in seconds)\n",
    "\n",
    "    Assumptions:\n",
    "      - A window is acceptable if NOT (flatline OR noiseburst OR clipping).\n",
    "      - A window overlaps seizure if [win_start, win_end] overlaps [t0, t1].\n",
    "    \"\"\"\n",
    "    w = pd.read_csv(winq_csv_or_df) if isinstance(winq_csv_or_df, (str, Path)) else winq_csv_or_df.copy()\n",
    "\n",
    "    # required window columns\n",
    "    req_w = {\"recording_uid\", \"win_start_s\", \"win_end_s\", flatline_col, noiseburst_col, clipping_col}\n",
    "    miss_w = req_w - set(w.columns)\n",
    "    if miss_w:\n",
    "        raise KeyError(f\"window_quality missing columns: {miss_w}. Found: {list(w.columns)}\")\n",
    "\n",
    "    # required seizure columns\n",
    "    req_s = {\"recording_uid\", t0_col, t1_col}\n",
    "    miss_s = req_s - set(df_seiz.columns)\n",
    "    if miss_s:\n",
    "        raise KeyError(f\"df_seiz missing columns: {miss_s}. Found: {list(df_seiz.columns)}\")\n",
    "\n",
    "    # coerce types\n",
    "    w[\"recording_uid\"] = pd.to_numeric(w[\"recording_uid\"], errors=\"coerce\")\n",
    "    w[\"win_start_s\"] = pd.to_numeric(w[\"win_start_s\"], errors=\"coerce\")\n",
    "    w[\"win_end_s\"] = pd.to_numeric(w[\"win_end_s\"], errors=\"coerce\")\n",
    "    w = w.dropna(subset=[\"recording_uid\", \"win_start_s\", \"win_end_s\"]).copy()\n",
    "    w[\"recording_uid\"] = w[\"recording_uid\"].astype(int)\n",
    "\n",
    "    def _to_bool(col: pd.Series) -> pd.Series:\n",
    "        if col.dtype == bool:\n",
    "            return col\n",
    "        v = col.astype(str).str.strip().str.lower()\n",
    "        return v.isin([\"1\", \"true\", \"t\", \"yes\", \"y\"])\n",
    "\n",
    "    w[flatline_col] = _to_bool(w[flatline_col])\n",
    "    w[noiseburst_col] = _to_bool(w[noiseburst_col])\n",
    "    w[clipping_col] = _to_bool(w[clipping_col])\n",
    "\n",
    "    # define acceptability\n",
    "    w[\"is_acceptable\"] = ~(w[flatline_col] | w[noiseburst_col] | w[clipping_col])\n",
    "\n",
    "    # compute seizure overlap per window (per recording)\n",
    "    seiz = df_seiz.copy()\n",
    "    seiz[\"recording_uid\"] = pd.to_numeric(seiz[\"recording_uid\"], errors=\"coerce\")\n",
    "    seiz[t0_col] = pd.to_numeric(seiz[t0_col], errors=\"coerce\")\n",
    "    seiz[t1_col] = pd.to_numeric(seiz[t1_col], errors=\"coerce\")\n",
    "    seiz = seiz.dropna(subset=[\"recording_uid\", t0_col, t1_col]).copy()\n",
    "    seiz[\"recording_uid\"] = seiz[\"recording_uid\"].astype(int)\n",
    "\n",
    "    # default: no overlap\n",
    "    w[\"window_overlaps_seizure\"] = False\n",
    "\n",
    "    # efficient-ish per recording loop\n",
    "    for rid, gw in w.groupby(\"recording_uid\", sort=False):\n",
    "        gs = seiz[seiz[\"recording_uid\"] == rid]\n",
    "        if gs.empty:\n",
    "            continue\n",
    "\n",
    "        win_start = gw[\"win_start_s\"].to_numpy(dtype=float)\n",
    "        win_end = gw[\"win_end_s\"].to_numpy(dtype=float)\n",
    "\n",
    "        overlaps = np.zeros(win_start.shape[0], dtype=bool)\n",
    "        for _, srow in gs.iterrows():\n",
    "            a = float(srow[t0_col])\n",
    "            b = float(srow[t1_col])\n",
    "            overlaps |= (win_end >= a) & (win_start <= b)\n",
    "\n",
    "        w.loc[gw.index, \"window_overlaps_seizure\"] = overlaps\n",
    "\n",
    "    return w[[\"recording_uid\", \"win_start_s\", \"win_end_s\", \"is_acceptable\", \"window_overlaps_seizure\"]].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Core HRV features (Jeppesen-compatible)\n",
    "# ============================================================\n",
    "\n",
    "def clean_rr(rr_s: np.ndarray, *, min_s: float = 0.25, max_s: float = 2.5) -> np.ndarray:\n",
    "    rr = np.asarray(rr_s, float)\n",
    "    rr = rr[np.isfinite(rr)]\n",
    "    rr = rr[(rr >= min_s) & (rr <= max_s)]\n",
    "    return rr\n",
    "\n",
    "\n",
    "def median_prefilter_7(rr_s: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    \"previous seven RR intervals\" causal median filter.\n",
    "    \"\"\"\n",
    "    rr = np.asarray(rr_s, float)\n",
    "    out = np.empty_like(rr)\n",
    "    for i in range(rr.size):\n",
    "        j0 = max(0, i - 6)\n",
    "        out[i] = np.median(rr[j0:i+1])\n",
    "    return out\n",
    "\n",
    "\n",
    "def poincare_sd1_sd2(rr_s_win: np.ndarray) -> tuple[float, float]:\n",
    "    rr = np.asarray(rr_s_win, float)\n",
    "    if rr.size < 3:\n",
    "        return np.nan, np.nan\n",
    "    x = rr[:-1]\n",
    "    y = rr[1:]\n",
    "    sd1 = np.std((y - x) / np.sqrt(2.0), ddof=1)\n",
    "    sd2 = np.std((y + x) / np.sqrt(2.0), ddof=1)\n",
    "    return float(sd1), float(sd2)\n",
    "\n",
    "\n",
    "def csi_from_sd(sd1: float, sd2: float) -> float:\n",
    "    T = 4.0 * sd1\n",
    "    L = 4.0 * sd2\n",
    "    if not (np.isfinite(T) and np.isfinite(L) and T > 0):\n",
    "        return np.nan\n",
    "    return float(L / T)\n",
    "\n",
    "\n",
    "def modcsi_from_sd(sd1: float, sd2: float) -> float:\n",
    "    T = 4.0 * sd1\n",
    "    L = 4.0 * sd2\n",
    "    if not (np.isfinite(T) and np.isfinite(L) and T > 0):\n",
    "        return np.nan\n",
    "    return float((L * L) / T)\n",
    "\n",
    "\n",
    "def rolling_median(x: np.ndarray, *, win: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Centered rolling median with min_periods=1.\n",
    "    Uses pandas' rolling median (fast, C-optimized).\n",
    "    \"\"\"\n",
    "    if win is None or int(win) < 1:\n",
    "        raise ValueError(\"win must be >= 1\")\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if x.size == 0:\n",
    "        return x.copy()\n",
    "    return (\n",
    "        pd.Series(x)\n",
    "        .rolling(window=int(win), center=True, min_periods=1)\n",
    "        .median()\n",
    "        .to_numpy(dtype=float)\n",
    "    )\n",
    "\n",
    "\n",
    "def slope_ls(t_s: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Least-squares slope of y(t) w.r.t. time t_s.\n",
    "    Returns slope in 'y-units per second'.\n",
    "    \"\"\"\n",
    "    t = np.asarray(t_s, dtype=float)\n",
    "    yy = np.asarray(y, dtype=float)\n",
    "    m = np.isfinite(t) & np.isfinite(yy)\n",
    "    t = t[m]\n",
    "    yy = yy[m]\n",
    "    if t.size < 2:\n",
    "        return 0.0\n",
    "    t0 = t - t.mean()\n",
    "    denom = float(np.dot(t0, t0))\n",
    "    if denom <= 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(t0, yy - yy.mean()) / denom)\n",
    "\n",
    "\n",
    "def slope_ls_abs(t_s: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"Absolute LS slope (convenience wrapper).\"\"\"\n",
    "    return abs(slope_ls(t_s, y))\n",
    "\n",
    "\n",
    "\n",
    "def compute_csi_modcsi_slope_jeppesen(\n",
    "    rr_s: np.ndarray,\n",
    "    *,\n",
    "    win_rr: int = 100,\n",
    "    ma7: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compute Jeppesen-style CSI / ModCSI / SlopeHR features in sliding RR windows.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    rr_s : array-like\n",
    "        RR intervals in **seconds**.\n",
    "\n",
    "    Key implementation details (validated in Study 5)\n",
    "    -------------------------------------------------\n",
    "    - CSI is scale-invariant, but ModCSI has units of RR. Therefore, SD1/SD2 are\n",
    "      computed on RR converted to **milliseconds** to match NeuroKit/LabVIEW scale.\n",
    "    - MA7 is implemented as a 7-sample *median filter* on the RR tachogram before\n",
    "      ModCSI and SlopeHR.\n",
    "    - SlopeHR is computed as the absolute least-squares slope of HR (bpm) versus\n",
    "      time (s) within each window, yielding units of bpm/s.\n",
    "    \"\"\"\n",
    "    rr = np.asarray(rr_s, dtype=float)\n",
    "    rr = rr[np.isfinite(rr)]\n",
    "    rr = rr[rr > 0]\n",
    "\n",
    "    if rr.size < win_rr + 2:\n",
    "        return pd.DataFrame(\n",
    "            columns=[\n",
    "                \"t_s\",\n",
    "                \"CSI100\",\n",
    "                \"ModCSI100_filt\",\n",
    "                \"SlopeHR100_abs_bpm_per_s\",\n",
    "                \"CSI100_x_SlopeHR\",\n",
    "                \"ModCSI100_filt_x_SlopeHR\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # --- MA7 median filter on RR (seconds) ---\n",
    "    rr_f = rr.copy()\n",
    "    if ma7:\n",
    "        rr_f = rr_f = median_prefilter_7(rr_f)\n",
    "\n",
    "    # Use raw cumulative time for alignment (seconds)\n",
    "    t_cum = np.cumsum(rr)\n",
    "\n",
    "    rows: list[dict] = []\n",
    "    n = rr.size\n",
    "    for i in range(win_rr - 1, n):\n",
    "        j0 = i - win_rr + 1\n",
    "        rr_win_raw = rr[j0 : i + 1]\n",
    "        rr_win_f = rr_f[j0 : i + 1]\n",
    "\n",
    "        # Convert to ms for Poincaré SDs (correct ModCSI magnitude)\n",
    "        rr_win_raw_ms = 1000.0 * rr_win_raw\n",
    "        rr_win_f_ms = 1000.0 * rr_win_f\n",
    "\n",
    "        sd1_raw, sd2_raw = poincare_sd1_sd2(rr_win_raw_ms)\n",
    "        sd1_f, sd2_f = poincare_sd1_sd2(rr_win_f_ms)\n",
    "\n",
    "        csi = csi_from_sd(sd1_raw, sd2_raw)      # dimensionless\n",
    "        modcsi = modcsi_from_sd(sd1_f, sd2_f)    # ms-scale\n",
    "\n",
    "        # SlopeHR on filtered RR (seconds) -> HR in bpm, slope in bpm/s\n",
    "        hr_win = 60.0 / rr_win_f\n",
    "        t_win = np.cumsum(rr_win_f)\n",
    "        slope_abs = float(slope_ls_abs(t_win, hr_win))\n",
    "\n",
    "        t_s = float(t_cum[i])\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"t_s\": t_s,\n",
    "                \"CSI100\": float(csi),\n",
    "                \"ModCSI100_filt\": float(modcsi),\n",
    "                \"SlopeHR100_abs_bpm_per_s\": slope_abs,\n",
    "                \"CSI100_x_SlopeHR\": float(csi) * slope_abs,\n",
    "                \"ModCSI100_filt_x_SlopeHR\": float(modcsi) * slope_abs,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "def map_points_to_windows(df_feat: pd.DataFrame, windows_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Map each feature point t_s to its Study4 window in windows_df for the same recording_uid.\n",
    "    windows_df must have: recording_uid, win_start_s, win_end_s, is_acceptable, window_overlaps_seizure.\n",
    "    \"\"\"\n",
    "    f = df_feat.copy()\n",
    "    w = windows_df[[\"recording_uid\", \"win_start_s\", \"win_end_s\", \"is_acceptable\", \"window_overlaps_seizure\"]].copy()\n",
    "\n",
    "    f[\"recording_uid\"] = pd.to_numeric(f[\"recording_uid\"], errors=\"coerce\")\n",
    "    f[\"t_s\"] = pd.to_numeric(f[\"t_s\"], errors=\"coerce\")\n",
    "    f = f.dropna(subset=[\"recording_uid\", \"t_s\"]).copy()\n",
    "    f[\"recording_uid\"] = f[\"recording_uid\"].astype(int)\n",
    "\n",
    "    w[\"recording_uid\"] = pd.to_numeric(w[\"recording_uid\"], errors=\"coerce\")\n",
    "    w[\"win_start_s\"] = pd.to_numeric(w[\"win_start_s\"], errors=\"coerce\")\n",
    "    w[\"win_end_s\"] = pd.to_numeric(w[\"win_end_s\"], errors=\"coerce\")\n",
    "    w = w.dropna(subset=[\"recording_uid\", \"win_start_s\", \"win_end_s\"]).copy()\n",
    "    w[\"recording_uid\"] = w[\"recording_uid\"].astype(int)\n",
    "\n",
    "    out_parts = []\n",
    "\n",
    "    for rid, g in f.groupby(\"recording_uid\", sort=False):\n",
    "        ww = w[w[\"recording_uid\"] == rid].copy()\n",
    "        if ww.empty:\n",
    "            continue\n",
    "\n",
    "        ww = ww.sort_values(\"win_start_s\", kind=\"mergesort\").reset_index(drop=True)\n",
    "        starts = ww[\"win_start_s\"].to_numpy(dtype=float)\n",
    "        ends = ww[\"win_end_s\"].to_numpy(dtype=float)\n",
    "\n",
    "        t = g[\"t_s\"].to_numpy(dtype=float)\n",
    "        idx = np.searchsorted(starts, t, side=\"right\") - 1\n",
    "        ok = (idx >= 0) & (t < ends[np.clip(idx, 0, len(ends) - 1)])\n",
    "        if not np.any(ok):\n",
    "            continue\n",
    "\n",
    "        gg = g.iloc[np.where(ok)[0]].copy()\n",
    "        idx_ok = idx[ok]\n",
    "\n",
    "        gg[\"win_start_s\"] = starts[idx_ok]\n",
    "        gg[\"win_end_s\"] = ends[idx_ok]\n",
    "        gg[\"is_acceptable\"] = ww[\"is_acceptable\"].to_numpy()[idx_ok]\n",
    "        gg[\"window_overlaps_seizure\"] = ww[\"window_overlaps_seizure\"].to_numpy()[idx_ok]\n",
    "\n",
    "        gg[\"group\"] = np.where(gg[\"window_overlaps_seizure\"], \"seizure\", \"baseline\")\n",
    "        gg[\"q\"] = np.where(gg[\"is_acceptable\"], \"accepted\", \"rejected\")\n",
    "\n",
    "        out_parts.append(gg)\n",
    "\n",
    "    if not out_parts:\n",
    "        return pd.DataFrame(\n",
    "            columns=list(df_feat.columns)\n",
    "            + [\"win_start_s\", \"win_end_s\", \"is_acceptable\", \"window_overlaps_seizure\", \"group\", \"q\"]\n",
    "        )\n",
    "\n",
    "    return pd.concat(out_parts, ignore_index=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Build df_feat from rr_aligned folder\n",
    "# ============================================================\n",
    "\n",
    "def build_features_from_rr_folder(\n",
    "    rr_dir: Path,\n",
    "    *,\n",
    "    df_rec_index: pd.DataFrame,\n",
    "    windows_df: pd.DataFrame,\n",
    "    thr_map_modcsi: Dict[int, float],\n",
    "    thr_map_csi: Dict[int, float],\n",
    "    rr_source: str,                          # \"labview\" or \"python\"\n",
    "    rr_col: str,                             # \"RR_labview_s\" or \"RR_python_s\"\n",
    "    algo_keep: Optional[set] = None,\n",
    "    recording_uid_keep: Optional[set] = None,\n",
    "    set_label: str = \"trim\",\n",
    "    win_rr: int = 100,\n",
    "    rr_min_s: float = 0.25,\n",
    "    rr_max_s: float = 2.5,\n",
    ") -> pd.DataFrame:\n",
    "    rows: List[pd.DataFrame] = []\n",
    "\n",
    "    for p in sorted(rr_dir.glob(\"*.csv\")):\n",
    "        meta = parse_rr_filename(p)\n",
    "        algo_id = meta[\"algo_id\"]\n",
    "\n",
    "        if algo_keep is not None and algo_id not in algo_keep:\n",
    "            continue\n",
    "\n",
    "        rid = lookup_recording_uid(meta, df_rec_index)\n",
    "        if recording_uid_keep is not None and rid not in recording_uid_keep:\n",
    "            continue\n",
    "\n",
    "        pid = int(meta[\"patient_number\"])\n",
    "        thr_mod = float(thr_map_modcsi.get(pid, np.nan))\n",
    "        thr_csi = float(thr_map_csi.get(pid, np.nan))\n",
    "\n",
    "        df_rr = pd.read_csv(p)\n",
    "        if rr_col not in df_rr.columns:\n",
    "            continue\n",
    "\n",
    "        rr_s = pd.to_numeric(df_rr[rr_col], errors=\"coerce\").to_numpy(dtype=float)\n",
    "        rr_s = clean_rr(rr_s, min_s=rr_min_s, max_s=rr_max_s)\n",
    "        if rr_s.size < win_rr:\n",
    "            continue\n",
    "\n",
    "        feat = compute_csi_modcsi_slope_jeppesen(rr_s, win_rr=win_rr)\n",
    "        if feat.empty:\n",
    "            continue\n",
    "\n",
    "        feat[\"recording_uid\"] = int(rid)\n",
    "        feat[\"patient_id\"] = int(pid)\n",
    "        feat[\"algo_id\"] = str(algo_id)\n",
    "        feat[\"rr_source\"] = str(rr_source)\n",
    "        feat[\"set\"] = str(set_label)\n",
    "        feat[\"win_rr\"] = int(win_rr)\n",
    "\n",
    "        feat[\"thr_modcsi\"] = thr_mod\n",
    "        feat[\"thr_csi\"] = thr_csi\n",
    "\n",
    "        feat = map_points_to_windows(feat, windows_df)\n",
    "        rows.append(feat)\n",
    "\n",
    "    out = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()\n",
    "\n",
    "    # Hard guard: ensure expected final columns exist\n",
    "    required = {\n",
    "        \"recording_uid\", \"patient_id\", \"t_s\",\n",
    "        \"CSI100_x_SlopeHR\", \"ModCSI100_filt_x_SlopeHR\",\n",
    "        \"thr_csi\", \"thr_modcsi\",\n",
    "        \"win_start_s\", \"win_end_s\", \"is_acceptable\", \"window_overlaps_seizure\"\n",
    "    }\n",
    "    if not out.empty:\n",
    "        miss = required - set(out.columns)\n",
    "        if miss:\n",
    "            raise RuntimeError(f\"Feature build missing required columns: {miss}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Event-based scoring\n",
    "# ============================================================\n",
    "\n",
    "def _extract_events_from_series(t: np.ndarray, x: np.ndarray, *, gap_s: float) -> list[dict]:\n",
    "    if t.size == 0:\n",
    "        return []\n",
    "    dt = np.diff(t)\n",
    "    splits = np.where(dt > gap_s)[0] + 1\n",
    "    groups = np.split(np.arange(t.size), splits)\n",
    "\n",
    "    events = []\n",
    "    for idx in groups:\n",
    "        tt = t[idx]\n",
    "        xx = x[idx]\n",
    "        k = int(np.argmax(xx))\n",
    "        events.append(\n",
    "            {\n",
    "                \"t_start\": float(tt[0]),\n",
    "                \"t_end\": float(tt[-1]),\n",
    "                \"duration_s\": float(tt[-1] - tt[0]),\n",
    "                \"t_peak\": float(tt[k]),\n",
    "                \"peak_value\": float(xx[k]),\n",
    "                \"n_points\": int(len(idx)),\n",
    "            }\n",
    "        )\n",
    "    return events\n",
    "\n",
    "\n",
    "def build_event_list(\n",
    "    df_feat: pd.DataFrame,\n",
    "    *,\n",
    "    value_col: str,\n",
    "    thr_col: str,\n",
    "    time_col: str = \"t_s\",\n",
    "    gap_s: float = 180.0,\n",
    ") -> pd.DataFrame:\n",
    "    need = {\"recording_uid\", time_col, value_col, thr_col}\n",
    "    miss = need - set(df_feat.columns)\n",
    "    if miss:\n",
    "        raise KeyError(f\"df_feat missing columns: {miss}\")\n",
    "\n",
    "    df = df_feat.copy()\n",
    "    df[\"recording_uid\"] = pd.to_numeric(df[\"recording_uid\"], errors=\"coerce\")\n",
    "    df[time_col] = pd.to_numeric(df[time_col], errors=\"coerce\")\n",
    "    df[value_col] = pd.to_numeric(df[value_col], errors=\"coerce\")\n",
    "    df[thr_col] = pd.to_numeric(df[thr_col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"recording_uid\", time_col, value_col, thr_col]).copy()\n",
    "    df[\"recording_uid\"] = df[\"recording_uid\"].astype(int)\n",
    "\n",
    "    out = []\n",
    "    for rid, g in df.groupby(\"recording_uid\", sort=False):\n",
    "        thr = float(g[thr_col].iloc[0])\n",
    "        gg = g[g[value_col] > thr].sort_values(time_col, kind=\"mergesort\")\n",
    "        if gg.empty:\n",
    "            continue\n",
    "\n",
    "        t = gg[time_col].to_numpy(dtype=float)\n",
    "        x = gg[value_col].to_numpy(dtype=float)\n",
    "\n",
    "        for e in _extract_events_from_series(t, x, gap_s=gap_s):\n",
    "            out.append({\"recording_uid\": int(rid), **e})\n",
    "\n",
    "    return pd.DataFrame(out) if out else pd.DataFrame(\n",
    "        columns=[\"recording_uid\", \"t_start\", \"t_end\", \"duration_s\", \"t_peak\", \"peak_value\", \"n_points\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def analyzable_hours_from_windows(df_feat: pd.DataFrame, *, use_sqi: bool) -> float:\n",
    "    need = {\"recording_uid\", \"win_start_s\", \"win_end_s\", \"is_acceptable\"}\n",
    "    miss = need - set(df_feat.columns)\n",
    "    if miss:\n",
    "        raise KeyError(f\"df_feat missing columns for time accounting: {miss}\")\n",
    "\n",
    "    w = df_feat[[\"recording_uid\", \"win_start_s\", \"win_end_s\", \"is_acceptable\"]].drop_duplicates().copy()\n",
    "    w[\"recording_uid\"] = pd.to_numeric(w[\"recording_uid\"], errors=\"coerce\")\n",
    "    w[\"win_start_s\"] = pd.to_numeric(w[\"win_start_s\"], errors=\"coerce\")\n",
    "    w[\"win_end_s\"] = pd.to_numeric(w[\"win_end_s\"], errors=\"coerce\")\n",
    "    w = w.dropna(subset=[\"recording_uid\", \"win_start_s\", \"win_end_s\"]).copy()\n",
    "    w[\"recording_uid\"] = w[\"recording_uid\"].astype(int)\n",
    "\n",
    "    if use_sqi:\n",
    "        w = w[w[\"is_acceptable\"].astype(bool)]\n",
    "\n",
    "    dur_s = (w[\"win_end_s\"] - w[\"win_start_s\"]).clip(lower=0).sum()\n",
    "    return float(dur_s / 3600.0)\n",
    "\n",
    "\n",
    "def score_pipeline_events(\n",
    "    df_feat: pd.DataFrame,\n",
    "    df_seiz: pd.DataFrame,\n",
    "    *,\n",
    "    value_col: str,\n",
    "    thr_col: str,\n",
    "    time_col: str = \"t_s\",\n",
    "    t0_col: str = \"t0_clinical\",\n",
    "    t1_col: str = \"t1_clinical\",\n",
    "    pad_s: float = 300.0,\n",
    "    gap_s: float = 180.0,\n",
    "    use_sqi: bool = False,\n",
    ") -> dict:\n",
    "    feat = df_feat.copy()\n",
    "    if use_sqi:\n",
    "        feat = feat[feat[\"is_acceptable\"].astype(bool)].copy()\n",
    "\n",
    "    used_rids = (\n",
    "        pd.to_numeric(feat[\"recording_uid\"], errors=\"coerce\")\n",
    "        .dropna()\n",
    "        .astype(int)\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    total_h = analyzable_hours_from_windows(df_feat, use_sqi=use_sqi)\n",
    "\n",
    "    seiz = df_seiz.copy()\n",
    "    for c in [\"recording_uid\", t0_col, t1_col]:\n",
    "        if c not in seiz.columns:\n",
    "            raise KeyError(f\"df_seiz missing column: {c}\")\n",
    "\n",
    "    seiz[\"recording_uid\"] = pd.to_numeric(seiz[\"recording_uid\"], errors=\"coerce\")\n",
    "    seiz[t0_col] = pd.to_numeric(seiz[t0_col], errors=\"coerce\")\n",
    "    seiz[t1_col] = pd.to_numeric(seiz[t1_col], errors=\"coerce\")\n",
    "    seiz_raw = seiz.dropna(subset=[\"recording_uid\"]).copy()\n",
    "    seiz_raw[\"recording_uid\"] = seiz_raw[\"recording_uid\"].astype(int)\n",
    "    n_seiz_in_used_recordings_raw = int(seiz_raw[seiz_raw[\"recording_uid\"].isin(used_rids)].shape[0])\n",
    "\n",
    "    seiz = seiz.dropna(subset=[\"recording_uid\", t0_col, t1_col]).copy()\n",
    "    seiz[\"recording_uid\"] = seiz[\"recording_uid\"].astype(int)\n",
    "    n_seiz_total_defined = int(len(seiz))\n",
    "    n_seiz_total_used_defined = int(seiz[seiz[\"recording_uid\"].isin(used_rids)].shape[0])\n",
    "\n",
    "    df_events = build_event_list(\n",
    "        feat,\n",
    "        value_col=value_col,\n",
    "        thr_col=thr_col,\n",
    "        time_col=time_col,\n",
    "        gap_s=gap_s,\n",
    "    )\n",
    "\n",
    "    if df_events.empty:\n",
    "        return dict(\n",
    "            n_seiz_in_used_recordings_raw=n_seiz_in_used_recordings_raw,\n",
    "            n_seiz_total=n_seiz_total_defined,\n",
    "            n_seiz_total_used=n_seiz_total_used_defined,\n",
    "            n_seiz_detected=0,\n",
    "            recall_total=(0.0 if n_seiz_total_defined else np.nan),\n",
    "            recall_used=(0.0 if n_seiz_total_used_defined else np.nan),\n",
    "            FP_events=0,\n",
    "            FAR_per_h=(0.0 if total_h > 0 else np.nan),\n",
    "            total_h=float(total_h),\n",
    "            n_events=0,\n",
    "            n_recordings_used=int(len(used_rids)),\n",
    "        )\n",
    "\n",
    "    detected = 0\n",
    "    fp_events = 0\n",
    "\n",
    "    for rid, ev in df_events.groupby(\"recording_uid\", sort=False):\n",
    "        seiz_r = seiz[seiz[\"recording_uid\"] == int(rid)]\n",
    "\n",
    "        intervals = []\n",
    "        if not seiz_r.empty:\n",
    "            t0s = seiz_r[t0_col].to_numpy(dtype=float) - pad_s\n",
    "            t1s = seiz_r[t1_col].to_numpy(dtype=float) + pad_s\n",
    "            intervals = list(zip(t0s, t1s))\n",
    "\n",
    "        if intervals:\n",
    "            for _, s in seiz_r.iterrows():\n",
    "                a = float(s[t0_col]) - pad_s\n",
    "                b = float(s[t1_col]) + pad_s\n",
    "                hit = ((ev[\"t_end\"] >= a) & (ev[\"t_start\"] <= b)).any()\n",
    "                detected += int(hit)\n",
    "\n",
    "        if intervals:\n",
    "            e_start = ev[\"t_start\"].to_numpy(dtype=float)\n",
    "            e_end = ev[\"t_end\"].to_numpy(dtype=float)\n",
    "            inside_any = np.zeros(len(ev), dtype=bool)\n",
    "            for (a, b) in intervals:\n",
    "                inside_any |= (e_end >= a) & (e_start <= b)\n",
    "            fp_events += int((~inside_any).sum())\n",
    "        else:\n",
    "            fp_events += int(len(ev))\n",
    "\n",
    "    recall_total = detected / n_seiz_total_defined if n_seiz_total_defined else np.nan\n",
    "    recall_used = detected / n_seiz_total_used_defined if n_seiz_total_used_defined else np.nan\n",
    "    far = fp_events / total_h if total_h > 0 else np.nan\n",
    "\n",
    "    return dict(\n",
    "        n_seiz_in_used_recordings_raw=n_seiz_in_used_recordings_raw,\n",
    "        n_seiz_total=n_seiz_total_defined,\n",
    "        n_seiz_total_used=n_seiz_total_used_defined,\n",
    "        n_seiz_detected=int(detected),\n",
    "        recall_total=float(recall_total) if np.isfinite(recall_total) else recall_total,\n",
    "        recall_used=float(recall_used) if np.isfinite(recall_used) else recall_used,\n",
    "        FP_events=int(fp_events),\n",
    "        FAR_per_h=float(far) if np.isfinite(far) else far,\n",
    "        total_h=float(total_h),\n",
    "        n_events=int(len(df_events)),\n",
    "        n_recordings_used=int(len(used_rids)),\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Table builders (overall + responder split)\n",
    "# ============================================================\n",
    "\n",
    "def add_responder_label(df: pd.DataFrame, responders: list[int], *, pid_col: str = \"patient_id\") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[pid_col] = pd.to_numeric(out[pid_col], errors=\"coerce\")\n",
    "    out[\"is_responder\"] = out[pid_col].astype(\"Int64\").isin(list(map(int, responders)))\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_event_main_table(\n",
    "    df_feat5: pd.DataFrame,\n",
    "    df_seiz: pd.DataFrame,\n",
    "    *,\n",
    "    value_col: str,\n",
    "    thr_col: str,\n",
    "    rr_sources: tuple[str, ...] = (\"labview\", \"python\"),\n",
    "    collapse_labview_algo: bool = True,\n",
    "    pad_s: float = 300.0,\n",
    "    gap_s: float = 180.0,\n",
    ") -> pd.DataFrame:\n",
    "    need = {\n",
    "        \"rr_source\", \"algo_id\", \"recording_uid\",\n",
    "        \"win_start_s\", \"win_end_s\", \"is_acceptable\", \"window_overlaps_seizure\",\n",
    "        \"t_s\", value_col, thr_col\n",
    "    }\n",
    "    miss = need - set(df_feat5.columns)\n",
    "    if miss:\n",
    "        raise KeyError(f\"df_feat5 missing columns: {miss}\")\n",
    "\n",
    "    rows = []\n",
    "    for rr_src in rr_sources:\n",
    "        sub = df_feat5[df_feat5[\"rr_source\"] == rr_src].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        if rr_src == \"labview\" and collapse_labview_algo:\n",
    "            sub = sub.copy()\n",
    "            sub[\"algo_id\"] = \"LabVIEW\"\n",
    "\n",
    "        for algo, g in sub.groupby(\"algo_id\", sort=False):\n",
    "            for use_sqi in [False, True]:\n",
    "                res = score_pipeline_events(\n",
    "                    g, df_seiz,\n",
    "                    value_col=value_col,\n",
    "                    thr_col=thr_col,\n",
    "                    time_col=\"t_s\",\n",
    "                    t0_col=\"t0_clinical\",\n",
    "                    t1_col=\"t1_clinical\",\n",
    "                    pad_s=pad_s,\n",
    "                    gap_s=gap_s,\n",
    "                    use_sqi=use_sqi,\n",
    "                )\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"RR_source\": (\"LabVIEW\" if rr_src == \"labview\" else \"Python\"),\n",
    "                        \"Algorithm\": (\"—\" if (rr_src == \"labview\" and collapse_labview_algo) else str(algo)),\n",
    "                        \"SQI\": (\"on\" if use_sqi else \"off\"),\n",
    "                        **res,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    if not df_out.empty:\n",
    "        df_out = df_out.sort_values([\"RR_source\", \"Algorithm\", \"SQI\"]).reset_index(drop=True)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def build_event_tables_with_responder_split(\n",
    "    df_feat5: pd.DataFrame,\n",
    "    df_seiz: pd.DataFrame,\n",
    "    responders: list[int],\n",
    "    *,\n",
    "    value_col: str,\n",
    "    thr_col: str,\n",
    "    pad_s: float = 300.0,\n",
    "    gap_s: float = 180.0,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df_main = build_event_main_table(\n",
    "        df_feat5, df_seiz,\n",
    "        value_col=value_col,\n",
    "        thr_col=thr_col,\n",
    "        collapse_labview_algo=True,\n",
    "        pad_s=pad_s,\n",
    "        gap_s=gap_s,\n",
    "    )\n",
    "\n",
    "    feat2 = add_responder_label(df_feat5, responders)\n",
    "    seiz2 = add_responder_label(df_seiz, responders)\n",
    "\n",
    "    parts = []\n",
    "    for grp, gfeat in feat2.groupby(\"is_responder\", sort=False):\n",
    "        gseiz = seiz2[seiz2[\"is_responder\"] == grp].copy()\n",
    "        tab = build_event_main_table(\n",
    "            gfeat, gseiz,\n",
    "            value_col=value_col,\n",
    "            thr_col=thr_col,\n",
    "            collapse_labview_algo=True,\n",
    "            pad_s=pad_s,\n",
    "            gap_s=gap_s,\n",
    "        )\n",
    "        tab.insert(0, \"is_responder\", bool(grp))\n",
    "        parts.append(tab)\n",
    "\n",
    "    df_split = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()\n",
    "    return df_main, df_split\n",
    "\n",
    "# ===========================================================\n",
    "# 5.1) Threshold validation helper\n",
    "# ===========================================================\n",
    "def _intervals_overlap(a0: float, a1: float, b0: float, b1: float) -> bool:\n",
    "    return (a1 >= b0) and (a0 <= b1)\n",
    "\n",
    "\n",
    "def _segment_has_seizure(\n",
    "    seiz: pd.DataFrame,\n",
    "    rid: int,\n",
    "    seg_start: float,\n",
    "    seg_end: float,\n",
    "    *,\n",
    "    t0_col: str = \"t0_clinical\",\n",
    "    t1_col: str = \"t1_clinical\",\n",
    ") -> bool:\n",
    "    s = seiz[seiz[\"recording_uid\"] == rid]\n",
    "    if s.empty:\n",
    "        return False\n",
    "    t0 = s[t0_col].to_numpy(dtype=float)\n",
    "    t1 = s[t1_col].to_numpy(dtype=float)\n",
    "    for a, b in zip(t0, t1):\n",
    "        if _intervals_overlap(seg_start, seg_end, float(a), float(b)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def build_auto_thresholds_105pct(\n",
    "    df_feat5: pd.DataFrame,\n",
    "    df_seiz: pd.DataFrame,\n",
    "    *,\n",
    "    value_col: str,\n",
    "    patient_col: str = \"patient_id\",\n",
    "    rid_col: str = \"recording_uid\",\n",
    "    time_col: str = \"t_s\",\n",
    "    factor: float = 1.05,\n",
    "    # candidate baseline segments (seconds)\n",
    "    segs_s: tuple[tuple[str, float], ...] = ((\"first_24h\", 24*3600), (\"first_12h\", 12*3600)),\n",
    "    allow_half_fallback: bool = True,\n",
    "    # Optional: restrict baseline to SQI-acceptable windows only\n",
    "    use_sqi_for_threshold: bool = True,\n",
    "    # Fallback maps (from Excel) if no seizure-free segment exists\n",
    "    fallback_thr_map: Optional[dict[int, float]] = None,\n",
    ") -> tuple[dict[int, float], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Build patient-specific thresholds as 1.05 * max(value_col) in a seizure-free baseline segment.\n",
    "\n",
    "    Returns:\n",
    "      thr_map_auto: patient_id -> threshold\n",
    "      thr_meta: per-patient details about segment used and max values\n",
    "    \"\"\"\n",
    "    req = {patient_col, rid_col, time_col, value_col}\n",
    "    miss = req - set(df_feat5.columns)\n",
    "    if miss:\n",
    "        raise KeyError(f\"df_feat5 missing required columns for auto-threshold: {miss}\")\n",
    "\n",
    "    seiz = df_seiz.copy()\n",
    "    seiz[\"recording_uid\"] = pd.to_numeric(seiz[\"recording_uid\"], errors=\"coerce\")\n",
    "    seiz[\"t0_clinical\"] = pd.to_numeric(seiz[\"t0_clinical\"], errors=\"coerce\")\n",
    "    seiz[\"t1_clinical\"] = pd.to_numeric(seiz[\"t1_clinical\"], errors=\"coerce\")\n",
    "    seiz = seiz.dropna(subset=[\"recording_uid\", \"t0_clinical\", \"t1_clinical\"]).copy()\n",
    "    seiz[\"recording_uid\"] = seiz[\"recording_uid\"].astype(int)\n",
    "\n",
    "    df = df_feat5.copy()\n",
    "    df[patient_col] = pd.to_numeric(df[patient_col], errors=\"coerce\")\n",
    "    df[rid_col] = pd.to_numeric(df[rid_col], errors=\"coerce\")\n",
    "    df[time_col] = pd.to_numeric(df[time_col], errors=\"coerce\")\n",
    "    df[value_col] = pd.to_numeric(df[value_col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[patient_col, rid_col, time_col, value_col]).copy()\n",
    "    df[patient_col] = df[patient_col].astype(int)\n",
    "    df[rid_col] = df[rid_col].astype(int)\n",
    "\n",
    "    if use_sqi_for_threshold:\n",
    "        if \"is_acceptable\" not in df.columns:\n",
    "            raise KeyError(\"use_sqi_for_threshold=True requires df_feat5['is_acceptable']\")\n",
    "        df = df[df[\"is_acceptable\"].astype(bool)].copy()\n",
    "\n",
    "    thr_map: dict[int, float] = {}\n",
    "    meta_rows: list[dict] = []\n",
    "\n",
    "    # auto-thresholds must be computed per patient, but seizures live per recording.\n",
    "    for pid, gpid in df.groupby(patient_col, sort=False):\n",
    "        # use all recordings for this patient in gpid\n",
    "        rids = sorted(gpid[rid_col].unique().tolist())\n",
    "\n",
    "        best = None  # (mode, rid, seg_start, seg_end, maxv)\n",
    "\n",
    "        # try fixed segments first\n",
    "        for mode, seg_end in segs_s:\n",
    "            for rid in rids:\n",
    "                seg_start = 0.0\n",
    "                # check seizure-free\n",
    "                if _segment_has_seizure(seiz, rid, seg_start, seg_end):\n",
    "                    continue\n",
    "                gg = gpid[(gpid[rid_col] == rid) & (gpid[time_col] >= seg_start) & (gpid[time_col] <= seg_end)]\n",
    "                if gg.empty:\n",
    "                    continue\n",
    "                maxv = float(gg[value_col].max())\n",
    "                if not np.isfinite(maxv):\n",
    "                    continue\n",
    "                if (best is None) or (maxv > best[4]):\n",
    "                    best = (mode, rid, seg_start, seg_end, maxv)\n",
    "\n",
    "        # half-recording fallback\n",
    "        if best is None and allow_half_fallback:\n",
    "            for rid in rids:\n",
    "                gg_all = gpid[gpid[rid_col] == rid]\n",
    "                if gg_all.empty:\n",
    "                    continue\n",
    "                tmax = float(gg_all[time_col].max())\n",
    "                seg_start = 0.0\n",
    "                seg_end = 0.5 * tmax\n",
    "                if _segment_has_seizure(seiz, rid, seg_start, seg_end):\n",
    "                    continue\n",
    "                gg = gg_all[(gg_all[time_col] >= seg_start) & (gg_all[time_col] <= seg_end)]\n",
    "                if gg.empty:\n",
    "                    continue\n",
    "                maxv = float(gg[value_col].max())\n",
    "                if not np.isfinite(maxv):\n",
    "                    continue\n",
    "                best = (\"first_half\", rid, seg_start, seg_end, maxv)\n",
    "                break\n",
    "\n",
    "        # decide threshold\n",
    "        if best is not None:\n",
    "            mode, rid, seg_start, seg_end, maxv = best\n",
    "            thr = float(factor * maxv)\n",
    "            thr_map[int(pid)] = thr\n",
    "            meta_rows.append({\n",
    "                \"patient_id\": int(pid),\n",
    "                \"mode_used\": mode,\n",
    "                \"recording_uid_used\": int(rid),\n",
    "                \"segment_start_s\": float(seg_start),\n",
    "                \"segment_end_s\": float(seg_end),\n",
    "                \"max_value_in_segment\": float(maxv),\n",
    "                \"factor\": float(factor),\n",
    "                \"threshold\": float(thr),\n",
    "                \"fallback_used\": False,\n",
    "            })\n",
    "        else:\n",
    "            thr_fb = None\n",
    "            if fallback_thr_map is not None:\n",
    "                thr_fb = fallback_thr_map.get(int(pid), None)\n",
    "\n",
    "            thr_map[int(pid)] = float(thr_fb) if thr_fb is not None else np.nan\n",
    "            meta_rows.append({\n",
    "                \"patient_id\": int(pid),\n",
    "                \"mode_used\": \"fallback_excel\" if thr_fb is not None else \"no_threshold\",\n",
    "                \"recording_uid_used\": np.nan,\n",
    "                \"segment_start_s\": np.nan,\n",
    "                \"segment_end_s\": np.nan,\n",
    "                \"max_value_in_segment\": np.nan,\n",
    "                \"factor\": float(factor),\n",
    "                \"threshold\": float(thr_map[int(pid)]) if np.isfinite(thr_map[int(pid)]) else np.nan,\n",
    "                \"fallback_used\": True,\n",
    "            })\n",
    "\n",
    "    thr_meta = pd.DataFrame(meta_rows).sort_values(\"patient_id\").reset_index(drop=True)\n",
    "    return thr_map, thr_meta\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Minimal \"main\" (edit paths + run)\n",
    "# ============================================================\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Study5Paths:\n",
    "    rr_dir: Path\n",
    "    recordings_index_csv: Path\n",
    "    seizure_events_csv: Path\n",
    "    window_quality_csv: Path\n",
    "    threshold_xlsx: Path\n",
    "\n",
    "\n",
    "def run_study5(\n",
    "    paths: Study5Paths,\n",
    "    *,\n",
    "    algo_keep: Optional[set] = None,\n",
    "    recording_uid_keep: Optional[set] = None,\n",
    "    win_rr: int = 100,\n",
    "    pad_s: float = 300.0,\n",
    "    gap_s: float = 180.0,\n",
    "    responders: Optional[list[int]] = None,\n",
    "    value_mode: str = \"modcsi\",  # \"modcsi\" or \"csi\"\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      df_feat5  : features for all rr_source/algo\n",
    "      df_main   : overall main table\n",
    "      df_split  : responder split table (empty if responders=None)\n",
    "    \"\"\"\n",
    "    df_rec = pd.read_csv(paths.recordings_index_csv)\n",
    "    df_seiz = load_df_seiz(paths.seizure_events_csv)\n",
    "    windows_df = make_windows_df_from_sqi_and_seiz(paths.window_quality_csv, df_seiz)\n",
    "    thr_map_modcsi, thr_map_csi = load_thr_maps_from_excel(paths.threshold_xlsx)\n",
    "\n",
    "    # Build features for LabVIEW RR stream (uses RR_labview_s)\n",
    "    feat_lab = build_features_from_rr_folder(\n",
    "        paths.rr_dir,\n",
    "        df_rec_index=df_rec,\n",
    "        windows_df=windows_df,\n",
    "        thr_map_modcsi=thr_map_modcsi,\n",
    "        thr_map_csi=thr_map_csi,\n",
    "        rr_source=\"labview\",\n",
    "        rr_col=\"RR_labview_s\",\n",
    "        algo_keep=algo_keep,\n",
    "        recording_uid_keep=recording_uid_keep,\n",
    "        win_rr=win_rr,\n",
    "    )\n",
    "\n",
    "    # Build features for Python RR stream (uses RR_python_s)\n",
    "    feat_py = build_features_from_rr_folder(\n",
    "        paths.rr_dir,\n",
    "        df_rec_index=df_rec,\n",
    "        windows_df=windows_df,\n",
    "        thr_map_modcsi=thr_map_modcsi,\n",
    "        thr_map_csi=thr_map_csi,\n",
    "        rr_source=\"python\",\n",
    "        rr_col=\"RR_python_s\",\n",
    "        algo_keep=algo_keep,\n",
    "        recording_uid_keep=recording_uid_keep,\n",
    "        win_rr=win_rr,\n",
    "    )\n",
    "\n",
    "    df_feat5 = pd.concat([feat_lab, feat_py], ignore_index=True)\n",
    "\n",
    "    # --- AUTO thresholds (105% of max in seizure-free baseline segment) ---\n",
    "    # We compute separately for ModCSI×SlopeHR and CSI×SlopeHR\n",
    "    thr_map_auto_modcsi, thr_meta_modcsi = build_auto_thresholds_105pct(\n",
    "        df_feat5,\n",
    "        df_seiz,\n",
    "        value_col=\"ModCSI100_filt_x_SlopeHR\",\n",
    "        factor=1.05,\n",
    "        segs_s=((\"first_24h\", 24*3600), (\"first_12h\", 12*3600)),\n",
    "        allow_half_fallback=True,\n",
    "        use_sqi_for_threshold=True,\n",
    "        fallback_thr_map=thr_map_modcsi,  # excel fallback\n",
    "    )\n",
    "\n",
    "    thr_map_auto_csi, thr_meta_csi = build_auto_thresholds_105pct(\n",
    "        df_feat5,\n",
    "        df_seiz,\n",
    "        value_col=\"CSI100_x_SlopeHR\",\n",
    "        factor=1.05,\n",
    "        segs_s=((\"first_24h\", 24*3600), (\"first_12h\", 12*3600)),\n",
    "        allow_half_fallback=True,\n",
    "        use_sqi_for_threshold=True,\n",
    "        fallback_thr_map=thr_map_csi,      # excel fallback\n",
    "    )\n",
    "\n",
    "    # write auto-thresholds into df_feat5 (these are what scoring will use)\n",
    "    df_feat5[\"thr_modcsi\"] = df_feat5[\"patient_id\"].map(thr_map_auto_modcsi)\n",
    "    df_feat5[\"thr_csi\"] = df_feat5[\"patient_id\"].map(thr_map_auto_csi)\n",
    "\n",
    "\n",
    "    if value_mode.lower() == \"modcsi\":\n",
    "        value_col = \"ModCSI100_filt_x_SlopeHR\"\n",
    "        thr_col = \"thr_modcsi\"\n",
    "    elif value_mode.lower() == \"csi\":\n",
    "        value_col = \"CSI100_x_SlopeHR\"\n",
    "        thr_col = \"thr_csi\"\n",
    "    else:\n",
    "        raise ValueError(\"value_mode must be 'modcsi' or 'csi'\")\n",
    "\n",
    "    df_main = build_event_main_table(\n",
    "        df_feat5,\n",
    "        df_seiz,\n",
    "        value_col=value_col,\n",
    "        thr_col=thr_col,\n",
    "        pad_s=pad_s,\n",
    "        gap_s=gap_s,\n",
    "        collapse_labview_algo=True,\n",
    "    )\n",
    "\n",
    "    if responders:\n",
    "        df_main2, df_split = build_event_tables_with_responder_split(\n",
    "            df_feat5,\n",
    "            df_seiz,\n",
    "            responders,\n",
    "            value_col=value_col,\n",
    "            thr_col=thr_col,\n",
    "            pad_s=pad_s,\n",
    "            gap_s=gap_s,\n",
    "        )\n",
    "        # # df_main2 should match df_main; return df_main2 for consistency\n",
    "        # return df_feat5, df_main2, df_split\n",
    "\n",
    "    return df_feat5, df_main, df_split, thr_meta_modcsi, thr_meta_csi\n",
    "\n",
    "# Extra function\n",
    "def pick_seizure_time_cols(df_evt: pd.DataFrame, *, axis: str = \"trim\", prefer: str = \"clinical\"):\n",
    "    \"\"\"\n",
    "    axis: \"trim\" or \"raw\"\n",
    "    prefer: \"clinical\" or \"video\" or \"any\"\n",
    "    Returns (t0_col, t1_col) that exist in df_evt.\n",
    "    \"\"\"\n",
    "    suffix = \"_trim\" if axis == \"trim\" else \"\"\n",
    "    candidates = []\n",
    "\n",
    "    if prefer == \"clinical\":\n",
    "        candidates += [(f\"t0_clinical{suffix}\", f\"t1_clinical{suffix}\")]\n",
    "    if prefer == \"video\":\n",
    "        candidates += [(f\"t0_video{suffix}\", f\"t1_video{suffix}\")]\n",
    "    # fallback to generic\n",
    "    candidates += [(f\"t0{suffix}\", f\"t1{suffix}\")]\n",
    "\n",
    "    for a, b in candidates:\n",
    "        if a in df_evt.columns and b in df_evt.columns:\n",
    "            return a, b\n",
    "\n",
    "    raise KeyError(f\"No valid seizure time columns for axis={axis}. Tried: {candidates}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa17512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recording_uid', 'patient_id', 'recording_id', 'window_idx', 'win_start_s', 'win_end_s', 'context', 'std', 'range', 'diff_abs_med', 'is_flatline', 'is_noiseburst', 'is_clipping']\n"
     ]
    }
   ],
   "source": [
    "# SeizureTimeAxis = Literal[\"clinical\", \"video\", \"default\"]\n",
    "DATASTRUCT_ROOT = Path(r\"E:\\Speciale - Results\\Datastruct\")\n",
    "MAIN_DATA_ROOT  = Path(r\"E:\\Speciale - Results\")\n",
    "STUDY2_ROOT     = Path(MAIN_DATA_ROOT / \"study2\")\n",
    "STUDY3_ROOT     = Path(MAIN_DATA_ROOT / \"study3\")\n",
    "STUDY4_ROOT     = Path(MAIN_DATA_ROOT / \"study4\")\n",
    "\n",
    "PATH_REC = DATASTRUCT_ROOT / \"recordings_index.csv\"\n",
    "PATH_SEIZURE = DATASTRUCT_ROOT / \"seizure_events.csv\"\n",
    "PATH_WINDOW_QUALITY = STUDY2_ROOT / \"window_quality_baseline_vs_seizure.csv\"\n",
    "\n",
    "# hvor du evt. vil gemme mellem- og slutresultater til Study4\n",
    "STUDY4_OUT = Path(MAIN_DATA_ROOT  / \"study4\")\n",
    "STUDY4_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "STUDY5_OUT = Path(MAIN_DATA_ROOT  / \"study5\")\n",
    "STUDY5_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# %%\n",
    "paths = Study5Paths(\n",
    "        rr_dir=Path(MAIN_DATA_ROOT / \"Final_RR_alignment\" / \"Test_aligned_rr_Trim\"),\n",
    "        recordings_index_csv=Path(DATASTRUCT_ROOT / \"recordings_index.csv\"),\n",
    "        seizure_events_csv=Path(DATASTRUCT_ROOT / \"seizure_events.csv\"),\n",
    "        window_quality_csv=Path(STUDY2_ROOT / \"window_quality_baseline_vs_seizure.csv\"),\n",
    "        threshold_xlsx=Path(r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus to Lausanne\\Threshold values.xlsx\"),\n",
    "    )\n",
    "\n",
    "df_winq = pd.read_csv(paths.window_quality_csv)\n",
    "print(df_winq.columns.tolist())\n",
    "\n",
    "# Optional filters\n",
    "algo_keep = {\"hamilton2002\", \"neurokit\", \"pantompkins1985\", \"emrich2023\"}\n",
    "recording_uid_keep = {6,11}  # e.g. {4,5,9,11} for pilot\n",
    "\n",
    "responders = [3, 5, 6, 8, 14, 15, 16, 21, 23, 27, 28, 29, 31, 34, 37, 39, 40, 41, 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21a20b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - E:\\Speciale - Results\\study5\\study5_feat5_final.parquet\n",
      " - E:\\Speciale - Results\\study5\\study5_main_table_final.csv\n",
      " - E:\\Speciale - Results\\study5\\study5_split_table_final.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_uid</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>enrollment_id</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>seizure_id</th>\n",
       "      <th>t0</th>\n",
       "      <th>t1</th>\n",
       "      <th>duration_s</th>\n",
       "      <th>absolute_start</th>\n",
       "      <th>absolute_end</th>\n",
       "      <th>...</th>\n",
       "      <th>absolute_start_video</th>\n",
       "      <th>absolute_end_video</th>\n",
       "      <th>t0_video_trim</th>\n",
       "      <th>t1_video_trim</th>\n",
       "      <th>t0_clinical</th>\n",
       "      <th>t1_clinical</th>\n",
       "      <th>absolute_start_clinical</th>\n",
       "      <th>absolute_end_clinical</th>\n",
       "      <th>t0_clinical_trim</th>\n",
       "      <th>t1_clinical_trim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73289.0</td>\n",
       "      <td>73316.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2016-10-13 07:26:31</td>\n",
       "      <td>2016-10-13 07:26:58</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-10-13 07:26:31</td>\n",
       "      <td>2016-10-13 07:26:58</td>\n",
       "      <td>71939.0</td>\n",
       "      <td>71966.0</td>\n",
       "      <td>73315.0</td>\n",
       "      <td>73435.0</td>\n",
       "      <td>2016-10-13 07:26:57</td>\n",
       "      <td>2016-10-13 07:28:57</td>\n",
       "      <td>71965.0</td>\n",
       "      <td>72085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>99747.0</td>\n",
       "      <td>99862.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2016-10-13 14:47:29</td>\n",
       "      <td>2016-10-13 14:49:24</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-10-13 14:47:29</td>\n",
       "      <td>2016-10-13 14:49:24</td>\n",
       "      <td>98397.0</td>\n",
       "      <td>98512.0</td>\n",
       "      <td>99768.0</td>\n",
       "      <td>99861.0</td>\n",
       "      <td>2016-10-13 14:47:50</td>\n",
       "      <td>2016-10-13 14:49:23</td>\n",
       "      <td>98418.0</td>\n",
       "      <td>98511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>102688.0</td>\n",
       "      <td>102816.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2016-10-13 15:36:30</td>\n",
       "      <td>2016-10-13 15:38:38</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-10-13 15:36:30</td>\n",
       "      <td>2016-10-13 15:38:38</td>\n",
       "      <td>101338.0</td>\n",
       "      <td>101466.0</td>\n",
       "      <td>102686.0</td>\n",
       "      <td>102816.0</td>\n",
       "      <td>2016-10-13 15:36:28</td>\n",
       "      <td>2016-10-13 15:38:38</td>\n",
       "      <td>101336.0</td>\n",
       "      <td>101466.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    recording_uid  patient_id enrollment_id  recording_id  seizure_id  \\\n",
       "16              6           5           NaN             1           1   \n",
       "17              6           5           NaN             1           2   \n",
       "18              6           5           NaN             1           3   \n",
       "\n",
       "          t0        t1  duration_s       absolute_start         absolute_end  \\\n",
       "16   73289.0   73316.0        27.0  2016-10-13 07:26:31  2016-10-13 07:26:58   \n",
       "17   99747.0   99862.0       115.0  2016-10-13 14:47:29  2016-10-13 14:49:24   \n",
       "18  102688.0  102816.0       128.0  2016-10-13 15:36:30  2016-10-13 15:38:38   \n",
       "\n",
       "    ...  absolute_start_video   absolute_end_video  t0_video_trim  \\\n",
       "16  ...   2016-10-13 07:26:31  2016-10-13 07:26:58        71939.0   \n",
       "17  ...   2016-10-13 14:47:29  2016-10-13 14:49:24        98397.0   \n",
       "18  ...   2016-10-13 15:36:30  2016-10-13 15:38:38       101338.0   \n",
       "\n",
       "    t1_video_trim  t0_clinical  t1_clinical absolute_start_clinical  \\\n",
       "16        71966.0      73315.0      73435.0     2016-10-13 07:26:57   \n",
       "17        98512.0      99768.0      99861.0     2016-10-13 14:47:50   \n",
       "18       101466.0     102686.0     102816.0     2016-10-13 15:36:28   \n",
       "\n",
       "   absolute_end_clinical  t0_clinical_trim  t1_clinical_trim  \n",
       "16   2016-10-13 07:28:57           71965.0           72085.0  \n",
       "17   2016-10-13 14:49:23           98418.0           98511.0  \n",
       "18   2016-10-13 15:38:38          101336.0          101466.0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat5, df_main, df_split, thr_meta_modcsi, thr_meta_csi = run_study5(\n",
    "    paths,\n",
    "    algo_keep=algo_keep,\n",
    "    recording_uid_keep=recording_uid_keep,\n",
    "    win_rr=100,\n",
    "    pad_s=300.0,\n",
    "    gap_s=180.0,\n",
    "    responders=responders,\n",
    "    value_mode=\"modcsi\",  # \"modcsi\" or \"csi\"\n",
    ")\n",
    "\n",
    "df_feat5.to_parquet(STUDY5_OUT / \"study5_feat5_final.parquet\", index=False)\n",
    "df_main.to_csv(STUDY5_OUT / \"study5_main_table_final.csv\", index=False)\n",
    "if not df_split.empty:\n",
    "    df_split.to_csv(STUDY5_OUT / \"study5_split_table_final.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", STUDY5_OUT / \"study5_feat5_final.parquet\")\n",
    "print(\" -\", STUDY5_OUT / \"study5_main_table_final.csv\")\n",
    "if not df_split.empty:\n",
    "    print(\" -\", STUDY5_OUT / \"study5_split_table_final.csv\")\n",
    "\n",
    "df_seiz = pd.read_csv(paths.seizure_events_csv)\n",
    "df_seiz.head()\n",
    "df_seiz[df_seiz[\"patient_id\"] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bd30aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-threshold sanity (ModCSI×SlopeHR):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>mode_used</th>\n",
       "      <th>recording_uid_used</th>\n",
       "      <th>segment_start_s</th>\n",
       "      <th>segment_end_s</th>\n",
       "      <th>max_value_in_segment</th>\n",
       "      <th>factor</th>\n",
       "      <th>threshold</th>\n",
       "      <th>fallback_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>first_12h</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43200.0</td>\n",
       "      <td>6326.272188</td>\n",
       "      <td>1.05</td>\n",
       "      <td>6642.585798</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>first_24h</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86400.0</td>\n",
       "      <td>13069.673825</td>\n",
       "      <td>1.05</td>\n",
       "      <td>13723.157516</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  mode_used  recording_uid_used  segment_start_s  segment_end_s  \\\n",
       "0           5  first_12h                   6              0.0        43200.0   \n",
       "1           8  first_24h                  11              0.0        86400.0   \n",
       "\n",
       "   max_value_in_segment  factor     threshold  fallback_used  \n",
       "0           6326.272188    1.05   6642.585798          False  \n",
       "1          13069.673825    1.05  13723.157516          False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-threshold sanity (CSI×SlopeHR):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>mode_used</th>\n",
       "      <th>recording_uid_used</th>\n",
       "      <th>segment_start_s</th>\n",
       "      <th>segment_end_s</th>\n",
       "      <th>max_value_in_segment</th>\n",
       "      <th>factor</th>\n",
       "      <th>threshold</th>\n",
       "      <th>fallback_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>first_12h</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43200.0</td>\n",
       "      <td>3.261583</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.424662</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>first_24h</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86400.0</td>\n",
       "      <td>7.149821</td>\n",
       "      <td>1.05</td>\n",
       "      <td>7.507312</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  mode_used  recording_uid_used  segment_start_s  segment_end_s  \\\n",
       "0           5  first_12h                   6              0.0        43200.0   \n",
       "1           8  first_24h                  11              0.0        86400.0   \n",
       "\n",
       "   max_value_in_segment  factor  threshold  fallback_used  \n",
       "0              3.261583    1.05   3.424662          False  \n",
       "1              7.149821    1.05   7.507312          False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modes used (ModCSI):\n",
      "mode_used\n",
      "first_12h    1\n",
      "first_24h    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Modes used (CSI):\n",
      "mode_used\n",
      "first_12h    1\n",
      "first_24h    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Auto-threshold sanity (ModCSI×SlopeHR):\")\n",
    "display(thr_meta_modcsi)\n",
    "\n",
    "print(\"Auto-threshold sanity (CSI×SlopeHR):\")\n",
    "display(thr_meta_csi)\n",
    "\n",
    "print(\"\\nModes used (ModCSI):\")\n",
    "print(thr_meta_modcsi[\"mode_used\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nModes used (CSI):\")\n",
    "print(thr_meta_csi[\"mode_used\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d538f169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>mode_used</th>\n",
       "      <th>recording_uid_used</th>\n",
       "      <th>segment_start_s</th>\n",
       "      <th>segment_end_s</th>\n",
       "      <th>max_value_in_segment</th>\n",
       "      <th>factor</th>\n",
       "      <th>threshold</th>\n",
       "      <th>fallback_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>first_12h</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43200.0</td>\n",
       "      <td>6326.272188</td>\n",
       "      <td>1.05</td>\n",
       "      <td>6642.585798</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  mode_used  recording_uid_used  segment_start_s  segment_end_s  \\\n",
       "0           5  first_12h                   6              0.0        43200.0   \n",
       "\n",
       "   max_value_in_segment  factor    threshold  fallback_used  \n",
       "0           6326.272188    1.05  6642.585798          False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pid = 5\n",
    "row = thr_meta_modcsi[thr_meta_modcsi[\"patient_id\"] == pid]\n",
    "display(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b79e141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak row:\n",
      "t_s                         14935.599609\n",
      "ModCSI100_filt              16285.787935\n",
      "SlopeHR100_abs_bpm_per_s        0.388454\n",
      "ModCSI100_filt_x_SlopeHR     6326.272188\n",
      "thr_modcsi                   6642.585798\n",
      "Name: 1906015, dtype: object\n",
      "\n",
      "Check product: 6326.272188228972\n"
     ]
    }
   ],
   "source": [
    "pid = 5\n",
    "rid = int(thr_meta_modcsi.loc[thr_meta_modcsi.patient_id==pid, \"recording_uid_used\"].iloc[0])\n",
    "seg_end = float(thr_meta_modcsi.loc[thr_meta_modcsi.patient_id==pid, \"segment_end_s\"].iloc[0])\n",
    "\n",
    "value_col = \"ModCSI100_filt_x_SlopeHR\"\n",
    "\n",
    "g = df_feat5[(df_feat5.patient_id==pid) & (df_feat5.recording_uid==rid) & (df_feat5.t_s <= seg_end)].copy()\n",
    "k = g[value_col].idxmax()\n",
    "row = g.loc[k]\n",
    "\n",
    "print(\"Peak row:\")\n",
    "print(row[[\n",
    "    \"t_s\",\n",
    "    \"ModCSI100_filt\",\n",
    "    \"SlopeHR100_abs_bpm_per_s\",\n",
    "    \"ModCSI100_filt_x_SlopeHR\",\n",
    "    \"thr_modcsi\"\n",
    "]])\n",
    "print(\"\\nCheck product:\", row[\"ModCSI100_filt\"] * row[\"SlopeHR100_abs_bpm_per_s\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aa2fc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3.548130e+05\n",
      "mean     5.119656e-02\n",
      "std      5.115943e-02\n",
      "min      5.220409e-07\n",
      "50%      3.441390e-02\n",
      "90%      1.205125e-01\n",
      "99%      2.294475e-01\n",
      "max      4.461479e-01\n",
      "Name: SlopeHR100_abs_bpm_per_s, dtype: float64\n",
      "Fraction of points over threshold (by stream/algo):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rr_source</th>\n",
       "      <th>algo_id</th>\n",
       "      <th>n_points</th>\n",
       "      <th>frac_over</th>\n",
       "      <th>n_over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>labview</td>\n",
       "      <td>emrich2023</td>\n",
       "      <td>368047</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>labview</td>\n",
       "      <td>hamilton2002</td>\n",
       "      <td>367709</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>labview</td>\n",
       "      <td>neurokit</td>\n",
       "      <td>368043</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>labview</td>\n",
       "      <td>pantompkins1985</td>\n",
       "      <td>289411</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python</td>\n",
       "      <td>emrich2023</td>\n",
       "      <td>368039</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>python</td>\n",
       "      <td>hamilton2002</td>\n",
       "      <td>367659</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>python</td>\n",
       "      <td>neurokit</td>\n",
       "      <td>368109</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>python</td>\n",
       "      <td>pantompkins1985</td>\n",
       "      <td>289400</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rr_source          algo_id  n_points  frac_over  n_over\n",
       "0   labview       emrich2023    368047   0.001013     373\n",
       "1   labview     hamilton2002    367709   0.001028     378\n",
       "2   labview         neurokit    368043   0.001022     376\n",
       "3   labview  pantompkins1985    289411   0.000688     199\n",
       "4    python       emrich2023    368039   0.000946     348\n",
       "5    python     hamilton2002    367659   0.001044     384\n",
       "6    python         neurokit    368109   0.000932     343\n",
       "7    python  pantompkins1985    289400   0.000874     253"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_feat5.loc[g.index, \"SlopeHR100_abs_bpm_per_s\"].describe(percentiles=[0.5,0.9,0.99]))\n",
    "\n",
    "value_col = \"ModCSI100_filt_x_SlopeHR\"\n",
    "thr_col = \"thr_modcsi\"\n",
    "\n",
    "tmp = df_feat5.copy()\n",
    "tmp[\"is_over_thr\"] = tmp[value_col] > tmp[thr_col]\n",
    "\n",
    "over_stats = (\n",
    "    tmp.groupby([\"rr_source\",\"algo_id\"])\n",
    "    .agg(\n",
    "        n_points=(\"is_over_thr\",\"size\"),\n",
    "        frac_over=(\"is_over_thr\",\"mean\"),\n",
    "        n_over=(\"is_over_thr\",\"sum\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values([\"rr_source\",\"algo_id\"])\n",
    ")\n",
    "\n",
    "print(\"Fraction of points over threshold (by stream/algo):\")\n",
    "display(over_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b432239",
   "metadata": {},
   "outputs": [],
   "source": [
    "first24 = df_feat5[df_feat5[\"t_s\"] <= 24*3600].copy()\n",
    "\n",
    "stats_24h = (\n",
    "    first24.groupby([\"rr_source\",\"algo_id\"])\n",
    "    .agg(\n",
    "        p99=(value_col, lambda s: s.quantile(0.99)),\n",
    "        maxv=(value_col, \"max\"),\n",
    "        thr=(thr_col, \"median\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "stats_24h[\"max_over_thr\"] = stats_24h[\"maxv\"] / stats_24h[\"thr\"]\n",
    "stats_24h[\"p99_over_thr\"] = stats_24h[\"p99\"] / stats_24h[\"thr\"]\n",
    "\n",
    "print(\"First 24h sanity (p99/max relative to threshold):\")\n",
    "display(stats_24h.sort_values([\"rr_source\",\"algo_id\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c45737cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_seiz_in_used_recordings_raw': 4, 'n_seiz_total': 116, 'n_seiz_total_used': 4, 'n_seiz_detected': 1, 'recall_total': 0.008620689655172414, 'recall_used': 0.25, 'FP_events': 4, 'FAR_per_h': 0.04260355029585799, 'total_h': 93.88888888888889, 'n_events': 5, 'n_recordings_used': 2}\n"
     ]
    }
   ],
   "source": [
    "# Python + neurokit + SQI on\n",
    "g = df_feat5[(df_feat5[\"rr_source\"]==\"python\") & (df_feat5[\"algo_id\"]==\"neurokit\")]\n",
    "\n",
    "res = score_pipeline_events(\n",
    "    g, df_seiz,\n",
    "    value_col=\"ModCSI100_filt_x_SlopeHR\",\n",
    "    thr_col=\"thr_modcsi\",\n",
    "    pad_s=300.0,\n",
    "    gap_s=180.0,\n",
    "    use_sqi=True,\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c13eb13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RR_source</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>SQI</th>\n",
       "      <th>n_seiz_total_used</th>\n",
       "      <th>n_seiz_detected</th>\n",
       "      <th>recall_used</th>\n",
       "      <th>FP_events</th>\n",
       "      <th>n_events</th>\n",
       "      <th>total_h</th>\n",
       "      <th>FAR_per_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LabVIEW</td>\n",
       "      <td>—</td>\n",
       "      <td>off</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>93.89</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LabVIEW</td>\n",
       "      <td>—</td>\n",
       "      <td>on</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>93.89</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python</td>\n",
       "      <td>emrich2023</td>\n",
       "      <td>off</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python</td>\n",
       "      <td>emrich2023</td>\n",
       "      <td>on</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python</td>\n",
       "      <td>hamilton2002</td>\n",
       "      <td>off</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>93.81</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python</td>\n",
       "      <td>hamilton2002</td>\n",
       "      <td>on</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>93.81</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python</td>\n",
       "      <td>neurokit</td>\n",
       "      <td>off</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>93.89</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Python</td>\n",
       "      <td>neurokit</td>\n",
       "      <td>on</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>93.89</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Python</td>\n",
       "      <td>pantompkins1985</td>\n",
       "      <td>off</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>73.62</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Python</td>\n",
       "      <td>pantompkins1985</td>\n",
       "      <td>on</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>73.62</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RR_source        Algorithm  SQI  n_seiz_total_used  n_seiz_detected  \\\n",
       "0   LabVIEW                —  off                  4                1   \n",
       "1   LabVIEW                —   on                  4                1   \n",
       "2    Python       emrich2023  off                  4                1   \n",
       "3    Python       emrich2023   on                  4                1   \n",
       "4    Python     hamilton2002  off                  4                1   \n",
       "5    Python     hamilton2002   on                  4                1   \n",
       "6    Python         neurokit  off                  4                1   \n",
       "7    Python         neurokit   on                  4                1   \n",
       "8    Python  pantompkins1985  off                  4                0   \n",
       "9    Python  pantompkins1985   on                  4                0   \n",
       "\n",
       "   recall_used  FP_events  n_events  total_h  FAR_per_h  \n",
       "0         0.25          7         8    93.89      0.075  \n",
       "1         0.25          7         8    93.89      0.075  \n",
       "2         0.25          4         5    93.88      0.043  \n",
       "3         0.25          4         5    93.88      0.043  \n",
       "4         0.25          4         5    93.81      0.043  \n",
       "5         0.25          4         5    93.81      0.043  \n",
       "6         0.25          4         5    93.89      0.043  \n",
       "7         0.25          4         5    93.89      0.043  \n",
       "8         0.00          5         5    73.62      0.068  \n",
       "9         0.00          5         5    73.62      0.068  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_report = df_main.copy()\n",
    "\n",
    "# vælg kolonner\n",
    "keep = [\n",
    "    \"RR_source\",\"Algorithm\",\"SQI\",\n",
    "    \"n_seiz_total_used\",\"n_seiz_detected\",\"recall_used\",\n",
    "    \"FP_events\",\"n_events\",\"total_h\",\"FAR_per_h\",\n",
    "]\n",
    "df_report = df_report[keep].copy()\n",
    "\n",
    "# rounding\n",
    "df_report[\"recall_used\"] = df_report[\"recall_used\"].round(3)\n",
    "df_report[\"FAR_per_h\"] = df_report[\"FAR_per_h\"].round(3)\n",
    "df_report[\"total_h\"] = df_report[\"total_h\"].round(2)\n",
    "\n",
    "display(df_report)\n",
    "\n",
    "df_report.to_csv(STUDY5_OUT / \"study5_main_table_report.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bb1c03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_uid</th>\n",
       "      <th>t_start</th>\n",
       "      <th>t_end</th>\n",
       "      <th>duration_s</th>\n",
       "      <th>t_peak</th>\n",
       "      <th>peak_value</th>\n",
       "      <th>n_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>98369.005859</td>\n",
       "      <td>98459.271484</td>\n",
       "      <td>90.265625</td>\n",
       "      <td>98388.447266</td>\n",
       "      <td>46143.950695</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>101289.173828</td>\n",
       "      <td>101359.906250</td>\n",
       "      <td>70.732422</td>\n",
       "      <td>101309.902344</td>\n",
       "      <td>22528.837612</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>146673.244141</td>\n",
       "      <td>146694.072266</td>\n",
       "      <td>20.828125</td>\n",
       "      <td>146681.984375</td>\n",
       "      <td>20692.466095</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>90480.472656</td>\n",
       "      <td>90502.875000</td>\n",
       "      <td>22.402344</td>\n",
       "      <td>90488.398438</td>\n",
       "      <td>16012.346023</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>71915.962891</td>\n",
       "      <td>71946.667969</td>\n",
       "      <td>30.705078</td>\n",
       "      <td>71929.183594</td>\n",
       "      <td>14713.046795</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recording_uid        t_start          t_end  duration_s         t_peak  \\\n",
       "2              6   98369.005859   98459.271484   90.265625   98388.447266   \n",
       "3              6  101289.173828  101359.906250   70.732422  101309.902344   \n",
       "4             11  146673.244141  146694.072266   20.828125  146681.984375   \n",
       "1              6   90480.472656   90502.875000   22.402344   90488.398438   \n",
       "0              6   71915.962891   71946.667969   30.705078   71929.183594   \n",
       "\n",
       "     peak_value  n_points  \n",
       "2  46143.950695       160  \n",
       "3  22528.837612        64  \n",
       "4  20692.466095        35  \n",
       "1  16012.346023        34  \n",
       "0  14713.046795        45  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events: 5\n"
     ]
    }
   ],
   "source": [
    "g = df_feat5[(df_feat5[\"rr_source\"]==\"python\") & (df_feat5[\"algo_id\"]==\"neurokit\")].copy()\n",
    "\n",
    "events = build_event_list(\n",
    "    g[g[\"is_acceptable\"]],  # SQI on\n",
    "    value_col=\"ModCSI100_filt_x_SlopeHR\",\n",
    "    thr_col=\"thr_modcsi\",\n",
    "    gap_s=180.0,\n",
    ")\n",
    "events = events.sort_values(\"peak_value\", ascending=False)\n",
    "\n",
    "display(events.head(20))\n",
    "print(\"Total events:\", len(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e2b1d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_responder</th>\n",
       "      <th>RR_source</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>SQI</th>\n",
       "      <th>n_seiz_in_used_recordings_raw</th>\n",
       "      <th>n_seiz_total</th>\n",
       "      <th>n_seiz_total_used</th>\n",
       "      <th>n_seiz_detected</th>\n",
       "      <th>recall_total</th>\n",
       "      <th>recall_used</th>\n",
       "      <th>FP_events</th>\n",
       "      <th>FAR_per_h</th>\n",
       "      <th>total_h</th>\n",
       "      <th>n_events</th>\n",
       "      <th>n_recordings_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>LabVIEW</td>\n",
       "      <td>—</td>\n",
       "      <td>off</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.25</td>\n",
       "      <td>7</td>\n",
       "      <td>0.074552</td>\n",
       "      <td>93.894444</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>LabVIEW</td>\n",
       "      <td>—</td>\n",
       "      <td>on</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.25</td>\n",
       "      <td>7</td>\n",
       "      <td>0.074556</td>\n",
       "      <td>93.888889</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Python</td>\n",
       "      <td>emrich2023</td>\n",
       "      <td>off</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.042606</td>\n",
       "      <td>93.883333</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>Python</td>\n",
       "      <td>emrich2023</td>\n",
       "      <td>on</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.042609</td>\n",
       "      <td>93.877778</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>Python</td>\n",
       "      <td>hamilton2002</td>\n",
       "      <td>off</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.042638</td>\n",
       "      <td>93.813889</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>Python</td>\n",
       "      <td>hamilton2002</td>\n",
       "      <td>on</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.042640</td>\n",
       "      <td>93.808333</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>Python</td>\n",
       "      <td>neurokit</td>\n",
       "      <td>off</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.042601</td>\n",
       "      <td>93.894444</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>Python</td>\n",
       "      <td>neurokit</td>\n",
       "      <td>on</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.042604</td>\n",
       "      <td>93.888889</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>Python</td>\n",
       "      <td>pantompkins1985</td>\n",
       "      <td>off</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.067914</td>\n",
       "      <td>73.622222</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>Python</td>\n",
       "      <td>pantompkins1985</td>\n",
       "      <td>on</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.067919</td>\n",
       "      <td>73.616667</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_responder RR_source        Algorithm  SQI  \\\n",
       "0          True   LabVIEW                —  off   \n",
       "1          True   LabVIEW                —   on   \n",
       "2          True    Python       emrich2023  off   \n",
       "3          True    Python       emrich2023   on   \n",
       "4          True    Python     hamilton2002  off   \n",
       "5          True    Python     hamilton2002   on   \n",
       "6          True    Python         neurokit  off   \n",
       "7          True    Python         neurokit   on   \n",
       "8          True    Python  pantompkins1985  off   \n",
       "9          True    Python  pantompkins1985   on   \n",
       "\n",
       "   n_seiz_in_used_recordings_raw  n_seiz_total  n_seiz_total_used  \\\n",
       "0                              4            44                  4   \n",
       "1                              4            44                  4   \n",
       "2                              4            44                  4   \n",
       "3                              4            44                  4   \n",
       "4                              4            44                  4   \n",
       "5                              4            44                  4   \n",
       "6                              4            44                  4   \n",
       "7                              4            44                  4   \n",
       "8                              4            44                  4   \n",
       "9                              4            44                  4   \n",
       "\n",
       "   n_seiz_detected  recall_total  recall_used  FP_events  FAR_per_h  \\\n",
       "0                1      0.022727         0.25          7   0.074552   \n",
       "1                1      0.022727         0.25          7   0.074556   \n",
       "2                1      0.022727         0.25          4   0.042606   \n",
       "3                1      0.022727         0.25          4   0.042609   \n",
       "4                1      0.022727         0.25          4   0.042638   \n",
       "5                1      0.022727         0.25          4   0.042640   \n",
       "6                1      0.022727         0.25          4   0.042601   \n",
       "7                1      0.022727         0.25          4   0.042604   \n",
       "8                0      0.000000         0.00          5   0.067914   \n",
       "9                0      0.000000         0.00          5   0.067919   \n",
       "\n",
       "     total_h  n_events  n_recordings_used  \n",
       "0  93.894444         8                  2  \n",
       "1  93.888889         8                  2  \n",
       "2  93.883333         5                  2  \n",
       "3  93.877778         5                  2  \n",
       "4  93.813889         5                  2  \n",
       "5  93.808333         5                  2  \n",
       "6  93.894444         5                  2  \n",
       "7  93.888889         5                  2  \n",
       "8  73.622222         5                  2  \n",
       "9  73.616667         5                  2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split[df_split[\"is_responder\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc05e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta -> mapping (dict)\n",
    "thr_map_modcsi = (\n",
    "    thr_meta_modcsi\n",
    "    .dropna(subset=[\"patient_id\", \"threshold\"])\n",
    "    .drop_duplicates(\"patient_id\")\n",
    "    .set_index(\"patient_id\")[\"threshold\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "thr_map_csi = (\n",
    "    thr_meta_csi\n",
    "    .dropna(subset=[\"patient_id\", \"threshold\"])\n",
    "    .drop_duplicates(\"patient_id\")\n",
    "    .set_index(\"patient_id\")[\"threshold\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# map ind i df_feat5\n",
    "df_feat5[\"patient_id\"] = pd.to_numeric(df_feat5[\"patient_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "df_feat5[\"thr_modcsi\"] = df_feat5[\"patient_id\"].map(thr_map_modcsi)\n",
    "df_feat5[\"thr_csi\"]    = df_feat5[\"patient_id\"].map(thr_map_csi)\n",
    "\n",
    "# brug Excel-thresholds direkte\n",
    "df_feat5[\"thr_modcsi\"] = df_feat5[\"patient_id\"].map(thr_map_modcsi)\n",
    "df_feat5[\"thr_csi\"] = df_feat5[\"patient_id\"].map(thr_map_csi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7df36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9aeeee70",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'k_end'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvjkv\\anaconda3\\envs\\mast\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'k_end'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# varighed af 100RR vinduet ved peak\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m k_end = \u001b[38;5;28mint\u001b[39m(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mk_end\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# du kan genskabe varigheden hvis du gemmer rr_f / t_end; ellers approx med nabotider:\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# her: tag 100 samples bagud i df_feat5 for samme rid (kun approx!)\u001b[39;00m\n\u001b[32m      5\u001b[39m gg = g.sort_values(\u001b[33m\"\u001b[39m\u001b[33mt_s\u001b[39m\u001b[33m\"\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvjkv\\anaconda3\\envs\\mast\\Lib\\site-packages\\pandas\\core\\series.py:1130\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1133\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvjkv\\anaconda3\\envs\\mast\\Lib\\site-packages\\pandas\\core\\series.py:1246\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1243\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1245\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvjkv\\anaconda3\\envs\\mast\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'k_end'"
     ]
    }
   ],
   "source": [
    "# varighed af 100RR vinduet ved peak\n",
    "k_end = int(row[\"k_end\"])\n",
    "# du kan genskabe varigheden hvis du gemmer rr_f / t_end; ellers approx med nabotider:\n",
    "# her: tag 100 samples bagud i df_feat5 for samme rid (kun approx!)\n",
    "gg = g.sort_values(\"t_s\").reset_index(drop=True)\n",
    "i = gg.index[gg[\"t_s\"].eq(row[\"t_s\"])][0]\n",
    "if i >= 99:\n",
    "    win_dur = gg.loc[i, \"t_s\"] - gg.loc[i-99, \"t_s\"]\n",
    "    print(\"Approx 100RR window duration (s):\", float(win_dur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35893ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %%\n",
    "lab = df_feat5[\n",
    "    (df_feat5[\"rr_source\"] == \"labview\")\n",
    "].copy()\n",
    "\n",
    "\n",
    "# %%\n",
    "cols = [\n",
    "    \"CSI100_x_SlopeHR\",\n",
    "    \"ModCSI100_filt_x_SlopeHR\",\n",
    "    \"CSI100\",\n",
    "    \"ModCSI100_filt\",\n",
    "    \"SlopeHR100_abs_bpm_per_s\",  # hvis du har den version\n",
    "]\n",
    "\n",
    "display(\n",
    "    lab[cols]\n",
    "    .describe(percentiles=[0.5, 0.9, 0.99, 0.999])\n",
    ")\n",
    "\n",
    "\n",
    "# %%\n",
    "lab_stats = (\n",
    "    lab.groupby(\"patient_id\")[cols]\n",
    "    .quantile(0.99)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "display(lab_stats.sort_values(\"ModCSI100_filt_x_SlopeHR\", ascending=False))\n",
    "\n",
    "\n",
    "# %%\n",
    "lab_stats[\"thr_modcsi\"] = lab_stats[\"patient_id\"].map(thr_map_modcsi)\n",
    "lab_stats[\"ratio_p99_thr\"] = (\n",
    "    lab_stats[\"ModCSI100_filt_x_SlopeHR\"] / lab_stats[\"thr_modcsi\"]\n",
    ")\n",
    "\n",
    "display(lab_stats.sort_values(\"ratio_p99_thr\", ascending=False))\n",
    "\n",
    "\n",
    "# %%\n",
    "pid = 8\n",
    "rid = 11        # fra thr_meta_modcsi\n",
    "seiz_idx = 0   # første seizure i den recording\n",
    "\n",
    "\n",
    "# --- parameters ---\n",
    "pad_s = 30 * 60  # ±10 min\n",
    "\n",
    "# --- seizure info ---\n",
    "seiz_r = df_seiz[(df_seiz[\"patient_id\"] == pid) & (df_seiz[\"recording_uid\"] == rid)]\n",
    "s = seiz_r.iloc[seiz_idx]\n",
    "t0 = float(s[\"t0_clinical\"])\n",
    "t1 = float(s[\"t1_clinical\"])\n",
    "\n",
    "# --- feature slice ---\n",
    "g = df_feat5[\n",
    "    (df_feat5[\"rr_source\"] == \"labview\") &\n",
    "    (df_feat5[\"patient_id\"] == pid) &\n",
    "    (df_feat5[\"recording_uid\"] == rid) &\n",
    "    (df_feat5[\"t_s\"] >= t0 - pad_s) &\n",
    "    (df_feat5[\"t_s\"] <= t1 + pad_s)\n",
    "].sort_values(\"t_s\")\n",
    "\n",
    "t_min = (g[\"t_s\"] - t0) / 60.0  # relative minutes\n",
    "\n",
    "\n",
    "# %%\n",
    "fig, axs = plt.subplots(\n",
    "    3, 1,\n",
    "    figsize=(10, 6),\n",
    "    sharex=True,\n",
    "    gridspec_kw={\"hspace\": 0.15}\n",
    ")\n",
    "\n",
    "# -------- Panel 1: ModCSI × Slope --------\n",
    "axs[0].plot(t_min, g[\"ModCSI100_filt_x_SlopeHR\"], label=\"ModCSI × Slope\", color=\"black\")\n",
    "axs[0].axhline(\n",
    "    g[\"thr_modcsi\"].iloc[0],\n",
    "    color=\"red\", linestyle=\"--\", label=\"Threshold\"\n",
    ")\n",
    "axs[0].axvspan(0, (t1 - t0)/60, color=\"red\", alpha=0.15)\n",
    "axs[0].set_ylabel(\"ModCSI × Slope\")\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "\n",
    "# -------- Panel 2: ModCSI --------\n",
    "axs[1].plot(t_min, g[\"ModCSI100_filt\"], color=\"tab:blue\")\n",
    "axs[1].axvspan(0, (t1 - t0)/60, color=\"red\", alpha=0.15)\n",
    "axs[1].set_ylabel(\"ModCSI\")\n",
    "\n",
    "# -------- Panel 3: SlopeHR --------\n",
    "axs[2].plot(t_min, g[\"SlopeHR100_abs_bpm_per_s\"], color=\"tab:green\")\n",
    "axs[2].axvspan(0, (t1 - t0)/60, color=\"red\", alpha=0.15)\n",
    "axs[2].set_ylabel(\"Slope HR\\n(bpm/min)\")\n",
    "axs[2].set_xlabel(\"Time relative to seizure onset (min)\")\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"Patient {pid}, Recording {rid} — LabVIEW RR\\n\"\n",
    "    \"Autonomic response during seizure does not consistently exceed detection threshold\",\n",
    "    y=0.98\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97606681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# varighed af 100RR vinduet ved peak\n",
    "k_end = int(row[\"k_end\"])\n",
    "# du kan genskabe varigheden hvis du gemmer rr_f / t_end; ellers approx med nabotider:\n",
    "# her: tag 100 samples bagud i df_feat5 for samme rid (kun approx!)\n",
    "gg = g.sort_values(\"t_s\").reset_index(drop=True)\n",
    "i = gg.index[gg[\"t_s\"].eq(row[\"t_s\"])][0]\n",
    "if i >= 99:\n",
    "    win_dur = gg.loc[i, \"t_s\"] - gg.loc[i-99, \"t_s\"]\n",
    "    print(\"Approx 100RR window duration (s):\", float(win_dur))\n",
    "\n",
    "\n",
    "# %%\n",
    "lab = df_feat5[\n",
    "    (df_feat5[\"rr_source\"] == \"labview\")\n",
    "].copy()\n",
    "\n",
    "\n",
    "# %%\n",
    "cols = [\n",
    "    \"CSI100_x_SlopeHR\",\n",
    "    \"ModCSI100_filt_x_SlopeHR\",\n",
    "    \"CSI100\",\n",
    "    \"ModCSI100_filt\",\n",
    "    \"SlopeHR100_abs_bpm_per_s\",  # hvis du har den version\n",
    "]\n",
    "\n",
    "display(\n",
    "    lab[cols]\n",
    "    .describe(percentiles=[0.5, 0.9, 0.99, 0.999])\n",
    ")\n",
    "\n",
    "\n",
    "# %%\n",
    "lab_stats = (\n",
    "    lab.groupby(\"patient_id\")[cols]\n",
    "    .quantile(0.99)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "display(lab_stats.sort_values(\"ModCSI100_filt_x_SlopeHR\", ascending=False))\n",
    "\n",
    "\n",
    "# %%\n",
    "lab_stats[\"thr_modcsi\"] = lab_stats[\"patient_id\"].map(thr_map_modcsi)\n",
    "lab_stats[\"ratio_p99_thr\"] = (\n",
    "    lab_stats[\"ModCSI100_filt_x_SlopeHR\"] / lab_stats[\"thr_modcsi\"]\n",
    ")\n",
    "\n",
    "display(lab_stats.sort_values(\"ratio_p99_thr\", ascending=False))\n",
    "\n",
    "\n",
    "# %%\n",
    "pid = 8\n",
    "rid = 11        # fra thr_meta_modcsi\n",
    "seiz_idx = 0   # første seizure i den recording\n",
    "\n",
    "\n",
    "# --- parameters ---\n",
    "pad_s = 30 * 60  # ±10 min\n",
    "\n",
    "# --- seizure info ---\n",
    "seiz_r = df_seiz[(df_seiz[\"patient_id\"] == pid) & (df_seiz[\"recording_uid\"] == rid)]\n",
    "s = seiz_r.iloc[seiz_idx]\n",
    "t0 = float(s[\"t0_clinical\"])\n",
    "t1 = float(s[\"t1_clinical\"])\n",
    "\n",
    "# --- feature slice ---\n",
    "g = df_feat5[\n",
    "    (df_feat5[\"rr_source\"] == \"labview\") &\n",
    "    (df_feat5[\"patient_id\"] == pid) &\n",
    "    (df_feat5[\"recording_uid\"] == rid) &\n",
    "    (df_feat5[\"t_s\"] >= t0 - pad_s) &\n",
    "    (df_feat5[\"t_s\"] <= t1 + pad_s)\n",
    "].sort_values(\"t_s\")\n",
    "\n",
    "t_min = (g[\"t_s\"] - t0) / 60.0  # relative minutes\n",
    "\n",
    "\n",
    "# %%\n",
    "fig, axs = plt.subplots(\n",
    "    3, 1,\n",
    "    figsize=(10, 6),\n",
    "    sharex=True,\n",
    "    gridspec_kw={\"hspace\": 0.15}\n",
    ")\n",
    "\n",
    "# -------- Panel 1: ModCSI × Slope --------\n",
    "axs[0].plot(t_min, g[\"ModCSI100_filt_x_SlopeHR\"], label=\"ModCSI × Slope\", color=\"black\")\n",
    "axs[0].axhline(\n",
    "    g[\"thr_modcsi\"].iloc[0],\n",
    "    color=\"red\", linestyle=\"--\", label=\"Threshold\"\n",
    ")\n",
    "axs[0].axvspan(0, (t1 - t0)/60, color=\"red\", alpha=0.15)\n",
    "axs[0].set_ylabel(\"ModCSI × Slope\")\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "\n",
    "# -------- Panel 2: ModCSI --------\n",
    "axs[1].plot(t_min, g[\"ModCSI100_filt\"], color=\"tab:blue\")\n",
    "axs[1].axvspan(0, (t1 - t0)/60, color=\"red\", alpha=0.15)\n",
    "axs[1].set_ylabel(\"ModCSI\")\n",
    "\n",
    "# -------- Panel 3: SlopeHR --------\n",
    "axs[2].plot(t_min, g[\"SlopeHR100_abs_bpm_per_s\"], color=\"tab:green\")\n",
    "axs[2].axvspan(0, (t1 - t0)/60, color=\"red\", alpha=0.15)\n",
    "axs[2].set_ylabel(\"Slope HR\\n(bpm/min)\")\n",
    "axs[2].set_xlabel(\"Time relative to seizure onset (min)\")\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"Patient {pid}, Recording {rid} — LabVIEW RR\\n\"\n",
    "    \"Autonomic response during seizure does not consistently exceed detection threshold\",\n",
    "    y=0.98\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
