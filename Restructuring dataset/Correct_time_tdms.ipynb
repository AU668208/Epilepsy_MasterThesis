{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4809122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nptdms import TdmsFile\n",
    "import os\n",
    "\n",
    "path_base_folder = r\"D:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus to Lausanne\\Patients ePatch data\"\n",
    "output_base_folder = r\"D:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch - Corrected\\Patients ePatch data\"\n",
    "\n",
    "patient_path_1 = r\"D:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus to Lausanne\\Patients ePatch data\\Patient 1\\recording 2\\Patient 1_2.tdms\"\n",
    "\n",
    "Patients_to_use = [\"Patient 3\", \"Patient 5\", \"Patient 6\", \"Patient 8\", \"Patient 10\", \"Patient 14\", \"Patient 15\", \"Patient 16\", \"Patient 21\", \"Patient 23\", \"Patient 27\", \"Patient 28\", \"Patient 29\", \"Patient 31\", \"Patient 34\", \"Patient 37\", \"Patient 39\", \"Patient 40\", \"Patient 41\", \"Patient 42\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f739a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_tdms_start_time(tdms_file_path, output_path=\"copied_file.tdms\"):\n",
    "    from nptdms import TdmsFile, TdmsWriter, RootObject\n",
    "    import numpy as np\n",
    "    import re\n",
    "    from datetime import datetime\n",
    "\n",
    "    original_file = TdmsFile(tdms_file_path)\n",
    "    original_groups = original_file.groups()\n",
    "    original_channels = [chan for group in original_groups for chan in group.channels()]\n",
    "    original_file.properties[\"Corrected_by: \"] = \"Kasper Viken Jensen\"\n",
    "    starttime_string = original_file.properties[\"name\"]\n",
    "\n",
    "    # Extract start datetime information from the start_time string\n",
    "    datetime_matches = re.findall(r'\\d{2}_\\d{2}_\\d{4} kl_?\\d{6}', starttime_string)\n",
    "    if len(datetime_matches) > 0:\n",
    "        start_dt_str = datetime_matches[0].replace(' kl_', ' ').replace(' kl', ' ')\n",
    "        start_datetime = datetime.strptime(start_dt_str, '%d_%m_%Y %H%M%S')\n",
    "    if len(datetime_matches) == 0:\n",
    "        datetime_matches = re.findall(r'\\d{2}-\\d{2}-\\d{4} kl_?\\d{6}', starttime_string)\n",
    "        \n",
    "    else:\n",
    "        start_datetime = None\n",
    "\n",
    "    # Correct the start time in channel properties if found\n",
    "    if start_datetime is not None:\n",
    "        original_channels[0].properties[\"wf_start_time\"] = np.datetime64(start_datetime)\n",
    "\n",
    "    # Write to new TDMS file\n",
    "    with TdmsWriter(output_path) as copied_file:\n",
    "        root_object = RootObject(original_file.properties)\n",
    "        copied_file.write_segment([root_object] + original_groups + original_channels)\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "74469205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final patient folders: ['D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 10\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 14\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 14\\\\recording 2', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 15\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 15\\\\recording 2', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 16\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 21\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 21\\\\recording 2', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 23\\\\enrollment a\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 23\\\\enrollment b\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 23\\\\enrollment b\\\\recording 2', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 27\\\\enrollment a\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 27\\\\enrollment b\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 28\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 28\\\\recording 2', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 29\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 3\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 3\\\\recording 2', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 31\\\\enrollment a\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 31\\\\enrollment b\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 31\\\\enrollment b\\\\recording 2', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 34\\\\enrollment a\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 34\\\\enrollment b\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 34\\\\enrollment c\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 34\\\\enrollment c\\\\recording 2', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 37\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 39\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 40\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 40\\\\recording 2', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 41\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 42\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 5\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 6\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 6\\\\recording 2', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 8\\\\Enrollment a\\\\recording 1', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 8\\\\Enrollment a\\\\recording 2', 'D:\\\\ML algoritme tl anfaldsdetektion vha HRV\\\\ePatch data from Aarhus to Lausanne\\\\Patients ePatch data\\\\Patient 8\\\\Enrollment b']\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'start_datetime' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m tdms_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder1, tdms_files[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     20\u001b[0m output \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_base_folder, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(folder1), tdms_files[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mcorrect_tdms_start_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtdms_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTDMS file path:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tdms_file_path)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput path:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output)\n",
      "Cell \u001b[1;32mIn[139], line 25\u001b[0m, in \u001b[0;36mcorrect_tdms_start_time\u001b[1;34m(tdms_file_path, output_path)\u001b[0m\n\u001b[0;32m     22\u001b[0m     start_datetime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Correct the start time in channel properties if found\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mstart_datetime\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     original_channels[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mproperties[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwf_start_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime64(start_datetime)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Write to new TDMS file\u001b[39;00m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'start_datetime' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "final_patient_folders = []\n",
    "folders = [folder for folder in os.listdir(path_base_folder) if folder in Patients_to_use]\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(path_base_folder, folder)\n",
    "    output_path = os.path.join(output_base_folder, folder)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        if not dirs:  # Deepest folder\n",
    "            final_patient_folders.append(root)\n",
    "\n",
    "print(\"Final patient folders:\", final_patient_folders)\n",
    "\n",
    "for folder1 in final_patient_folders:\n",
    "    files_in_folder = os.listdir(folder1)\n",
    "    tdms_files = [f for f in files_in_folder if f.endswith('.tdms')]\n",
    "    if tdms_files:\n",
    "        tdms_file_path = os.path.join(folder1, tdms_files[0])\n",
    "        output = os.path.join(output_base_folder, os.path.basename(folder1), tdms_files[0])\n",
    "        x = correct_tdms_start_time(tdms_file_path, output)\n",
    "        print(\"TDMS file path:\", tdms_file_path)\n",
    "        print(\"Output path:\", output)\n",
    "        print(\"Corrected file:\", x)\n",
    "        print(\"TDMS files:\", tdms_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e36fed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "patient_path = r\"D:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus to Lausanne\\Patients ePatch data\\Patient 10\\recording 1\\Patient 10_1.tdms\"\n",
    "\n",
    "# Remove leading/trailing whitespace and ensure correct joining\n",
    "patient_path_clean = patient_path.strip().lstrip(\"\\\\/\")\n",
    "tdms_file_path = os.path.join(path_base_folder, patient_path_clean)\n",
    "\n",
    "# print(path_base_folder)\n",
    "# print(patient_path)\n",
    "# print(patient_path_1)\n",
    "# print(tdms_file_path)\n",
    "\n",
    "if not os.path.exists(tdms_file_path):\n",
    "    raise FileNotFoundError(f\"Path does not exist: {tdms_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b07aa420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method TdmsFile.groups of <nptdms.tdms.TdmsFile object at 0x0000027981C964D0>>\n"
     ]
    }
   ],
   "source": [
    "td = TdmsFile(patient_path_clean)\n",
    "ch = td.groups\n",
    "\n",
    "print(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "525dfe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('wf_start_time', numpy.datetime64('2017-06-20T11:44:43.000000')), ('wf_start_offset', 0.0), ('wf_increment', 0.001953125), ('wf_samples', 132710144), ('DigitalMaximum', 32767), ('DigitalMinimum', -32768), ('NI_ChannelName', 'EKG'), ('NI_ExpIsRelativeTime', False), ('wf_time_pref', 'absolute'), ('NI_ExpStartTimeStamp', numpy.datetime64('2017-06-20T11:44:43.000000')), ('NI_ExpTimeStamp', numpy.datetime64('2017-06-20T11:44:43.000000')), ('NI_ExpXDimension', 't'), ('wf_xname', 'Time'), ('wf_xunit_string', 's'), ('NI_UnitDescription', 'uV'), ('unit_string', 'uV'), ('PhysicalMaximum', 90298.0), ('PhysicalMinimum', -90298.0), ('PreFilter', ''), ('TransducerType', ''), ('ValsPerRec', 128)])\n",
      "TDMS File Properties:\n",
      "OrderedDict([('name', 'Sidsel Borg Nielsen 20062017 kl_134443 __23062017_kl_130000.tdms'), ('author', 'Jesper'), ('description', ''), ('registertxt1', 'Written by National Instruments LabVIEW')])\n",
      "\n",
      "TDMS Groups:\n",
      "Group: Untitled\n",
      "Properties: OrderedDict([('wf_xcolumns', 'None')])\n",
      "Channels: ['EKG']\n",
      "  Channel: EKG\n",
      "  Properties: OrderedDict([('wf_start_time', numpy.datetime64('2017-06-20T11:44:43.000000')), ('wf_start_offset', 0.0), ('wf_increment', 0.001953125), ('wf_samples', 132710144), ('DigitalMaximum', 32767), ('DigitalMinimum', -32768), ('NI_ChannelName', 'EKG'), ('NI_ExpIsRelativeTime', False), ('wf_time_pref', 'absolute'), ('NI_ExpStartTimeStamp', numpy.datetime64('2017-06-20T11:44:43.000000')), ('NI_ExpTimeStamp', numpy.datetime64('2017-06-20T11:44:43.000000')), ('NI_ExpXDimension', 't'), ('wf_xname', 'Time'), ('wf_xunit_string', 's'), ('NI_UnitDescription', 'uV'), ('unit_string', 'uV'), ('PhysicalMaximum', 90298.0), ('PhysicalMinimum', -90298.0), ('PreFilter', ''), ('TransducerType', ''), ('ValsPerRec', 128)])\n",
      "  First 5 data points: [516.69718471 541.49864958 574.5672694  591.10157931 591.10157931]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ch = td.groups()[0].channels()[0]\n",
    "\n",
    "# Data\n",
    "x = ch.data.astype(float)\n",
    "\n",
    "print(ch.properties)\n",
    "\n",
    "# Print the first few lines of raw TDMS file metadata\n",
    "print(\"TDMS File Properties:\")\n",
    "print(td.properties)\n",
    "\n",
    "tdms_prop = td.properties\n",
    "\n",
    "group = td.groups()\n",
    "\n",
    "print(\"\\nTDMS Groups:\")\n",
    "for group in td.groups():\n",
    "    print(f\"Group: {group.name}\")\n",
    "    print(\"Properties:\", group.properties)\n",
    "    print(\"Channels:\", [ch.name for ch in group.channels()])\n",
    "    for channel in group.channels():\n",
    "        print(f\"  Channel: {channel.name}\")\n",
    "        print(\"  Properties:\", channel.properties)\n",
    "        print(\"  First 5 data points:\", channel.data[:5])\n",
    "        print()\n",
    "# Samplingfrekvens\n",
    "inc = ch.properties.get(\"wf_increment\", None)\n",
    "\n",
    "# Starttid\n",
    "start_time = ch.properties.get(\"wf_start_time\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b156a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TdmsGroup with path /'Untitled'>\n",
      "<nptdms.tdms.TdmsFile object at 0x0000027981455650>\n"
     ]
    }
   ],
   "source": [
    "# print(group)\n",
    "# print(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3281d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-10-12T09:05:02.000000\n",
      "[ -70.27081712   -1.37785916   37.2021973  ... -125.38518349 -128.14090181\n",
      " -125.38518349]\n"
     ]
    }
   ],
   "source": [
    "# prop = ch.properties\n",
    "\n",
    "# print(prop[\"wf_start_time\"])\n",
    "\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074bea93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thue Bundgaard 12_10_2016 kl_110502__14_10_2016_ kl_080000.tdms\n"
     ]
    }
   ],
   "source": [
    "# start_time = td.properties[\"name\"]\n",
    "# print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15f67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed start datetime: 2016-10-12 11:05:02\n",
      "Parsed end datetime: 2016-10-14 08:00:00\n"
     ]
    }
   ],
   "source": [
    "# import re\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Extract start and end datetime information from the start_time string\n",
    "# datetime_matches = re.findall(r'\\d{2}_\\d{2}_\\d{4} kl_?\\d{6}', start_time)\n",
    "\n",
    "# datetime_end = re.findall(r'__\\d{2}_\\d{2}_\\d{4}_ kl_?\\d{6}', start_time)\n",
    "\n",
    "# # Parse start datetime\n",
    "# if len(datetime_matches) > 0:\n",
    "#     start_dt_str = datetime_matches[0].replace(' kl_', ' ').replace(' kl', ' ')\n",
    "#     start_datetime = datetime.strptime(start_dt_str, '%d_%m_%Y %H%M%S')\n",
    "#     print(\"Parsed start datetime:\", start_datetime)\n",
    "# else:\n",
    "#     start_datetime = None\n",
    "#     print(\"No valid start datetime found.\")\n",
    "\n",
    "# # Parse end datetime\n",
    "# if len(datetime_end) > 0:\n",
    "#     end_dt_str = datetime_end[0].replace(' kl_', ' ').replace(' kl', ' ')\n",
    "#     end_datetime = datetime.strptime(end_dt_str, '__%d_%m_%Y_ %H%M%S')\n",
    "#     print(\"Parsed end datetime:\", end_datetime)\n",
    "# else:\n",
    "#     end_datetime = None\n",
    "#     print(\"No valid end datetime found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3af5f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected start_time: 2016-10-12T11:05:02.000000\n",
      "Before correction: 2016-10-12T11:05:02.000000\n",
      "After correction: 2016-10-12T11:05:02.000000\n",
      "Kasper Viken Jensen\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Update start_time with the correct date, hour, and minute from start_datetime\n",
    "\n",
    "# corrected_start_time = np.datetime64(start_datetime)\n",
    "# print(\"Corrected start_time:\", corrected_start_time)\n",
    "\n",
    "# print(\"Before correction:\", td.groups()[0].channels()[0].properties[\"wf_start_time\"])\n",
    "# td.groups()[0].channels()[0].properties[\"wf_start_time\"] = corrected_start_time\n",
    "# print(\"After correction:\", td.groups()[0].channels()[0].properties[\"wf_start_time\"])\n",
    "\n",
    "# td.properties[\"Corrected_by: \"] = \"Kasper Viken Jensen\"\n",
    "# print(td.properties[\"Corrected_by: \"])\n",
    "\n",
    "# # prop[\"wf_start_time\"] = corrected_start_time\n",
    "# # print(prop[\"wf_start_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e12c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kasper Viken Jensen\n",
      "OrderedDict([('name', 'Thue Bundgaard 12_10_2016 kl_110502__14_10_2016_ kl_080000.tdms'), ('author', 'Jesper'), ('description', ''), ('registertxt1', 'Written by National Instruments LabVIEW'), ('Corrected_by: ', 'Kasper Viken Jensen')])\n"
     ]
    }
   ],
   "source": [
    "# tdms_prop[\"Corrected_by: \"] = \"Kasper Viken Jensen\"\n",
    "\n",
    "# print(tdms_prop[\"Corrected_by: \"])\n",
    "# print(tdms_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896245c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kvj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
