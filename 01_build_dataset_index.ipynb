{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c7d5c5d",
   "metadata": {},
   "source": [
    "# Notebook for setup og DataFrame for use acros project\n",
    "Update file roots and output dir before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85b9df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "from dataclasses import asdict\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "SRC_ROOT = PROJECT_ROOT / \"src\"\n",
    "if str(SRC_ROOT) not in sys.path:\n",
    "    sys.path.append(str(SRC_ROOT))\n",
    "\n",
    "from hrv_epatch.dataset.loader import iter_recordings\n",
    "from hrv_epatch.dataset.naming import parse_recording_key, RecordingKey\n",
    "from hrv_epatch.dataset.seizures import build_seizure_events_from_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f724403",
   "metadata": {},
   "source": [
    "## OBS - Configure root's and paths before running notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de4e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "TDMS_ROOT = Path(r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus to Lausanne\\Patients ePatch data\")\n",
    "ANN_ROOT  = Path(r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus to Lausanne\\Seizure log ePatch patients with seizures - excluded seizures removed\")\n",
    "TRIM_ROOT = Path(r\"E:\\Speciale - Results\\Final-LabView-Trim-Testset\\Pictures\\Trim-Overview.csv\")\n",
    "\n",
    "# OUT_DIR = PROJECT_ROOT / \"_analysis\"\n",
    "OUT_DIR = Path(r\"E:\\Speciale - Results\\Datastruct\")\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "REC_OUT_PATH = OUT_DIR / \"recordings_index.parquet\"\n",
    "EVT_OUT_PATH = OUT_DIR / \"seizure_events.parquet\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8526ac7f",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a664378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trim data\n",
    "trim_df = pd.read_csv(TRIM_ROOT)\n",
    "\n",
    "# trim_df = trim_df.rename(columns={\n",
    "#     \"uid\": \"recording_uid\",\n",
    "#     \"Patient_id\": \"patient_id\",\n",
    "#     \"Recording_uid\": \"recording_uid_str\",\n",
    "#     \"Trim_start\": \"trim_start_s\",\n",
    "#     \"Trim_end\": \"trim_end_s\",\n",
    "# })\n",
    "\n",
    "trim_df[\"recording_uid\"] = pd.to_numeric(trim_df[\"recording_uid\"], errors=\"coerce\").astype(\"Int64\")\n",
    "trim_df[\"trim_start_s\"] = pd.to_numeric(trim_df[\"trim_start_s\"], errors=\"coerce\")\n",
    "trim_df[\"trim_end_s\"] = pd.to_numeric(trim_df[\"trim_end_s\"], errors=\"coerce\")\n",
    "trim_df = trim_df.dropna(subset=[\"recording_uid\", \"trim_start_s\"]).copy()\n",
    "\n",
    "trim_map = (\n",
    "    trim_df[[\"recording_uid\", \"trim_start_s\", \"trim_end_s\"]]\n",
    "    .drop_duplicates(\"recording_uid\")\n",
    "    .set_index(\"recording_uid\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df328d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Patient 1_1.tdms  <->  P01_R01\n",
      "1 Patient 1_2.tdms  <->  P01_R02\n",
      "2 Patient 2_1.tdms  <->  P02_R01\n",
      "3 Patient 3_1.tdms  <->  P03_R01\n",
      "4 Patient 3_2.tdms  <->  P03_R02\n",
      "5 Patient 4_1.tdms  <->  P04_R01\n",
      "6 Patient 5_1.tdms  <->  P05_R01\n",
      "7 Patient 6_1.tdms  <->  P06_R01\n",
      "8 Patient 6_2.tdms  <->  P06_R02\n",
      "9 Patient 7_1.tdms  <->  P07_R01\n",
      "10 Patient 7_2.tdms  <->  P07_R02\n",
      "11 Patient 8a_1.tdms  <->  P08a_R01\n",
      "12 Patient 8a_2.tdms  <->  P08a_R02\n",
      "13 Patient 8b_1.tdms  <->  P08b_R01\n",
      "14 Patient 9_1.tdms  <->  P09_R01\n",
      "15 Patient 9_2.tdms  <->  P09_R02\n",
      "16 Patient 10_1.tdms  <->  P10_R01\n",
      "17 Patient 11_1.tdms  <->  P11_R01\n",
      "18 Patient 11_2.tdms  <->  P11_R02\n",
      "19 Patient 12_1.tdms  <->  P12_R01\n",
      "20 Patient 12_2.tdms  <->  P12_R02\n",
      "21 Patient 13_1.tdms  <->  P13_R01\n",
      "22 Patient 13_2.tdms  <->  P13_R02\n",
      "23 Patient 14_1.tdms  <->  P14_R01\n",
      "24 Patient 14_2.tdms  <->  P14_R02\n",
      "25 Patient 15_1.tdms  <->  P15_R01\n",
      "26 Patient 15_2.tdms  <->  P15_R02\n",
      "27 Patient 16_1.tdms  <->  P16_R01\n",
      "28 Patient 17_1.tdms  <->  P17_R01\n",
      "29 Patient 18_1.tdms  <->  P18_R01\n",
      "30 Patient 19_1.tdms  <->  P19_R01\n",
      "31 Patient 20_1.tdms  <->  P20_R01\n",
      "32 Patient 20_2.tdms  <->  P20_R02\n",
      "33 Patient 21_1.tdms  <->  P21_R01\n",
      "34 Patient 21_2.tdms  <->  P21_R02\n",
      "35 Patient 22_1.tdms  <->  P22_R01\n",
      "36 Patient 22_2.tdms  <->  P22_R02\n",
      "37 Patient 23a_1.tdms  <->  P23a_R01\n",
      "38 Patient 23b_1.tdms  <->  P23b_R01\n",
      "39 Patient 23b_2.tdms  <->  P23b_R02\n",
      "40 Patient 24_1.tdms  <->  P24_R01\n",
      "41 Patient 24_2.tdms  <->  P24_R02\n",
      "42 Patient 25_1.tdms  <->  P25_R01\n",
      "43 Patient 25_2.tdms  <->  P25_R02\n",
      "44 Patient 26_1.tdms  <->  P26_R01\n",
      "45 Patient 27a_1.tdms  <->  P27a_R01\n",
      "46 Patient 27b_1.tdms  <->  P27b_R01\n",
      "47 Patient 28_1.tdms  <->  P28_R01\n",
      "48 Patient 28_2.tdms  <->  P28_R02\n",
      "49 Patient 29_1.tdms  <->  P29_R01\n",
      "50 Patient 30_1.tdms  <->  P30_R01\n",
      "51 Patient 31a_1.tdms  <->  P31a_R01\n",
      "52 Patient 31b_1.tdms  <->  P31b_R01\n",
      "53 Patient 31b_2.tdms  <->  P31b_R02\n",
      "54 Patient 32_1.tdms  <->  P32_R01\n",
      "55 Patient 33_1.tdms  <->  P33_R01\n",
      "56 Patient 34a_1.tdms  <->  P34a_R01\n",
      "57 Patient 34b_1.tdms  <->  P34b_R01\n",
      "58 Patient 34c_1.tdms  <->  P34c_R01\n",
      "59 Patient 34c_2.tdms  <->  P34c_R02\n",
      "60 Patient 35_1.tdms  <->  P35_R01\n",
      "61 Patient 36_1.tdms  <->  P36_R01\n",
      "62 Patient 36_2.tdms  <->  P36_R02\n",
      "63 Patient 37_1.tdms  <->  P37_R01\n",
      "64 Patient 38a_1.tdms  <->  P38a_R01\n",
      "65 Patient 38b_1.tdms  <->  P38b_R01\n",
      "66 Patient 39_1.tdms  <->  P39_R01\n",
      "67 Patient 40_1.tdms  <->  P40_R01\n",
      "68 Patient 40_2.tdms  <->  P40_R02\n",
      "69 Patient 41_1.tdms  <->  P41_R01\n",
      "70 Patient 42_1.tdms  <->  P42_R01\n",
      "71 Patient 43_1.tdms  <->  P43_R01\n"
     ]
    }
   ],
   "source": [
    "recording_rows = []\n",
    "event_rows = []\n",
    "\n",
    "for sig, meta, ann in iter_recordings(TDMS_ROOT, ANN_ROOT):\n",
    "    rec_start = pd.to_datetime(meta.start_time)\n",
    "    rec_duration_s = len(sig) / meta.fs\n",
    "    rec_end = rec_start + pd.to_timedelta(rec_duration_s, unit=\"s\")\n",
    "\n",
    "    tdms_path = Path(meta.path)\n",
    "    key = parse_recording_key(tdms_path)\n",
    "\n",
    "    rid = len(recording_rows)\n",
    "    if rid in trim_df[\"recording_uid\"].values:\n",
    "        s = trim_df.loc[trim_df[\"recording_uid\"] == rid, \"recording_uid_str\"].iloc[0]\n",
    "        print(rid, tdms_path.name, \" <-> \", s)\n",
    "\n",
    "\n",
    "    trim_start_s = float(trim_map.loc[rid, \"trim_start_s\"]) if rid in trim_map.index else 0.0\n",
    "    trim_end_s   = float(trim_map.loc[rid, \"trim_end_s\"])   if rid in trim_map.index else 0.0\n",
    "\n",
    "    events = build_seizure_events_from_df(\n",
    "        seizure_df=ann,\n",
    "        rec_start=rec_start,\n",
    "        rec_end=rec_end,\n",
    "        trim_start_s=trim_start_s,\n",
    "        trim_end_s=trim_end_s,\n",
    "    )\n",
    "\n",
    "    # annotation_source\n",
    "    if ann is not None and not ann.empty and \"source_file\" in ann.columns:\n",
    "        ann_source = ann[\"source_file\"].iloc[0]\n",
    "    else:\n",
    "        ann_source = None\n",
    "\n",
    "    recording_rows.append({\n",
    "        \"recording_uid\": rid,\n",
    "        \"patient_id\": key.patient_id,\n",
    "        \"enrollment_id\": key.enrollment_id,\n",
    "        \"recording_id\": key.recording_id,\n",
    "        \"tdms_path\": str(tdms_path),\n",
    "        \"annotation_source\": ann_source,\n",
    "        \"recording_start\": rec_start,\n",
    "        \"recording_end\": rec_end,\n",
    "        \"rec_duration_s\": rec_duration_s,\n",
    "        \"fs\": meta.fs,\n",
    "        # (optional) keep trim metadata at recording-level too\n",
    "        \"trim_start_s\": trim_start_s,\n",
    "        \"trim_end_s\": trim_end_s,\n",
    "    })\n",
    "\n",
    "    for ev in events:\n",
    "        row = {\n",
    "            \"recording_uid\": rid,\n",
    "            \"patient_id\": key.patient_id,\n",
    "            \"enrollment_id\": key.enrollment_id,\n",
    "            \"recording_id\": key.recording_id,\n",
    "            \"seizure_id\": ev.seizure_id,\n",
    "\n",
    "            # RAW (relative to original rec_start)\n",
    "            \"t0\": ev.t0,\n",
    "            \"t1\": ev.t1,\n",
    "            \"duration_s\": ev.duration_s,\n",
    "            \"absolute_start\": ev.absolute_start,\n",
    "            \"absolute_end\": ev.absolute_end,\n",
    "\n",
    "            # trim metadata\n",
    "            \"trim_start_s\": ev.trim_start_s,\n",
    "            \"trim_end_s\": ev.trim_end_s,\n",
    "\n",
    "            # TRIMMED (relative to trimmed signal start)\n",
    "            \"t0_trim\": ev.t0_trim,\n",
    "            \"t1_trim\": ev.t1_trim,\n",
    "        }\n",
    "\n",
    "        # RAW + TRIM: video\n",
    "        if ev.t0_video is not None:\n",
    "            row[\"t0_video\"] = ev.t0_video\n",
    "            row[\"t1_video\"] = ev.t1_video\n",
    "            row[\"absolute_start_video\"] = rec_start + pd.to_timedelta(ev.t0_video, unit=\"s\")\n",
    "            row[\"absolute_end_video\"]   = rec_start + pd.to_timedelta(ev.t1_video, unit=\"s\")\n",
    "\n",
    "            row[\"t0_video_trim\"] = ev.t0_video_trim\n",
    "            row[\"t1_video_trim\"] = ev.t1_video_trim\n",
    "\n",
    "        # RAW + TRIM: clinical\n",
    "        if ev.t0_clinical is not None:\n",
    "            row[\"t0_clinical\"] = ev.t0_clinical\n",
    "            row[\"t1_clinical\"] = ev.t1_clinical\n",
    "            row[\"absolute_start_clinical\"] = rec_start + pd.to_timedelta(ev.t0_clinical, unit=\"s\")\n",
    "            row[\"absolute_end_clinical\"]   = rec_start + pd.to_timedelta(ev.t1_clinical, unit=\"s\")\n",
    "\n",
    "            row[\"t0_clinical_trim\"] = ev.t0_clinical_trim\n",
    "            row[\"t1_clinical_trim\"] = ev.t1_clinical_trim\n",
    "\n",
    "        event_rows.append(row)\n",
    "\n",
    "df_rec = pd.DataFrame(recording_rows)\n",
    "df_evt = pd.DataFrame(event_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74edd9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   recording_uid  patient_id enrollment_id  recording_id  \\\n",
       " 0              0           1          None             1   \n",
       " 1              1           1          None             2   \n",
       " 2              2           2          None             1   \n",
       " 3              3           3          None             1   \n",
       " 4              4           3          None             2   \n",
       " \n",
       "                                            tdms_path annotation_source  \\\n",
       " 0  E:\\ML algoritme tl anfaldsdetektion vha HRV\\eP...     patient 1.xls   \n",
       " 1  E:\\ML algoritme tl anfaldsdetektion vha HRV\\eP...     patient 1.xls   \n",
       " 2  E:\\ML algoritme tl anfaldsdetektion vha HRV\\eP...     patient 2.xls   \n",
       " 3  E:\\ML algoritme tl anfaldsdetektion vha HRV\\eP...     patient 3.xls   \n",
       " 4  E:\\ML algoritme tl anfaldsdetektion vha HRV\\eP...     patient 3.xls   \n",
       " \n",
       "       recording_start                 recording_end  rec_duration_s     fs  \\\n",
       " 0 2016-02-22 11:04:14 2016-02-24 16:09:49.750000000   191135.750000  512.0   \n",
       " 1 2016-02-24 16:15:00 2016-02-26 09:00:00.001953125   146700.001953  512.0   \n",
       " 2 2016-05-03 13:19:05 2016-05-04 07:03:49.750000000    63884.750000  512.0   \n",
       " 3 2016-09-05 11:19:32 2016-09-07 10:49:54.500000000   171022.500000  512.0   \n",
       " 4 2016-09-07 10:50:46 2016-09-09 09:44:08.000000000   168802.000000  512.0   \n",
       " \n",
       "    trim_start_s  trim_end_s  \n",
       " 0         100.0       300.0  \n",
       " 1         300.0       300.0  \n",
       " 2         100.0        20.0  \n",
       " 3         120.0        40.0  \n",
       " 4          60.0        90.0  ,\n",
       "    recording_uid  patient_id enrollment_id  recording_id  seizure_id  \\\n",
       " 0              0           1          None             1           1   \n",
       " 1              1           1          None             2           2   \n",
       " 2              1           1          None             2           3   \n",
       " 3              2           2          None             1           1   \n",
       " 4              2           2          None             1           2   \n",
       " \n",
       "          t0        t1  duration_s      absolute_start        absolute_end  \\\n",
       " 0  130187.0  130228.0        41.0 2016-02-23 23:14:01 2016-02-23 23:14:42   \n",
       " 1   47163.0   47185.0        22.0 2016-02-25 05:21:03 2016-02-25 05:21:25   \n",
       " 2  134180.0  134210.0        30.0 2016-02-26 05:31:20 2016-02-26 05:31:50   \n",
       " 3    3209.0    3244.0        35.0 2016-05-03 14:12:34 2016-05-03 14:13:09   \n",
       " 4    5841.0    5878.0        37.0 2016-05-03 14:56:26 2016-05-03 14:57:03   \n",
       " \n",
       "    ...  absolute_start_video  absolute_end_video  t0_video_trim  \\\n",
       " 0  ...   2016-02-23 23:14:01 2016-02-23 23:14:42       130087.0   \n",
       " 1  ...   2016-02-25 05:21:03 2016-02-25 05:21:25        46863.0   \n",
       " 2  ...   2016-02-26 05:31:20 2016-02-26 05:31:50       133880.0   \n",
       " 3  ...   2016-05-03 14:12:34 2016-05-03 14:13:09         3109.0   \n",
       " 4  ...   2016-05-03 14:56:26 2016-05-03 14:57:03         5741.0   \n",
       " \n",
       "    t1_video_trim  t0_clinical  t1_clinical absolute_start_clinical  \\\n",
       " 0       130128.0     130187.0     130228.0     2016-02-23 23:14:01   \n",
       " 1        46885.0      47148.0      47240.0     2016-02-25 05:20:48   \n",
       " 2       133910.0     134153.0     134194.0     2016-02-26 05:30:53   \n",
       " 3         3144.0       3202.0       3307.0     2016-05-03 14:12:27   \n",
       " 4         5778.0       5825.0       5881.0     2016-05-03 14:56:10   \n",
       " \n",
       "   absolute_end_clinical  t0_clinical_trim  t1_clinical_trim  \n",
       " 0   2016-02-23 23:14:42          130087.0          130128.0  \n",
       " 1   2016-02-25 05:22:20           46848.0           46940.0  \n",
       " 2   2016-02-26 05:31:34          133853.0          133894.0  \n",
       " 3   2016-05-03 14:14:12            3102.0            3207.0  \n",
       " 4   2016-05-03 14:57:06            5725.0            5781.0  \n",
       " \n",
       " [5 rows x 26 columns])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 1) merge trim_start_s ind via recording_uid\n",
    "# df_evt = df_evt.merge(\n",
    "#     trim_df[[\"recording_uid\", \"trim_start_s\", \"trim_end_s\"]],\n",
    "#     on=\"recording_uid\",\n",
    "#     how=\"left\",\n",
    "#     validate=\"many_to_one\"\n",
    "# )\n",
    "\n",
    "# # fallback (hvis nogle få mangler trim, antag 0)\n",
    "# df_evt[\"trim_start_s\"] = df_evt[\"trim_start_s\"].fillna(0.0)\n",
    "\n",
    "\n",
    "# # korrigér clinical tider (hvis de findes)\n",
    "# for a, b in [(\"t0_clinical\",\"t1_clinical\"), (\"t0\",\"t1\"), (\"t0_video\",\"t1_video\")]:\n",
    "#     if a in df_evt.columns and b in df_evt.columns:\n",
    "#         df_evt[a] = df_evt[a] - df_evt[\"trim_start_s\"]\n",
    "#         df_evt[b] = df_evt[b] - df_evt[\"trim_start_s\"]\n",
    "\n",
    "# # drop events der nu ligger før signalstart\n",
    "# if \"t0_clinical\" in df_evt.columns:\n",
    "#     df_evt.loc[df_evt[\"t0_clinical\"] < 0, \"t0_clinical\"] = 0.0\n",
    "\n",
    "# # opdatér absolute tider hvis de findes\n",
    "# if \"absolute_start_clinical\" in df_evt.columns and \"t0_clinical\" in df_evt.columns:\n",
    "#     # absolute = rec_start + t0_clinical (i sek)  (rec_start ligger ikke i df_evt pt)\n",
    "#     # enkleste: drop dem og genberegn senere ved behov, eller merge rec_start ind:\n",
    "#     df_evt = df_evt.merge(\n",
    "#         df_rec[[\"recording_uid\", \"recording_start\"]],\n",
    "#         on=\"recording_uid\",\n",
    "#         how=\"left\"\n",
    "#     )\n",
    "#     df_evt[\"absolute_start_clinical\"] = df_evt[\"recording_start\"] + pd.to_timedelta(df_evt[\"t0_clinical\"], unit=\"s\")\n",
    "#     df_evt[\"absolute_end_clinical\"]   = df_evt[\"recording_start\"] + pd.to_timedelta(df_evt[\"t1_clinical\"], unit=\"s\")\n",
    "#     df_evt = df_evt.drop(columns=[\"recording_start\"])\n",
    "\n",
    "\n",
    "df_rec.head(), df_evt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a121f2f",
   "metadata": {},
   "source": [
    "Sanity Check to validate correct data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c45cb8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Antal recordings:\", len(df_rec))\n",
    "# print(\"Antal seizures:\", len(df_evt))\n",
    "\n",
    "# print(\"\\nUnikke patienter i df_rec:\", sorted(df_rec[\"patient_id\"].unique()))\n",
    "# print(\"Unikke patienter i df_evt:\", sorted(df_evt[\"patient_id\"].unique()))\n",
    "\n",
    "# df_rec.groupby(\"patient_id\")[\"recording_uid\"].count()\n",
    "# df_evt.groupby(\"patient_id\")[\"seizure_id\"].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e02511",
   "metadata": {},
   "source": [
    "## Save DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbf6ef16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "  recordings -> E:\\Speciale - Results\\Datastruct\\recordings_index.csv\n",
      "  events     -> E:\\Speciale - Results\\Datastruct\\seizure_events.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "OUT_DIR = Path(r\"E:\\Speciale - Results\\Datastruct\")\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "REC_OUT_PATH = OUT_DIR / \"recordings_index.csv\"\n",
    "EVT_OUT_PATH = OUT_DIR / \"seizure_events.csv\"\n",
    "\n",
    "df_rec.to_csv(REC_OUT_PATH, index=False)\n",
    "df_evt.to_csv(EVT_OUT_PATH, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  recordings ->\", REC_OUT_PATH)\n",
    "print(\"  events     ->\", EVT_OUT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d38b1",
   "metadata": {},
   "source": [
    "Validation code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5d56f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hvor mange seizures har vi nu for patient 31?\n",
    "# df_evt[df_evt[\"patient_id\"] == 31].shape\n",
    "\n",
    "# # kig på de første par\n",
    "# df_evt[df_evt[\"patient_id\"] == 31][[\"seizure_id\", \"duration_s\", \"absolute_start\"]].head()\n",
    "\n",
    "# from pathlib import Path\n",
    "# import pandas as pd\n",
    "# from hrv_epatch.dataset.annotations import load_annotations\n",
    "\n",
    "# # Alle recordings for patient 31\n",
    "# df_rec_31 = df_rec[df_rec[\"patient_id\"] == 31]\n",
    "# print(df_rec_31[[\"recording_uid\", \"enrollment_id\", \"tdms_path\", \"recording_start\", \"recording_end\"]])\n",
    "\n",
    "# rec31a = df_rec_31[df_rec_31[\"enrollment_id\"] == \"a\"].iloc[0]\n",
    "# print(rec31a)\n",
    "\n",
    "# from hrv_epatch.dataset.annotations import find_annotation_file\n",
    "# from hrv_epatch.dataset.naming import RecordingKey\n",
    "\n",
    "# # rekonstruér key for 31a\n",
    "# tdms_path_31a = Path(rec31a[\"tdms_path\"])\n",
    "# key31a = RecordingKey(patient_id=31, enrollment_id=\"a\", recording_id=rec31a[\"recording_id\"])\n",
    "\n",
    "# print(\"Candidates for 31a:\", [p.name for p in ANN_ROOT.glob(\"Patient 31*\")])\n",
    "# print(\"find_annotation_file says:\", find_annotation_file(key31a, ANN_ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd37d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rec = pd.read_csv(OUT_DIR / \"recordings_index.csv\",\n",
    "                     parse_dates=[\"recording_start\", \"recording_end\"])\n",
    "df_evt = pd.read_csv(OUT_DIR / \"seizure_events.csv\",\n",
    "                     parse_dates=[\"absolute_start\", \"absolute_end\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bc774c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rec_31 = df_rec[df_rec[\"patient_id\"] == 31]\n",
    "# print(df_rec_31[[\"recording_uid\", \"enrollment_id\", \"tdms_path\",\n",
    "#                  \"recording_start\", \"recording_end\", \"annotation_source\"]])\n",
    "\n",
    "# df_evt_31 = df_evt[df_evt[\"patient_id\"] == 31]\n",
    "# print(\"Seizures for patient 31:\", len(df_evt_31))\n",
    "# print(df_evt_31.groupby(\"enrollment_id\")[\"seizure_id\"].count())\n",
    "\n",
    "# print(df_evt_31[[\"t0\", \"t0_trim\", \"trim_start_s\"]])\n",
    "# cols_to_check = [c for c in df_evt.columns if c != \"enrollment_id\"]\n",
    "# n_nan_rows = df_evt[cols_to_check].isna().any(axis=1).sum()\n",
    "# print(\"Rows with at least one NaN (excluding enrollment_id):\", n_nan_rows, \"Out off\", len(df_evt))\n",
    "\n",
    "# print(df_evt)\n",
    "# print(\"Rows with at least one NaN:\", n_nan_rows, \"Out off\", len(df_evt))\n",
    "\n",
    "# print(df_evt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
