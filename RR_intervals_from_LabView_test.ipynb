{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e052625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n",
    "path = r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\LabView-Results\\Patient5_1-corrected-rr.lvm\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c30d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 186084 RR intervals\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.331858\n",
       "1    0.382904\n",
       "2    0.167871\n",
       "3    0.204339\n",
       "4    0.220332\n",
       "Name: RR, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load RR intervals from file (header lines 1-20, data starts at line 23)\n",
    "# The file uses tabs as separators and comma as decimal separator (e.g. \"0,000000\\t0,244154\")\n",
    "skiprows = 22\n",
    "\n",
    "# read with explicit tab separator and decimal comma; fallback to whitespace if needed\n",
    "try:\n",
    "    df_raw = pd.read_csv(path, skiprows=skiprows, sep='\\t', header=0, engine='python', decimal=',')\n",
    "except Exception:\n",
    "    df_raw = pd.read_csv(path, skiprows=skiprows, header=0, delim_whitespace=True, engine='python', decimal=',')\n",
    "\n",
    "# If no header row was present, ensure columns are strings and try again using first row as header\n",
    "if df_raw.columns.to_series().astype(str).str.contains('[A-Za-z]').any() is False and df_raw.iloc[0].astype(str).str.contains('[A-Za-z]').any():\n",
    "    df_raw = pd.read_csv(path, skiprows=skiprows, header=0, sep='\\t', engine='python', decimal=',')\n",
    "\n",
    "# Prefer numeric-typed columns; otherwise coerce columns to numeric (handling comma decimals)\n",
    "num_cols = df_raw.select_dtypes(include=['number']).columns\n",
    "if len(num_cols) > 0:\n",
    "    rr = df_raw[num_cols[1]].dropna().reset_index(drop=True)\n",
    "else:\n",
    "    # coerce by replacing comma with dot then converting\n",
    "    coerced = df_raw.apply(lambda col: pd.to_numeric(col.astype(str).str.replace(',', '.'), errors='coerce'))\n",
    "    numeric_mask = coerced.notna().sum() > 0\n",
    "    if numeric_mask.any():\n",
    "        rr = coerced.loc[:, numeric_mask].iloc[:, 0].dropna().reset_index(drop=True)\n",
    "    else:\n",
    "        # fallback: first column\n",
    "        rr = pd.to_numeric(df_raw.iloc[:, 0].astype(str).str.replace(',', '.'), errors='coerce').dropna().reset_index(drop=True)\n",
    "\n",
    "rr.name = 'RR'\n",
    "print(f\"Loaded {len(rr)} RR intervals\")\n",
    "rr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3ce20be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 13435 short intervals. Before: 186084, After: 172649\n"
     ]
    }
   ],
   "source": [
    "# Merge RR intervals shorter than 0.27 s into the smaller adjacent interval.\n",
    "# Uses existing `rr` Series from the notebook.\n",
    "threshold = 60/220\n",
    "\n",
    "vals = rr.tolist()\n",
    "removed = 0\n",
    "\n",
    "while True:\n",
    "    # find first short interval\n",
    "    short_idx = next((i for i, v in enumerate(vals) if v < threshold), None)\n",
    "    if short_idx is None:\n",
    "        break\n",
    "\n",
    "    v = vals[short_idx]\n",
    "    # choose neighbor (previous or next) with the smaller value (handle edges)\n",
    "    if short_idx == 0:\n",
    "        neighbor = 1\n",
    "    elif short_idx == len(vals) - 1:\n",
    "        neighbor = short_idx - 1\n",
    "    else:\n",
    "        neighbor = short_idx - 1 if vals[short_idx - 1] <= vals[short_idx + 1] else short_idx + 1\n",
    "\n",
    "    # add short interval to chosen neighbor and remove it\n",
    "    vals[neighbor] += v\n",
    "    vals.pop(short_idx)\n",
    "    removed += 1\n",
    "\n",
    "rr_clean = pd.Series(vals, name='RR')\n",
    "print(f\"Removed {removed} short intervals. Before: {len(rr)}, After: {len(rr_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e8c271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172649\n"
     ]
    }
   ],
   "source": [
    "print(len(rr_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb78bbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration of cleaned RR intervals: 160685.02818899963 seconds\n"
     ]
    }
   ],
   "source": [
    "rr_clean_total = 0\n",
    "\n",
    "for i in rr_clean:\n",
    "    rr_clean_total += i\n",
    "\n",
    "print(f\"Total duration of cleaned RR intervals: {rr_clean_total} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c198f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration based on original signal sampling rate: 161055.25 seconds\n",
      "Samples to remove at start: 60\n",
      "Samples to remove at end: 300\n",
      "Effective duration after removing start/end: 160695.25 seconds\n"
     ]
    }
   ],
   "source": [
    "fs = 512\n",
    "s_total = 82460288/fs\n",
    "print(f\"Total duration based on original signal sampling rate: {s_total} seconds\")\n",
    "\n",
    "remove_start = 60\n",
    "print(f\"Samples to remove at start: {remove_start}\")\n",
    "remove_end = 300\n",
    "print(f\"Samples to remove at end: {remove_end}\")\n",
    "\n",
    "s_effective = s_total - (remove_start + remove_end)\n",
    "print(f\"Effective duration after removing start/end: {s_effective} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43727e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec339506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups found: ['Untitled']\n",
      "Time from header: 2016-10-12T09:05:02.000000\n",
      "Loaded TDMS with shape: (82460288, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Untitled.EKG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-70.270817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.377859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.202197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-45.469352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-144.675212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Untitled.EKG\n",
       "0    -70.270817\n",
       "1     -1.377859\n",
       "2     37.202197\n",
       "3    -45.469352\n",
       "4   -144.675212"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neurokit2 as nk\n",
    "import nptdms\n",
    "\n",
    "# Read TDMS file\n",
    "try:\n",
    "    tdms = nptdms.TdmsFile.read(path_patient)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to read TDMS file: {e}\")\n",
    "\n",
    "# List groups\n",
    "groups = tdms.groups()\n",
    "print(\"Groups found:\", [g.name for g in groups])\n",
    "\n",
    "# Collect channel data into a dict of pandas Series\n",
    "channels = {}\n",
    "tdms_time_printed = globals().get('tdms_time_printed', False)\n",
    "\n",
    "for g in groups:\n",
    "    for ch in g.channels():\n",
    "        key = f\"{g.name}.{ch.name}\"\n",
    "        try:\n",
    "            arr = ch[:]  # numpy array of channel samples\n",
    "        except Exception:\n",
    "            arr = ch.data  # fallback\n",
    "        channels[key] = pd.Series(arr, name=key)\n",
    "\n",
    "        # Print \"Time\" from TDMS header/properties once\n",
    "        if not tdms_time_printed:\n",
    "            time_val = None\n",
    "\n",
    "            # file-level properties\n",
    "            props = getattr(tdms, \"properties\", {}) or {}\n",
    "            if isinstance(props, dict):\n",
    "                for k, v in props.items():\n",
    "                    if \"time\" in str(k).lower():\n",
    "                        time_val = v\n",
    "                        break\n",
    "\n",
    "            # fallback: file_info dict-like\n",
    "            if time_val is None and hasattr(tdms, \"file_info\"):\n",
    "                fi = getattr(tdms, \"file_info\") or {}\n",
    "                if isinstance(fi, dict):\n",
    "                    for k, v in fi.items():\n",
    "                        if \"time\" in str(k).lower():\n",
    "                            time_val = v\n",
    "                            break\n",
    "\n",
    "            # channel-level properties\n",
    "            if time_val is None and hasattr(ch, \"properties\"):\n",
    "                ch_props = getattr(ch, \"properties\") or {}\n",
    "                if isinstance(ch_props, dict):\n",
    "                    for k, v in ch_props.items():\n",
    "                        if \"time\" in str(k).lower():\n",
    "                            time_val = v\n",
    "                            break\n",
    "\n",
    "            if time_val is not None:\n",
    "                print(\"Time from header:\", time_val)\n",
    "            else:\n",
    "                print(\"No 'Time' property found in TDMS header/channel properties\")\n",
    "\n",
    "            globals()[\"tdms_time_printed\"] = True\n",
    "            tdms_time_printed = True\n",
    "\n",
    "# Build DataFrame (will align by index; if lengths differ, shorter series get NaN)\n",
    "df_tdms = pd.concat(channels, axis=1)\n",
    "\n",
    "print(f\"Loaded TDMS with shape: {df_tdms.shape}\")\n",
    "df_tdms.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e751ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned ECG signal: 82460288 samples. Added column 'EKG_clean' to df_tdms.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Untitled.EKG</th>\n",
       "      <th>EKG_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-70.270817</td>\n",
       "      <td>-549.314036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.377859</td>\n",
       "      <td>-553.209804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.202197</td>\n",
       "      <td>-557.270345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-45.469352</td>\n",
       "      <td>-561.564011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-144.675212</td>\n",
       "      <td>-565.635597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Untitled.EKG   EKG_clean\n",
       "0    -70.270817 -549.314036\n",
       "1     -1.377859 -553.209804\n",
       "2     37.202197 -557.270345\n",
       "3    -45.469352 -561.564011\n",
       "4   -144.675212 -565.635597"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean ECG signal (uses existing `df_tdms` and `key` variables)\n",
    "signal = df_tdms[key]  # 'Untitled.EKG'\n",
    "ecg_cleaned = nk.ecg_clean(signal, method=\"neurokit\")  # adjust method/sampling_rate if needed\n",
    "\n",
    "# Save cleaned signal to dataframe and show a quick check\n",
    "df_tdms[\"EKG_clean\"] = ecg_cleaned\n",
    "print(f\"Cleaned ECG signal: {len(ecg_cleaned)} samples. Added column 'EKG_clean' to df_tdms.\")\n",
    "df_tdms[[\"Untitled.EKG\", \"EKG_clean\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ff494a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sampling rate = 512.0 Hz\n",
      "Detected 167333 R-peaks\n",
      "Added boolean 'R_Peak' column to df_tdms.\n",
      "First 10 R-peak indices: [1218 2387 2785 3037 4280 4991 6417 6817 8551 9145]\n",
      "First 10 R-peak times (s): [ 2.37890625  4.66210938  5.43945312  5.93164062  8.359375    9.74804688\n",
      " 12.53320312 13.31445312 16.70117188 17.86132812]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Try to infer sampling rate from TDMS channel properties (common property names)\n",
    "srate = None\n",
    "if 'ch' in globals() and hasattr(ch, \"properties\"):\n",
    "    for key in (\"wf_sample_rate\", \"sample_rate\", \"sampling_rate\", \"Rate\", \"rate\"):\n",
    "        if key in ch.properties and ch.properties[key] not in (None, \"\"):\n",
    "            srate = ch.properties[key]\n",
    "            break\n",
    "\n",
    "# Normalize srate type if present\n",
    "try:\n",
    "    if isinstance(srate, (bytes, bytearray)):\n",
    "        srate = float(srate.decode())\n",
    "    elif srate is not None:\n",
    "        srate = float(srate)\n",
    "except Exception:\n",
    "    srate = None\n",
    "\n",
    "# Fallback sampling rate (adjust if you know the true rate)\n",
    "if srate is None:\n",
    "    srate = 512.0  # change this to the correct sampling rate if known\n",
    "print(f\"Using sampling rate = {srate} Hz\")\n",
    "\n",
    "# Detect R-peaks with NeuroKit2\n",
    "signals, info = nk.ecg_peaks(ecg_cleaned, sampling_rate=int(srate))\n",
    "\n",
    "# Extract R-peak indices (NeuroKit returns a dict under key 'ECG_R_Peaks')\n",
    "if isinstance(info, dict) and \"ECG_R_Peaks\" in info:\n",
    "    rpeak_indices = np.asarray(info[\"ECG_R_Peaks\"])\n",
    "else:\n",
    "    # fallback: try to extract first array found in `info`\n",
    "    if isinstance(info, dict) and len(info) > 0:\n",
    "        first_val = next(iter(info.values()))\n",
    "        rpeak_indices = np.asarray(first_val)\n",
    "    else:\n",
    "        # if something unexpected, make empty array\n",
    "        rpeak_indices = np.array([], dtype=int)\n",
    "\n",
    "print(f\"Detected {len(rpeak_indices)} R-peaks\")\n",
    "\n",
    "# Compute times of R-peaks (seconds)\n",
    "times = np.arange(len(ecg_cleaned)) / float(srate)\n",
    "rpeak_times = times[rpeak_indices]\n",
    "\n",
    "# Optionally mark R-peaks in df_tdms if lengths match\n",
    "if 'df_tdms' in globals() and len(df_tdms) == len(ecg_cleaned):\n",
    "    df_tdms[\"R_Peak\"] = False\n",
    "    df_tdms.loc[rpeak_indices, \"R_Peak\"] = True\n",
    "    print(\"Added boolean 'R_Peak' column to df_tdms.\")\n",
    "else:\n",
    "    if 'df_tdms' in globals():\n",
    "        print(\"df_tdms length does not match signal length; not adding 'R_Peak' column.\")\n",
    "\n",
    "# Expose results in variables for further use\n",
    "rpeaks_indices = rpeak_indices\n",
    "rpeaks_times = rpeak_times\n",
    "\n",
    "# Quick preview\n",
    "print(\"First 10 R-peak indices:\", rpeaks_indices[:10])\n",
    "print(\"First 10 R-peak times (s):\", rpeaks_times[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kvj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
