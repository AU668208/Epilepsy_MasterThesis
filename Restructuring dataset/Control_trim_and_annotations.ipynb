{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd9970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FEJL] Kunne ikke læse annoteringer fra E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 5\\Patient 5.xls: Ingen gyldige annoteringer (manglende dato/tid).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nptdms import TdmsFile\n",
    "\n",
    "\n",
    "# ------------------ Hjælpefunktioner ------------------\n",
    "\n",
    "def extract_patient_id_from_path(p: Path) -> int | None:\n",
    "    \"\"\"Forsøger at finde et patient-ID i sti/filnavn (Patient 5, Patient_5, etc.).\"\"\"\n",
    "    parts = list(p.parts) + [p.stem]\n",
    "    for part in parts:\n",
    "        m = re.search(r'Patient[ _-]?(\\d+)', part, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            try:\n",
    "                return int(m.group(1))\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_time_columns(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Gæt kolonner for start/slut (dansk/engelsk varianter).\n",
    "    Returnerer (start_col, end_col) eller (col, None) hvis kun start.\n",
    "    \"\"\"\n",
    "    cols = {c.lower(): c for c in df.columns.astype(str)}\n",
    "    # kandidater\n",
    "    start_keys = [\"start\", \"starttid\", \"start time\", \"starttime\", \"anfaldsstart\", \"onset\", \"begin\"]\n",
    "    end_keys   = [\"slut\", \"sluttid\", \"end\", \"end time\", \"endtime\", \"offset\", \"stop\"]\n",
    "\n",
    "    def pick(keys):\n",
    "        for k in cols:\n",
    "            if any(key in k for key in keys):\n",
    "                return cols[k]\n",
    "        return None\n",
    "\n",
    "    c_start = pick(start_keys)\n",
    "    c_end   = pick(end_keys)\n",
    "    if c_start is None:\n",
    "        # Hvis ingen oplagt start-kolonne, prøv første datetime-agtige kolonne\n",
    "        for c in df.columns:\n",
    "            if np.issubdtype(df[c].dtype, np.datetime64):\n",
    "                c_start = c\n",
    "                break\n",
    "    return c_start, c_end\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def _coerce_datetime(series: pd.Series) -> pd.Series:\n",
    "    # Numerisk? -> Excel-serial (origin 1899-12-30)\n",
    "    if np.issubdtype(series.dtype, np.number):\n",
    "        return pd.to_datetime(series, unit=\"d\", origin=\"1899-12-30\", errors=\"coerce\")\n",
    "    # Allerede datetime?\n",
    "    if np.issubdtype(series.dtype, np.datetime64):\n",
    "        return pd.to_datetime(series, errors=\"coerce\")\n",
    "    # Tekst: prøv dayfirst=True\n",
    "    return pd.to_datetime(series.astype(str).str.strip(), errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "# def load_annotations_from_excel_kvj(xls_path, start_row=8):\n",
    "    \"\"\"\n",
    "    Læs tider fra Excel:\n",
    "      - Start: kolonne E (fra række 8), fallback D\n",
    "      - Slut:  kolonne F (hvis tilgængelig)\n",
    "    Returnerer liste af dicts: [{\"start\": dt, \"end\": dt|None, \"row\": excel_row}, ...]\n",
    "    \"\"\"\n",
    "    import pandas as pd, numpy as np\n",
    "    from pathlib import Path\n",
    "    xls_path = Path(xls_path)\n",
    "    engine = \"xlrd\" if xls_path.suffix.lower() == \".xls\" else None\n",
    "    df = pd.read_excel(xls_path, header=None, engine=engine)\n",
    "\n",
    "    r0 = max(0, start_row - 1)\n",
    "    sub = df.iloc[r0:].copy()\n",
    "\n",
    "    def col_idx(letter): return ord(letter.upper()) - ord('A')\n",
    "    idx_D, idx_E, idx_F = col_idx('D'), col_idx('E'), col_idx('F')\n",
    "\n",
    "    def coerce(s):\n",
    "        # tal -> Excel-serial; datetime -> behold; tekst -> parse (dayfirst)\n",
    "        if np.issubdtype(s.dtype, np.number):\n",
    "            return pd.to_datetime(s, unit=\"d\", origin=\"1899-12-30\", errors=\"coerce\")\n",
    "        if np.issubdtype(s.dtype, np.datetime64):\n",
    "            return pd.to_datetime(s, errors=\"coerce\")\n",
    "        return pd.to_datetime(s.astype(str).str.strip(), errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "    in_cols = set(sub.columns)\n",
    "    if idx_E in in_cols:\n",
    "        s_start = coerce(sub[idx_E])\n",
    "    elif idx_D in in_cols:\n",
    "        s_start = coerce(sub[idx_D])\n",
    "    else:\n",
    "        raise ValueError(\"Kan ikke finde startkolonne (E eller D).\")\n",
    "\n",
    "    s_end = None\n",
    "    if idx_F in in_cols:\n",
    "        s_end = coerce(sub[idx_F])\n",
    "\n",
    "    anns = []\n",
    "    for ridx in sub.index:\n",
    "        st = s_start.loc[ridx]\n",
    "        if pd.isna(st):\n",
    "            continue\n",
    "        en = s_end.loc[ridx] if s_end is not None else pd.NaT\n",
    "        anns.append({\n",
    "            \"start\": pd.to_datetime(st).to_pydatetime(),\n",
    "            \"end\": (pd.to_datetime(en).to_pydatetime() if not pd.isna(en) else None),\n",
    "            \"row\": int(ridx) + 1,  # Excel-rækkenummer\n",
    "        })\n",
    "    if not anns:\n",
    "        raise ValueError(f\"Ingen gyldige tider i {xls_path} fra række {start_row}+.\")\n",
    "    return anns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pick_channel(td: TdmsFile, preferred=(\"Recording\", \"ECG\")):\n",
    "    \"\"\"\n",
    "    Vælg kanal; prøv (\"Recording\",\"ECG\") først (som vi lavede i trimming),\n",
    "    ellers første kanal i første gruppe.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ch = td[preferred[0]][preferred[1]]\n",
    "        return preferred[0], preferred[1], ch\n",
    "    except Exception:\n",
    "        for g in td.groups():\n",
    "            chans = g.channels()\n",
    "            if chans:\n",
    "                return g.name, chans[0].name, chans[0]\n",
    "    raise RuntimeError(\"Ingen kanaler fundet.\")\n",
    "\n",
    "\n",
    "def _inc_to_seconds(inc):\n",
    "    \"\"\"Robust konvertering af wf_increment til sekunder pr. sample.\"\"\"\n",
    "    if isinstance(inc, pd.Timedelta):\n",
    "        return inc.total_seconds()\n",
    "    try:\n",
    "        import numpy as np\n",
    "        if isinstance(inc, np.timedelta64):\n",
    "            return pd.to_timedelta(inc).total_seconds()\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Fald tilbage: antag tal (allerede i sekunder)\n",
    "    return float(inc)\n",
    "\n",
    "def channel_time_bounds(ch, expect_fs=(100, 2000)):\n",
    "    \"\"\"\n",
    "    Returnér (t0, t1, fs, n). Hvis fs er urimelig for EKG, prøv at korrigere\n",
    "    wf_increment som minutter eller timer -> sekunder.\n",
    "    \"\"\"\n",
    "    props = ch.properties\n",
    "    inc_s = _inc_to_seconds(props[\"wf_increment\"])  # s/sample\n",
    "    fs = 1.0 / inc_s\n",
    "\n",
    "    # Heuristisk enheds-fix: EKG bør ligge i ~100–2000 Hz (typisk 256/512)\n",
    "    if not (expect_fs[0] <= fs <= expect_fs[1]):\n",
    "        fs_try_min = 1.0 / (inc_s * 60.0)     # antag inc var i minutter\n",
    "        fs_try_hour = 1.0 / (inc_s * 3600.0)  # antag inc var i timer\n",
    "        if expect_fs[0] <= fs_try_min <= expect_fs[1]:\n",
    "            inc_s *= 60.0\n",
    "            fs = fs_try_min\n",
    "            print(\"[INFO] Justerede wf_increment fra minutter -> sekunder.\")\n",
    "        elif expect_fs[0] <= fs_try_hour <= expect_fs[1]:\n",
    "            inc_s *= 3600.0\n",
    "            fs = fs_try_hour\n",
    "            print(\"[INFO] Justerede wf_increment fra timer -> sekunder.\")\n",
    "        else:\n",
    "            print(f\"[ADVARSEL] Mærkelig fs={fs:.4f} Hz (ingen enhedskorrektion mulig).\")\n",
    "\n",
    "    t0 = pd.to_datetime(props[\"wf_start_time\"]).to_pydatetime()\n",
    "    n = len(ch)\n",
    "    dur = timedelta(seconds=(n - 1) / fs) if n > 1 else timedelta(0)\n",
    "    t1 = t0 + dur\n",
    "    return t0, t1, fs, n\n",
    "\n",
    "def align_annotation_to_file_window(st, en, t0, t1, minutes_before_start, minutes_after_end):\n",
    "    \"\"\"\n",
    "    Brug st/en som de er, hvis segmentet (st-Δ, en+Δ) overlapper [t0,t1].\n",
    "    Ellers prøv dag-shifts i rækkefølgen [0, -1, +1, -2, +2] og vælg bedste overlap\n",
    "    (ved tie: vælg med mindst |shift|).\n",
    "    Returnerer (st_adj, en_adj, overlap_seconds).\n",
    "    \"\"\"\n",
    "    def seg(s, e):\n",
    "        seg_start = s - timedelta(minutes=minutes_before_start)\n",
    "        seg_end   = (e if e is not None else s) + timedelta(minutes=minutes_after_end)\n",
    "        return seg_start, seg_end\n",
    "\n",
    "    def overlap_sec(s, e):\n",
    "        ss, ee = seg(s, e)\n",
    "        return (min(ee, t1) - max(ss, t0)).total_seconds()\n",
    "\n",
    "    # 0) hvis allerede overlap → behold\n",
    "    if overlap_sec(st, en) > 0:\n",
    "        return st, en, overlap_sec(st, en)\n",
    "\n",
    "    # 1) prøv skift (prioritér 0, så -1/+1…)\n",
    "    best = (st, en); best_ov = -1e9; best_shift = 0\n",
    "    for shift in (0, -1, 1, -2, 2):\n",
    "        s = st + timedelta(days=shift)\n",
    "        e = en + timedelta(days=shift) if en is not None else None\n",
    "        ov = overlap_sec(s, e)\n",
    "        if ov > best_ov or (ov == best_ov and abs(shift) < abs(best_shift)):\n",
    "            best, best_ov, best_shift = (s, e), ov, shift\n",
    "    return best[0], best[1], best_ov\n",
    "\n",
    "def extract_segment_by_datetime(ch, seg_start_dt, seg_end_dt, t0, fs, n):\n",
    "    \"\"\"\n",
    "    Konverter (seg_start_dt, seg_end_dt) til sample-indeks og udtræk data.\n",
    "    Klipper til filens grænser.\n",
    "    Returnerer (sig, ts) hvor ts er numpy array i sekunder relativt til seg_start_dt.\n",
    "    \"\"\"\n",
    "    # klip til [t0, t1]\n",
    "    t1 = t0 + timedelta(seconds=(n - 1) / fs) if n > 1 else t0\n",
    "    seg_start_dt = max(seg_start_dt, t0)\n",
    "    seg_end_dt = min(seg_end_dt, t1)\n",
    "\n",
    "    i0 = int(round((seg_start_dt - t0).total_seconds() * fs))\n",
    "    i1 = int(round((seg_end_dt   - t0).total_seconds() * fs)) + 1  # inklusivt\n",
    "    i0 = max(0, min(i0, n-1))\n",
    "    i1 = max(i0+1, min(i1, n))\n",
    "\n",
    "    sig = ch[i0:i1]\n",
    "    # tidsakse relativ til segment-start (sek)\n",
    "    ts = np.arange(i1 - i0) / fs\n",
    "    return sig, ts, i0, i1\n",
    "\n",
    "\n",
    "def plot_segment(ts, sig, ann_start_rel_sec, ann_end_rel_sec, out_png, title,\n",
    "                 auto_ylim_percentiles=(1, 99)):\n",
    "    \"\"\"Tegn signalet så linjen ligger over markeringen og autoskaler y-aksen.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    # tegn markering først (så linjen kommer øverst)\n",
    "    if ann_end_rel_sec is not None:\n",
    "        ax.axvspan(ann_start_rel_sec, ann_end_rel_sec, alpha=0.15, color=\"0.7\", zorder=1)\n",
    "    ax.axvline(ann_start_rel_sec, linestyle=\"--\", zorder=2)\n",
    "    if ann_end_rel_sec is not None:\n",
    "        ax.axvline(ann_end_rel_sec, linestyle=\"--\", zorder=2)\n",
    "\n",
    "    # selve signalet\n",
    "    ax.plot(ts, sig, linewidth=0.8, zorder=3)\n",
    "\n",
    "    # valgfrit: autoskalér y-aksen på percentiler for at undgå outliers der “flader” plottet\n",
    "    if auto_ylim_percentiles is not None and len(sig) > 0:\n",
    "        lo, hi = np.nanpercentile(sig, auto_ylim_percentiles)\n",
    "        if np.isfinite(lo) and np.isfinite(hi) and hi > lo:\n",
    "            pad = 0.05 * (hi - lo)\n",
    "            ax.set_ylim(lo - pad, hi + pad)\n",
    "\n",
    "    if len(ts) > 0:\n",
    "        ax.set_xlim(ts[0], ts[-1])\n",
    "\n",
    "    ax.set_xlabel(\"Tid [s] relativt til segment-start\")\n",
    "    ax.set_ylabel(\"EKG [unit]\")\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(out_png, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _td_from_time_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Robust: 'HH:MM:SS' -> Timedelta; Excel-tal -> dage -> Timedelta.\"\"\"\n",
    "    if np.issubdtype(s.dtype, np.number):\n",
    "        # Excel time as fraction of a day\n",
    "        return pd.to_timedelta(s, unit=\"d\", errors=\"coerce\")\n",
    "    # strings like '07:26:57', '7:26', etc.\n",
    "    return pd.to_timedelta(s.astype(str).str.strip(), errors=\"coerce\")\n",
    "\n",
    "def _coerce_date(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Dato-kolonne til datetime.date (dayfirst=True).\"\"\"\n",
    "    out = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
    "    return out.dt.date\n",
    "\n",
    "def _norm(txt):\n",
    "    if not isinstance(txt, str):\n",
    "        txt = str(txt)\n",
    "    return \"\".join(ch for ch in txt.lower() if ch.isalnum())\n",
    "\n",
    "# def load_annotations_from_excel_eeg_first(xls_path: str | Path, header_scan_rows: int = 20):\n",
    "    \"\"\"\n",
    "    Læs en Excel som på dit screenshot og lav annoteringer pr. række:\n",
    "      start = EEG start  (E), ellers Klinisk start (D)\n",
    "      slut  = EEG slut   (G), ellers Klinisk slut  (F)\n",
    "      dato  = 'Dato' kolonnen (C)\n",
    "    Returnerer: [{\"start\": dt, \"end\": dt|None, \"row\": excel_row}, ...]\n",
    "    \"\"\"\n",
    "    xls_path = Path(xls_path)\n",
    "    engine = \"xlrd\" if xls_path.suffix.lower() == \".xls\" else None\n",
    "    df = pd.read_excel(xls_path, header=None, engine=engine)\n",
    "\n",
    "    # 1) find header-rækken ved at lede efter kolonne-teksterne\n",
    "    target_map = {\n",
    "        \"dato\": None,\n",
    "        \"anfaldsstarteegttmmss\": None,\n",
    "        \"anfaldsstop eegttmmss\": None,\n",
    "        \"anfaldsstartkliniskttmmss\": None,\n",
    "        \"anfaldsstopkliniskttmmss\": None,\n",
    "    }\n",
    "    header_row = None\n",
    "    for r in range(min(header_scan_rows, len(df))):\n",
    "        row = df.iloc[r].tolist()\n",
    "        for c, v in enumerate(row):\n",
    "            key = _norm(v)\n",
    "            if key in target_map and target_map[key] is None:\n",
    "                target_map[key] = c\n",
    "        # har vi mindst 'dato' og én startkolonne?\n",
    "        if target_map[\"dato\"] is not None and (\n",
    "            target_map[\"anfaldsstarteegttmmss\"] is not None\n",
    "            or target_map[\"anfaldsstartkliniskttmmss\"] is not None\n",
    "        ):\n",
    "            header_row = r\n",
    "            break\n",
    "    if header_row is None:\n",
    "        raise ValueError(\"Kunne ikke finde header-rækken (’Dato’, ’Anfaldsstart EEG/Klinisk’).\")\n",
    "\n",
    "    c_date   = target_map[\"dato\"]\n",
    "    c_eeg_s  = target_map[\"anfaldsstarteegttmmss\"]\n",
    "    c_eeg_e  = target_map[\"anfaldsstop eegttmmss\"]\n",
    "    c_cli_s  = target_map[\"anfaldsstartkliniskttmmss\"]\n",
    "    c_cli_e  = target_map[\"anfaldsstopkliniskttmmss\"]\n",
    "\n",
    "    data = df.iloc[header_row+1:].copy()\n",
    "    # 2) parse dato og tider\n",
    "    date_col = _coerce_date(data[c_date])\n",
    "    eeg_start_td = _td_from_time_series(data[c_eeg_s]) if c_eeg_s is not None else pd.Series([pd.NaT]*len(data), index=data.index)\n",
    "    eeg_end_td   = _td_from_time_series(data[c_eeg_e]) if c_eeg_e is not None else pd.Series([pd.NaT]*len(data), index=data.index)\n",
    "    cli_start_td = _td_from_time_series(data[c_cli_s]) if c_cli_s is not None else pd.Series([pd.NaT]*len(data), index=data.index)\n",
    "    cli_end_td   = _td_from_time_series(data[c_cli_e]) if c_cli_e is not None else pd.Series([pd.NaT]*len(data), index=data.index)\n",
    "\n",
    "    # 3) kombiner dato + tid (prioritér EEG)\n",
    "    annotations = []\n",
    "    for ridx in data.index:\n",
    "        d = date_col.loc[ridx]\n",
    "        if pd.isna(d):\n",
    "            continue\n",
    "        # byg datetimes\n",
    "        st_eeg = pd.Timestamp.combine(d, pd.Timestamp(0) .time()) + (eeg_start_td.loc[ridx] if pd.notna(eeg_start_td.loc[ridx]) else pd.Timedelta(0))\n",
    "        st_cli = pd.Timestamp.combine(d, pd.Timestamp(0) .time()) + (cli_start_td.loc[ridx] if pd.notna(cli_start_td.loc[ridx]) else pd.Timedelta(0))\n",
    "        en_eeg = pd.Timestamp.combine(d, pd.Timestamp(0) .time()) + (eeg_end_td.loc[ridx]   if pd.notna(eeg_end_td.loc[ridx])   else pd.Timedelta(0))\n",
    "        en_cli = pd.Timestamp.combine(d, pd.Timestamp(0) .time()) + (cli_end_td.loc[ridx]   if pd.notna(cli_end_td.loc[ridx])   else pd.Timedelta(0))\n",
    "\n",
    "        # vælg start\n",
    "        st = st_eeg if (c_eeg_s is not None and pd.notna(eeg_start_td.loc[ridx])) else (\n",
    "             st_cli if (c_cli_s is not None and pd.notna(cli_start_td.loc[ridx])) else pd.NaT)\n",
    "        if pd.isna(st):\n",
    "            continue  # ingen start -> ignorer række\n",
    "\n",
    "        # vælg slut\n",
    "        en = None\n",
    "        if c_eeg_e is not None and pd.notna(eeg_end_td.loc[ridx]):\n",
    "            en = en_eeg\n",
    "        elif c_cli_e is not None and pd.notna(cli_end_td.loc[ridx]):\n",
    "            en = en_cli\n",
    "\n",
    "        annotations.append({\n",
    "            \"start\": pd.to_datetime(st).to_pydatetime(),\n",
    "            \"end\": (pd.to_datetime(en).to_pydatetime() if en is not None else None),\n",
    "            \"row\": int(ridx) + 1,  # rapportér som Excel-rækkenr (1-baseret)\n",
    "        })\n",
    "\n",
    "    if not annotations:\n",
    "        raise ValueError(\"Ingen gyldige annoteringer (manglede dato/tider).\")\n",
    "    return annotations\n",
    "\n",
    "\n",
    "def _norm(s):\n",
    "    s = \"\" if s is None else str(s)\n",
    "    return \"\".join(ch for ch in s.lower() if ch.isalnum())  # kun a-z0-9\n",
    "\n",
    "def _td_from_time_series(s: pd.Series) -> pd.Series:\n",
    "    if np.issubdtype(s.dtype, np.number):  # Excel-serial som fraktion af døgn\n",
    "        return pd.to_timedelta(s, unit=\"d\", errors=\"coerce\")\n",
    "    return pd.to_timedelta(s.astype(str).str.strip(), errors=\"coerce\")\n",
    "\n",
    "def _coerce_date(s: pd.Series) -> pd.Series:\n",
    "    out = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
    "    return out.dt.date\n",
    "\n",
    "def load_annotations_from_excel_eeg_first(xls_path: str | Path, header_scan_rows: int = 20):\n",
    "    \"\"\"\n",
    "    Finder kolonner via tokens:\n",
    "      - Dato: indeholder 'dato'\n",
    "      - EEG start: indeholder både 'anfaldsstart' og 'eeg'\n",
    "      - EEG stop : indeholder både 'anfaldsstop'  og 'eeg'\n",
    "      - Klinisk start/stop tilsvarende med 'klinisk'\n",
    "    Returnerer [{\"start\": dt, \"end\": dt|None, \"row\": excel_row}, ...]\n",
    "    \"\"\"\n",
    "    xls_path = Path(xls_path)\n",
    "    engine = \"xlrd\" if xls_path.suffix.lower() == \".xls\" else None\n",
    "    df = pd.read_excel(xls_path, header=None, engine=engine)\n",
    "\n",
    "    # --- find header-række + kolonneindekser via token-match ---\n",
    "    c_date = c_eeg_s = c_eeg_e = c_cli_s = c_cli_e = None\n",
    "    header_row = None\n",
    "\n",
    "    def match_tokens(cell, must_have, must_not=None):\n",
    "        key = _norm(cell)\n",
    "        if not key:\n",
    "            return False\n",
    "        ok = all(tok in key for tok in must_have)\n",
    "        if must_not:\n",
    "            ok = ok and all(tok not in key for tok in must_not)\n",
    "        return ok\n",
    "\n",
    "    for r in range(min(header_scan_rows, len(df))):\n",
    "        row = df.iloc[r]\n",
    "        for c, v in row.items():\n",
    "            if c_date is None and match_tokens(v, [\"dato\"]):\n",
    "                c_date = c\n",
    "            if c_eeg_s is None and match_tokens(v, [\"anfaldsstart\", \"eeg\"]):\n",
    "                c_eeg_s = c\n",
    "            if c_eeg_e is None and match_tokens(v, [\"anfaldsstop\", \"eeg\"]):\n",
    "                c_eeg_e = c\n",
    "            if c_cli_s is None and match_tokens(v, [\"anfaldsstart\", \"klinisk\"]):\n",
    "                c_cli_s = c\n",
    "            if c_cli_e is None and match_tokens(v, [\"anfaldsstop\", \"klinisk\"]):\n",
    "                c_cli_e = c\n",
    "        if c_date is not None and (c_eeg_s is not None or c_cli_s is not None):\n",
    "            header_row = r\n",
    "            break\n",
    "\n",
    "    if header_row is None:\n",
    "        raise ValueError(\"Kunne ikke finde header-rækken (Dato/EEG/Klinisk).\")\n",
    "\n",
    "    data = df.iloc[header_row+1:].copy()\n",
    "\n",
    "    # --- parse dato + tider ---\n",
    "    date_col = _coerce_date(data[c_date])\n",
    "\n",
    "    def safe_td(col_idx):\n",
    "        if col_idx is None or col_idx not in data.columns:\n",
    "            return pd.Series([pd.NaT]*len(data), index=data.index)\n",
    "        return _td_from_time_series(data[col_idx])\n",
    "\n",
    "    eeg_s_td = safe_td(c_eeg_s)\n",
    "    eeg_e_td = safe_td(c_eeg_e)\n",
    "    cli_s_td = safe_td(c_cli_s)\n",
    "    cli_e_td = safe_td(c_cli_e)\n",
    "\n",
    "    anns = []\n",
    "    for ridx in data.index:\n",
    "        d = date_col.loc[ridx]\n",
    "        if pd.isna(d):\n",
    "            continue\n",
    "        base = pd.Timestamp.combine(d, pd.Timestamp(0).time())\n",
    "\n",
    "        st = base + (eeg_s_td.loc[ridx] if pd.notna(eeg_s_td.loc[ridx]) else cli_s_td.loc[ridx])\n",
    "        if pd.isna(st):\n",
    "            continue\n",
    "\n",
    "        en = None\n",
    "        if pd.notna(eeg_e_td.loc[ridx]):\n",
    "            en = base + eeg_e_td.loc[ridx]\n",
    "        elif pd.notna(cli_e_td.loc[ridx]):\n",
    "            en = base + cli_e_td.loc[ridx]\n",
    "\n",
    "        anns.append({\n",
    "            \"start\": pd.to_datetime(st).to_pydatetime(),\n",
    "            \"end\": (pd.to_datetime(en).to_pydatetime() if en is not None else None),\n",
    "            \"row\": int(ridx) + 1,\n",
    "        })\n",
    "\n",
    "    if not anns:\n",
    "        raise ValueError(\"Ingen gyldige annoteringer (manglende dato/tid).\")\n",
    "    return anns\n",
    "\n",
    "\n",
    "\n",
    "# ------------------ Hoved-flow ------------------\n",
    "\n",
    "def _sanitize_end_time(st, en, default_after_min=2):\n",
    "    \"\"\"\n",
    "    Gør 'en' brugbar:\n",
    "      - NaT/None -> st + default_after_min\n",
    "      - Kun klokkeslæt (år <= 1901) -> brug datoen fra st (og +1 dag hvis den krydser midnat)\n",
    "      - Hvis afstanden er urealistisk stor (> 48h) -> fald tilbage til st + default_after_min\n",
    "    \"\"\"\n",
    "    if en is None or pd.isna(en):\n",
    "        return st + timedelta(minutes=default_after_min)\n",
    "\n",
    "    # Excel \"time only\" (år 1899/1900/1901)\n",
    "    if getattr(en, \"year\", 3000) <= 1901:\n",
    "        en = en.replace(year=st.year, month=st.month, day=st.day)\n",
    "        if en < st:\n",
    "            en = en + timedelta(days=1)\n",
    "\n",
    "    # Outliers (fx 2025 mod 2016)\n",
    "    if abs((en - st).total_seconds()) > 48 * 3600:\n",
    "        return st + timedelta(minutes=default_after_min)\n",
    "\n",
    "    return en\n",
    "\n",
    "def qa_extract_and_plot(\n",
    "    trimmed_root: str | Path,\n",
    "    patients_root_with_excels: str | Path,\n",
    "    minutes_before_start: int = 5,\n",
    "    minutes_after_end: int = 5,\n",
    "    excel_glob: str = \"*.xls*\",   # .xls og .xlsx\n",
    "):\n",
    "    trimmed_root = Path(trimmed_root)\n",
    "    excel_root = Path(patients_root_with_excels)\n",
    "\n",
    "    # Tillad direkte sti til én Excel\n",
    "    if excel_root.is_file() and excel_root.suffix.lower().startswith(\".xls\"):\n",
    "        excel_files = [excel_root]\n",
    "        excel_root = excel_root.parent\n",
    "    else:\n",
    "        excel_files = list(excel_root.rglob(excel_glob))\n",
    "\n",
    "    if not excel_files:\n",
    "        print(f\"Ingen Excel-filer fundet under: {excel_root}\")\n",
    "        return\n",
    "\n",
    "    summary_rows = []\n",
    "\n",
    "    for xls in excel_files:\n",
    "        pid = extract_patient_id_from_path(xls)\n",
    "        if pid is None:\n",
    "            print(f\"[SKIP] Kan ikke udlede patient-ID fra: {xls}\")\n",
    "            continue\n",
    "\n",
    "        # --- Find trimmede TDMS: 1) spejlet mappe, 2) patient-søgning, 3) alt ---\n",
    "        try:\n",
    "            rel_dir = xls.parent.relative_to(excel_root)\n",
    "            cand_dir = trimmed_root / rel_dir\n",
    "        except Exception:\n",
    "            cand_dir = trimmed_root\n",
    "\n",
    "        tdms_list = sorted(cand_dir.glob(\"*_trimmed.tdms\"))\n",
    "        if not tdms_list:\n",
    "            tdms_list = sorted(trimmed_root.rglob(f\"**/Patient*{pid}*/*_trimmed.tdms\")) + \\\n",
    "                        sorted(trimmed_root.rglob(f\"**/patient*{pid}*/*_trimmed.tdms\"))\n",
    "        if not tdms_list:\n",
    "            tdms_list = sorted(trimmed_root.rglob(\"**/*_trimmed.tdms\"))\n",
    "        if not tdms_list:\n",
    "            print(f\"[ADVARSEL] Ingen *_trimmed.tdms fundet for Patient {pid} i {trimmed_root}\")\n",
    "            continue\n",
    "\n",
    "        # -- Læs annoteringer\n",
    "        try:\n",
    "            anns = load_annotations_from_excel_eeg_first(xls, header_scan_rows=20)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[FEJL] Kunne ikke læse annoteringer fra {xls}: {e}\")\n",
    "            continue\n",
    "        if not anns:\n",
    "            print(f\"[INFO] Ingen gyldige annoteringer i {xls}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n== Patient {pid}: {xls.name} | {len(anns)} annoteringer ==\")\n",
    "\n",
    "\n",
    "        # -- For hver annotering\n",
    "        for j, a in enumerate(anns, 1):\n",
    "            st = a[\"start\"]\n",
    "            en = _sanitize_end_time(st, a[\"end\"], default_after_min=2)\n",
    "\n",
    "            seg_start = st - timedelta(minutes=minutes_before_start)\n",
    "            seg_end   = en + timedelta(minutes=minutes_after_end)\n",
    "\n",
    "            # Definér på forhånd (så de findes, selv hvis vi rammer except)\n",
    "            ann_start_rel = (st - seg_start).total_seconds()\n",
    "            ann_end_rel = (en - seg_start).total_seconds() if en else None\n",
    "\n",
    "            matched = False\n",
    "            first_bounds_msg = None\n",
    "\n",
    "            print(f\"  ann#{j}: st={st}, en={en}\")\n",
    "            seg_start = st - timedelta(minutes=minutes_before_start)\n",
    "            seg_end   = (en if en else st) + timedelta(minutes=minutes_after_end)\n",
    "            print(f\"           seg_start={seg_start}, seg_end={seg_end}\")\n",
    "\n",
    "            for tdms_path in tdms_list:\n",
    "                try:\n",
    "                    with TdmsFile.open(tdms_path) as td:\n",
    "                        _, _, ch = pick_channel(td)\n",
    "                        t0, t1, fs, n = channel_time_bounds(ch)\n",
    "\n",
    "                        # justér annotering til filvinduet\n",
    "                        st_adj, en_adj, overlap = align_annotation_to_file_window(\n",
    "                            st, en, t0, t1, minutes_before_start, minutes_after_end\n",
    "                        )\n",
    "                        print(f\"           {tdms_path.name}: aligned st={st_adj}, en={en_adj}, overlap={overlap:.1f}s\")\n",
    "\n",
    "                        if overlap <= 0:\n",
    "                            continue  # ingen brugbar overlap for denne fil, prøv næste\n",
    "\n",
    "                        seg_start = st_adj - timedelta(minutes=minutes_before_start)\n",
    "                        seg_end   = (en_adj if en_adj is not None else st_adj) + timedelta(minutes=minutes_after_end)\n",
    "\n",
    "                        # udtræk segment\n",
    "                        sig, ts, i0, i1 = extract_segment_by_datetime(ch, seg_start, seg_end, t0, fs, n)\n",
    "                        ann_start_rel = max(0.0, (st_adj - seg_start).total_seconds())\n",
    "                        ann_end_rel = (en_adj - seg_start).total_seconds() if en_adj is not None else None\n",
    "                        if ann_end_rel is not None:\n",
    "                            ann_end_rel = max(0.0, ann_end_rel)\n",
    "\n",
    "                        # Debug-print\n",
    "                        print(f\"  ✓ ann#{j}: fs={fs:.2f}Hz, samples={len(sig)}, i0={i0}, i1={i1}, \"\n",
    "                              f\"seg_dur={ts[-1]-ts[0] if len(ts) else 0:.2f}s\")\n",
    "\n",
    "                        # Plot\n",
    "                        qa_dir = tdms_path.parent / \"QA_plots\"\n",
    "                        title = f\"Patient {pid} | {tdms_path.stem} | ann#{j} (row {a['row']})\"\n",
    "                        out_png = qa_dir / f\"{tdms_path.stem}_ann{j:03d}.png\"\n",
    "                        plot_segment(ts, sig, ann_start_rel, ann_end_rel, out_png, title)\n",
    "\n",
    "                        # Summary\n",
    "                        summary_rows.append({\n",
    "                            \"patient_id\": pid,\n",
    "                            \"excel\": str(xls),\n",
    "                            \"tdms\": str(tdms_path),\n",
    "                            \"ann_index\": j,\n",
    "                            \"row_in_excel\": a[\"row\"],\n",
    "                            \"fs_Hz\": fs,\n",
    "                            \"ch_n\": n,\n",
    "                            \"file_t0\": pd.to_datetime(t0),\n",
    "                            \"file_t1\": pd.to_datetime(t1),\n",
    "                            \"ann_start\": pd.to_datetime(st),\n",
    "                            \"ann_end\": pd.to_datetime(en) if en else pd.NaT,\n",
    "                            \"seg_start\": pd.to_datetime(seg_start),\n",
    "                            \"seg_end\": pd.to_datetime(seg_end),\n",
    "                            \"i0\": i0,\n",
    "                            \"i1\": i1,\n",
    "                            \"png\": str(out_png),\n",
    "                            \"status\": \"ok\",\n",
    "                        })\n",
    "                        matched = True\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Log fejlen uden at bruge udefinerede variabler\n",
    "                    print(f\"  [FEJL] {tdms_path}: {type(e).__name__}: {e}\")\n",
    "                    summary_rows.append({\n",
    "                        \"patient_id\": pid, \"excel\": str(xls), \"tdms\": str(tdms_path),\n",
    "                        \"ann_index\": j, \"row_in_excel\": a[\"row\"], \"status\": f\"error: {type(e).__name__}: {e}\"\n",
    "                    })\n",
    "\n",
    "            if not matched:\n",
    "                msg = first_bounds_msg or \"ingen TDMS åbnet\"\n",
    "                print(f\"  [ADVARSEL] ann#{j}: fandt ingen TDMS med overlap af {seg_start}–{seg_end} ({msg})\")\n",
    "                summary_rows.append({\n",
    "                    \"patient_id\": pid, \"excel\": str(xls), \"tdms\": \"\",\n",
    "                    \"ann_index\": j, \"row_in_excel\": a[\"row\"], \"status\": \"no_matching_tdms\",\n",
    "                    \"ann_start\": pd.to_datetime(st),\n",
    "                    \"ann_end\": pd.to_datetime(en) if en else pd.NaT,\n",
    "                    \"seg_start\": pd.to_datetime(seg_start),\n",
    "                    \"seg_end\": pd.to_datetime(seg_end),\n",
    "                })\n",
    "\n",
    "\n",
    "# ------------------ Kørsel ------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Justér disse to stier:\n",
    "    TRIMMED_ROOT = r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 5\\recording 1\"\n",
    "    PATIENTS_ROOT_WITH_EXCELS = r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 5\\Patient 5.xls\"\n",
    "\n",
    "    qa_extract_and_plot(\n",
    "        trimmed_root=TRIMMED_ROOT,\n",
    "        patients_root_with_excels=PATIENTS_ROOT_WITH_EXCELS,\n",
    "        minutes_before_start=1,\n",
    "        minutes_after_end=1,\n",
    "        excel_glob=\"*.xls*\",  # .xls og .xlsx\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c47813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fandt 1 TDMS og 1 Excel-filer.\n",
      "Excel-kolonner: {'header_row(1-based)': 7, 'Dato': 'C', 'EEG_start': 'E', 'EEG_stop': None, 'Klinisk_start': 'D', 'Klinisk_stop': None}\n",
      "\n",
      "== Patient 5: Patient 5.xls | 3 annoteringer ==\n",
      "  ann#1: st=2016-10-13 07:22:37, en=2016-10-13 07:24:37  -> seg=2016-10-13 07:21:37..2016-10-13 07:25:37\n",
      "    ✓ Patient 5_1_trimmed.tdms: fs=512.00Hz, samples=122881, i0=40445440, i1=40568321, dur=240.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kvjkv\\AppData\\Local\\Temp\\ipykernel_13168\\2832436294.py:49: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  out = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ann#2: st=2016-10-13 14:47:29, en=2016-10-13 14:49:29  -> seg=2016-10-13 14:46:29..2016-10-13 14:50:29\n",
      "    ✓ Patient 5_1_trimmed.tdms: fs=512.00Hz, samples=122881, i0=54111744, i1=54234625, dur=240.00s\n",
      "  ann#3: st=2016-10-13 15:36:30, en=2016-10-13 15:38:30  -> seg=2016-10-13 15:35:30..2016-10-13 15:39:30\n",
      "    ✓ Patient 5_1_trimmed.tdms: fs=512.00Hz, samples=122881, i0=55617536, i1=55740417, dur=240.00s\n",
      "\n",
      "Summary gemt: E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 5\\recording 1\\QA_segments_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# --- QA: Excel (EEG-first) -> segmenter fra trimmede TDMS og plots ---\n",
    "# Kør alt i én celle. Tilpas stier i \"MAIN\" nederst.\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import timedelta, datetime\n",
    "import os, re, traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nptdms import TdmsFile\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "\n",
    "def _col_letter(idx: int) -> str:\n",
    "    # 0->A, 1->B ...\n",
    "    return chr(ord('A') + idx)\n",
    "\n",
    "def _norm(s):\n",
    "    s = \"\" if s is None else str(s)\n",
    "    return \"\".join(ch for ch in s.lower() if ch.isalnum())  # a-z0-9\n",
    "\n",
    "def extract_patient_id_from_path(p: Path) -> int | None:\n",
    "    parts = list(p.parts) + [p.stem]\n",
    "    for part in parts:\n",
    "        m = re.search(r'patient[ _-]?(\\d+)', part, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            try:\n",
    "                return int(m.group(1))\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Excel: EEG-first loader\n",
    "# =========================\n",
    "\n",
    "def _td_from_time_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Robust: Excel-tal => fraktion af døgn; tekst 'HH:MM:SS' => Timedelta.\"\"\"\n",
    "    if np.issubdtype(s.dtype, np.number):\n",
    "        return pd.to_timedelta(s, unit=\"d\", errors=\"coerce\")\n",
    "    return pd.to_timedelta(s.astype(str).str.strip(), errors=\"coerce\")\n",
    "\n",
    "def _coerce_date(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Dato til datetime.date (dayfirst=True). Håndterer også Excel-serial via to_datetime.\"\"\"\n",
    "    out = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
    "    # Nogle xls har dato som tal -> bliver også korrekt her\n",
    "    return out.dt.date\n",
    "\n",
    "def _find_header_and_columns(df: pd.DataFrame, header_scan_rows: int = 30):\n",
    "    \"\"\"\n",
    "    Find header-rækken ved at lede efter 'Dato' + mindst én start-kolonne\n",
    "    i *samme* række. Returnér kolonneindekser fra den række.\n",
    "    Fallback til (række 7, C/E/G/D/F) hvis ikke fundet.\n",
    "    \"\"\"\n",
    "    def match_tokens(cell, must_have, must_not=None):\n",
    "        key = _norm(cell)\n",
    "        if not key:\n",
    "            return False\n",
    "        ok = all(tok in key for tok in must_have)\n",
    "        if must_not:\n",
    "            ok = ok and all(tok not in key for tok in must_not)\n",
    "        return ok\n",
    "\n",
    "    scan_limit = min(header_scan_rows, len(df))\n",
    "    for r in range(scan_limit):\n",
    "        row = df.iloc[r]\n",
    "\n",
    "        # Nulstil for hver række (VIGTIGT)\n",
    "        c_date = c_eeg_s = c_eeg_e = c_cli_s = c_cli_e = None\n",
    "\n",
    "        for c, v in row.items():\n",
    "            if c_date is None and match_tokens(v, [\"dato\"]):\n",
    "                c_date = c\n",
    "            if c_eeg_s is None and match_tokens(v, [\"anfaldsstart\", \"eeg\"]):\n",
    "                c_eeg_s = c\n",
    "            if c_eeg_e is None and match_tokens(v, [\"anfaldsstop\", \"eeg\"]):\n",
    "                c_eeg_e = c\n",
    "            if c_cli_s is None and match_tokens(v, [\"anfaldsstart\", \"klinisk\"]):\n",
    "                c_cli_s = c\n",
    "            if c_cli_e is None and match_tokens(v, [\"anfaldsstop\", \"klinisk\"]):\n",
    "                c_cli_e = c\n",
    "\n",
    "        # Krav: Dato + (EEG_start eller Klinisk_start) fundet i samme række\n",
    "        if c_date is not None and (c_eeg_s is not None or c_cli_s is not None):\n",
    "            return r, c_date, c_eeg_s, c_eeg_e, c_cli_s, c_cli_e\n",
    "\n",
    "    # ---- Fallback til dit layout (række 7; C/E/G/D/F) ----\n",
    "    header_row = 6  # 0-indekseret -> Excel-række 7\n",
    "    cols = set(df.columns)\n",
    "    def ci(letter):\n",
    "        idx = ord(letter.upper()) - ord('A')\n",
    "        return idx if idx in cols else None\n",
    "\n",
    "    c_date  = ci('C')\n",
    "    c_eeg_s = ci('E')\n",
    "    c_eeg_e = ci('G')\n",
    "    c_cli_s = ci('D')\n",
    "    c_cli_e = ci('F')\n",
    "    return header_row, c_date, c_eeg_s, c_eeg_e, c_cli_s, c_cli_e\n",
    "\n",
    "\n",
    "def load_annotations_from_excel_eeg_first(xls_path: str | Path, header_scan_rows: int = 30):\n",
    "    \"\"\"\n",
    "    Læs annoteringer som på dit ark:\n",
    "      start = EEG start  (prioritet), ellers Klinisk start\n",
    "      slut  = EEG stop   (prioritet), ellers Klinisk stop\n",
    "      dato  = 'Dato'\n",
    "    Returnerer liste af dicts: [{\"start\": dt, \"end\": dt|None, \"row\": excel_row}, ...]\n",
    "    \"\"\"\n",
    "    xls_path = Path(xls_path)\n",
    "    engine = \"xlrd\" if xls_path.suffix.lower() == \".xls\" else None\n",
    "    df = pd.read_excel(xls_path, header=None, engine=engine)\n",
    "\n",
    "    header_row, c_date, c_eeg_s, c_eeg_e, c_cli_s, c_cli_e = _find_header_and_columns(df, header_scan_rows)\n",
    "    data = df.iloc[header_row+1:].copy()\n",
    "\n",
    "    # Debug (valgfrit): print valgte kolonner\n",
    "    chosen = {\n",
    "        \"header_row(1-based)\": header_row + 1,\n",
    "        \"Dato\": _col_letter(c_date) if c_date is not None else None,\n",
    "        \"EEG_start\": _col_letter(c_eeg_s) if c_eeg_s is not None else None,\n",
    "        \"EEG_stop\": _col_letter(c_eeg_e) if c_eeg_e is not None else None,\n",
    "        \"Klinisk_start\": _col_letter(c_cli_s) if c_cli_s is not None else None,\n",
    "        \"Klinisk_stop\": _col_letter(c_cli_e) if c_cli_e is not None else None,\n",
    "    }\n",
    "    print(\"Excel-kolonner:\", chosen)\n",
    "\n",
    "    # Parse dato + tider\n",
    "    if c_date is None or c_date not in data.columns:\n",
    "        raise ValueError(\"Fandt ikke 'Dato'-kolonnen. Justér header/Fallback.\")\n",
    "\n",
    "    date_col = _coerce_date(data[c_date])\n",
    "\n",
    "    def safe_td(col_idx):\n",
    "        if col_idx is None or col_idx not in data.columns:\n",
    "            return pd.Series([pd.NaT]*len(data), index=data.index)\n",
    "        return _td_from_time_series(data[col_idx])\n",
    "\n",
    "    eeg_s_td = safe_td(c_eeg_s)\n",
    "    eeg_e_td = safe_td(c_eeg_e)\n",
    "    cli_s_td = safe_td(c_cli_s)\n",
    "    cli_e_td = safe_td(c_cli_e)\n",
    "\n",
    "    anns = []\n",
    "    for ridx in data.index:\n",
    "        d = date_col.loc[ridx]\n",
    "        if pd.isna(d):\n",
    "            continue\n",
    "        base = pd.Timestamp.combine(d, pd.Timestamp(0).time())\n",
    "        # vælg start\n",
    "        st_td = eeg_s_td.loc[ridx] if pd.notna(eeg_s_td.loc[ridx]) else cli_s_td.loc[ridx]\n",
    "        if pd.isna(st_td):\n",
    "            continue\n",
    "        st = base + st_td\n",
    "\n",
    "        # vælg slut\n",
    "        en = None\n",
    "        if pd.notna(eeg_e_td.loc[ridx]):\n",
    "            en = base + eeg_e_td.loc[ridx]\n",
    "        elif pd.notna(cli_e_td.loc[ridx]):\n",
    "            en = base + cli_e_td.loc[ridx]\n",
    "\n",
    "        # kryds af midnat (hvis slut < start)\n",
    "        if en is not None and en < st:\n",
    "            en = en + timedelta(days=1)\n",
    "\n",
    "        anns.append({\n",
    "            \"start\": pd.to_datetime(st).to_pydatetime(),\n",
    "            \"end\": (pd.to_datetime(en).to_pydatetime() if en is not None else None),\n",
    "            \"row\": int(ridx) + 1,  # Excel-rækkenummer\n",
    "        })\n",
    "\n",
    "    if not anns:\n",
    "        raise ValueError(\"Ingen gyldige annoteringer (manglende dato/tid).\")\n",
    "    return anns\n",
    "\n",
    "\n",
    "# =========================\n",
    "# TDMS helpers\n",
    "# =========================\n",
    "\n",
    "def pick_channel(td: TdmsFile, preferred=(\"Recording\", \"ECG\")):\n",
    "    try:\n",
    "        ch = td[preferred[0]][preferred[1]]\n",
    "        return preferred[0], preferred[1], ch\n",
    "    except Exception:\n",
    "        for g in td.groups():\n",
    "            chans = g.channels()\n",
    "            if chans:\n",
    "                return g.name, chans[0].name, chans[0]\n",
    "    raise RuntimeError(\"Ingen kanaler fundet.\")\n",
    "\n",
    "def _inc_to_seconds(inc):\n",
    "    if isinstance(inc, pd.Timedelta):\n",
    "        return inc.total_seconds()\n",
    "    try:\n",
    "        if isinstance(inc, np.timedelta64):\n",
    "            return pd.to_timedelta(inc).total_seconds()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return float(inc)\n",
    "\n",
    "def channel_time_bounds(ch, expect_fs=(50, 4000)):\n",
    "    \"\"\"Returnér (t0, t1, fs, n). Heuristik retter wf_increment hvis enhed er forkert.\"\"\"\n",
    "    props = ch.properties\n",
    "    inc_s = _inc_to_seconds(props[\"wf_increment\"])  # s/sample\n",
    "    fs = 1.0 / inc_s\n",
    "\n",
    "    if not (expect_fs[0] <= fs <= expect_fs[1]):\n",
    "        fs_try_min = 1.0 / (inc_s * 60.0)\n",
    "        fs_try_hour = 1.0 / (inc_s * 3600.0)\n",
    "        if expect_fs[0] <= fs_try_min <= expect_fs[1]:\n",
    "            inc_s *= 60.0; fs = fs_try_min\n",
    "            print(\"[INFO] Justerede wf_increment fra minutter -> sekunder.\")\n",
    "        elif expect_fs[0] <= fs_try_hour <= expect_fs[1]:\n",
    "            inc_s *= 3600.0; fs = fs_try_hour\n",
    "            print(\"[INFO] Justerede wf_increment fra timer -> sekunder.\")\n",
    "        else:\n",
    "            print(f\"[ADVARSEL] Uventet fs={fs:.4f} Hz – tjek wf_increment.\")\n",
    "\n",
    "    t0 = pd.to_datetime(props[\"wf_start_time\"]).to_pydatetime()\n",
    "    n  = len(ch)\n",
    "    dur = timedelta(seconds=(n - 1) / fs) if n > 1 else timedelta(0)\n",
    "    t1 = t0 + dur\n",
    "    return t0, t1, fs, n\n",
    "\n",
    "def extract_segment_by_datetime(ch, seg_start_dt, seg_end_dt, t0, fs, n):\n",
    "    # klip til filens vindue\n",
    "    t1 = t0 + timedelta(seconds=(n - 1) / fs) if n > 1 else t0\n",
    "    seg_start_dt = max(seg_start_dt, t0)\n",
    "    seg_end_dt   = min(seg_end_dt, t1)\n",
    "\n",
    "    i0 = int(round((seg_start_dt - t0).total_seconds() * fs))\n",
    "    i1 = int(round((seg_end_dt   - t0).total_seconds() * fs)) + 1\n",
    "    i0 = max(0, min(i0, n-1))\n",
    "    i1 = max(i0+1, min(i1, n))\n",
    "\n",
    "    sig = ch[i0:i1]\n",
    "    ts = np.arange(i1 - i0) / fs  # sek fra segment-start\n",
    "    return sig, ts, i0, i1\n",
    "\n",
    "def plot_segment(ts, sig, ann_start_rel_sec, ann_end_rel_sec, out_png, title,\n",
    "                 auto_ylim_percentiles=(1, 99)):\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    if ann_end_rel_sec is not None:\n",
    "        ax.axvspan(ann_start_rel_sec, ann_end_rel_sec, alpha=0.15, color=\"0.7\", zorder=1)\n",
    "    ax.axvline(ann_start_rel_sec, linestyle=\"--\", zorder=2)\n",
    "    if ann_end_rel_sec is not None:\n",
    "        ax.axvline(ann_end_rel_sec, linestyle=\"--\", zorder=2)\n",
    "    ax.plot(ts, sig, linewidth=0.8, zorder=3)\n",
    "\n",
    "    if auto_ylim_percentiles is not None and len(sig) > 0:\n",
    "        lo, hi = np.nanpercentile(sig, auto_ylim_percentiles)\n",
    "        if np.isfinite(lo) and np.isfinite(hi) and hi > lo:\n",
    "            pad = 0.05 * (hi - lo)\n",
    "            ax.set_ylim(lo - pad, hi + pad)\n",
    "\n",
    "    if len(ts) > 0:\n",
    "        ax.set_xlim(ts[0], ts[-1])\n",
    "    ax.set_xlabel(\"Tid [s] relativt til segment-start\")\n",
    "    ax.set_ylabel(\"EKG [unit]\")\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(out_png, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Core QA function\n",
    "# =========================\n",
    "\n",
    "def qa_extract_and_plot(\n",
    "    trimmed_root: str | Path,\n",
    "    excel_input: str | Path,\n",
    "    minutes_before_start: int = 5,\n",
    "    minutes_after_end: int = 5,\n",
    "    excel_glob: str = \"*.xls*\",\n",
    "):\n",
    "    \"\"\"\n",
    "    trimmed_root: mappe (eller fil) med de trimmede TDMS (søger rekursivt efter *_trimmed.tdms)\n",
    "    excel_input : mappe (eller fil) med Excel-annoteringer. Hvis fil, bruges kun den.\n",
    "    \"\"\"\n",
    "    trimmed_root = Path(trimmed_root)\n",
    "    excel_input  = Path(excel_input)\n",
    "\n",
    "    # Saml TDMS-kandidater\n",
    "    if trimmed_root.is_file() and trimmed_root.suffix.lower() == \".tdms\":\n",
    "        tdms_all = [trimmed_root]\n",
    "        trimmed_root = trimmed_root.parent\n",
    "    else:\n",
    "        tdms_all = sorted(trimmed_root.rglob(\"**/*_trimmed.tdms\"))\n",
    "    if not tdms_all:\n",
    "        print(f\"[ADVARSEL] Ingen *_trimmed.tdms fundet under: {trimmed_root}\")\n",
    "        return\n",
    "\n",
    "    # Saml Excel-filer\n",
    "    if excel_input.is_file() and excel_input.suffix.lower().startswith(\".xls\"):\n",
    "        excel_files = [excel_input]\n",
    "        excel_root = excel_input.parent\n",
    "    else:\n",
    "        excel_root = excel_input\n",
    "        excel_files = list(excel_root.rglob(excel_glob))\n",
    "    if not excel_files:\n",
    "        print(f\"[ADVARSEL] Ingen Excel-filer fundet under: {excel_root}\")\n",
    "        return\n",
    "\n",
    "    summary_rows = []\n",
    "    print(f\"Fandt {len(tdms_all)} TDMS og {len(excel_files)} Excel-filer.\")\n",
    "\n",
    "    for xls in excel_files:\n",
    "        pid = extract_patient_id_from_path(xls)\n",
    "        if pid is None:\n",
    "            print(f\"[SKIP] Kan ikke udlede patient-ID fra: {xls}\")\n",
    "            continue\n",
    "\n",
    "        # Find TDMS for samme patient (først i samme relative mappe, derefter bredt)\n",
    "        try:\n",
    "            rel_dir = xls.parent.relative_to(excel_root)\n",
    "            cand_dir = trimmed_root / rel_dir\n",
    "        except Exception:\n",
    "            cand_dir = trimmed_root\n",
    "        tdms_list = sorted(cand_dir.glob(\"*_trimmed.tdms\"))\n",
    "        if not tdms_list:\n",
    "            pat = f\"*{pid}*\"\n",
    "            tdms_list = sorted(trimmed_root.rglob(f\"**/Patient{pat}/*_trimmed.tdms\")) + \\\n",
    "                        sorted(trimmed_root.rglob(f\"**/patient{pat}/*_trimmed.tdms\"))\n",
    "        if not tdms_list:\n",
    "            tdms_list = [t for t in tdms_all if str(pid) in t.as_posix()]\n",
    "\n",
    "        # Læs annoteringer (EEG-first)\n",
    "        try:\n",
    "            anns = load_annotations_from_excel_eeg_first(xls, header_scan_rows=30)\n",
    "        except Exception as e:\n",
    "            print(f\"[FEJL] Kunne ikke læse annoteringer fra {xls}: {e}\")\n",
    "            continue\n",
    "        if not anns:\n",
    "            print(f\"[INFO] Ingen gyldige annoteringer i {xls}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n== Patient {pid}: {xls.name} | {len(anns)} annoteringer ==\")\n",
    "\n",
    "        for j, a in enumerate(anns, 1):\n",
    "            st, en = a[\"start\"], a[\"end\"]\n",
    "            # Hvis slut mangler, brug 2 min default\n",
    "            if en is None:\n",
    "                en = st + timedelta(minutes=2)\n",
    "\n",
    "            seg_start = st - timedelta(minutes=minutes_before_start)\n",
    "            seg_end   = en + timedelta(minutes=minutes_after_end)\n",
    "            print(f\"  ann#{j}: st={st}, en={en}  -> seg={seg_start}..{seg_end}\")\n",
    "\n",
    "            matched = False\n",
    "            first_bounds_msg = None\n",
    "\n",
    "            for tdms_path in tdms_list:\n",
    "                try:\n",
    "                    with TdmsFile.open(tdms_path) as td:\n",
    "                        _, _, ch = pick_channel(td)\n",
    "                        t0, t1, fs, n = channel_time_bounds(ch)\n",
    "\n",
    "                        if first_bounds_msg is None:\n",
    "                            first_bounds_msg = f\"{t0}..{t1} @ {fs:.2f}Hz\"\n",
    "\n",
    "                        # overlap?\n",
    "                        if seg_end < t0 or seg_start > t1:\n",
    "                            continue\n",
    "\n",
    "                        # udtræk segment\n",
    "                        sig, ts, i0, i1 = extract_segment_by_datetime(ch, seg_start, seg_end, t0, fs, n)\n",
    "                        ann_start_rel = max(0.0, (st - seg_start).total_seconds())\n",
    "                        ann_end_rel = max(0.0, (en - seg_start).total_seconds()) if en else None\n",
    "\n",
    "                        seg_dur = (ts[-1] - ts[0]) if len(ts) else 0\n",
    "                        print(f\"    ✓ {tdms_path.name}: fs={fs:.2f}Hz, samples={len(sig)}, i0={i0}, i1={i1}, dur={seg_dur:.2f}s\")\n",
    "\n",
    "                        qa_dir = tdms_path.parent / \"QA_plots\"\n",
    "                        title = f\"Patient {pid} | {tdms_path.stem} | ann#{j} (row {a['row']})\"\n",
    "                        out_png = qa_dir / f\"{tdms_path.stem}_ann{j:03d}.png\"\n",
    "                        plot_segment(ts, sig, ann_start_rel, ann_end_rel, out_png, title)\n",
    "\n",
    "                        summary_rows.append({\n",
    "                            \"patient_id\": pid, \"excel\": str(xls), \"tdms\": str(tdms_path),\n",
    "                            \"ann_index\": j, \"row_in_excel\": a[\"row\"], \"fs_Hz\": fs, \"ch_n\": n,\n",
    "                            \"file_t0\": pd.to_datetime(t0), \"file_t1\": pd.to_datetime(t1),\n",
    "                            \"ann_start\": pd.to_datetime(st), \"ann_end\": pd.to_datetime(en),\n",
    "                            \"seg_start\": pd.to_datetime(seg_start), \"seg_end\": pd.to_datetime(seg_end),\n",
    "                            \"i0\": i0, \"i1\": i1, \"png\": str(out_png), \"status\": \"ok\",\n",
    "                        })\n",
    "                        matched = True\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"    [FEJL] {tdms_path.name}: {type(e).__name__}: {e}\")\n",
    "                    summary_rows.append({\n",
    "                        \"patient_id\": pid, \"excel\": str(xls), \"tdms\": str(tdms_path),\n",
    "                        \"ann_index\": j, \"row_in_excel\": a[\"row\"],\n",
    "                        \"status\": f\"error: {type(e).__name__}: {e}\"\n",
    "                    })\n",
    "\n",
    "            if not matched:\n",
    "                print(f\"    [ADVARSEL] ann#{j}: ingen TDMS-overlap (filvindue {first_bounds_msg})\")\n",
    "                summary_rows.append({\n",
    "                    \"patient_id\": pid, \"excel\": str(xls), \"tdms\": \"\",\n",
    "                    \"ann_index\": j, \"row_in_excel\": a[\"row\"], \"status\": \"no_matching_tdms\",\n",
    "                    \"ann_start\": pd.to_datetime(st), \"ann_end\": pd.to_datetime(en),\n",
    "                    \"seg_start\": pd.to_datetime(seg_start), \"seg_end\": pd.to_datetime(seg_end),\n",
    "                })\n",
    "\n",
    "    # Gem summary i roden af trimmed_root\n",
    "    if summary_rows:\n",
    "        out_csv = Path(trimmed_root) / \"QA_segments_summary.csv\"\n",
    "        pd.DataFrame(summary_rows).to_csv(out_csv, index=False)\n",
    "        print(f\"\\nSummary gemt: {out_csv}\")\n",
    "    else:\n",
    "        print(\"\\nIngen plots/summary at gemme.\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN – Tilpas disse to\n",
    "# =========================\n",
    "\n",
    "# Eksempel (peg til en patientmappe eller roden med alle trimmede outputs)\n",
    "TRIMMED_ROOT = r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 5\\recording 1\"\n",
    "# Peg til én Excel-fil (eller en rodmappe med mange Excel-filer)\n",
    "EXCEL_INPUT  = r\"E:\\ML algoritme tl anfaldsdetektion vha HRV\\ePatch data from Aarhus - Corrected\\ePatch data\\Patient 5\\Patient 5.xls\"\n",
    "\n",
    "qa_extract_and_plot(\n",
    "    trimmed_root=TRIMMED_ROOT,\n",
    "    excel_input=EXCEL_INPUT,\n",
    "    minutes_before_start=1,   # 1 min før start\n",
    "    minutes_after_end=1,      # 1 min efter slut\n",
    "    excel_glob=\"*.xls*\",      # relevant hvis EXCEL_INPUT er en mappe\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
